1 ../data/NVD/CVE_2012_4186_PATCHED_nsWaveReader__LoadFormatChunk.c PR_STATIC_ASSERT ( PR_UINT16_MAX + ( PR_UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) ) 65
bool
CVE_2012_4186_PATCHED_nsWaveReader::LoadFormatChunk() 2
PRUint32 fmtSize , rate , channels , frameSize , sampleFormat ; 4
char waveFormat [ WAVE_FORMAT_CHUNK_SIZE ] ; 5
const char * p = waveFormat ; 6
if ( ! ScanForwardUntil ( FRMT_CHUNK_MAGIC , & fmtSize ) )  14
if ( ! ReadAll ( waveFormat , sizeof ( waveFormat ) ) )  18
if ( ReadUint16LE ( & p ) != WAVE_FORMAT_ENCODING_PCM )  28
p += 4; 37
if ( fmtSize > WAVE_FORMAT_CHUNK_SIZE )  48
char extLength [ 2 ] ; 49
if ( ! ReadAll ( extLength , sizeof ( extLength ) ) )  52
PRUint16 extra = ReadUint16LE ( & p ) ; 57
if ( fmtSize - ( WAVE_FORMAT_CHUNK_SIZE + 2 ) != extra )  58
extra += extra % 2; 62
if ( extra > 0 )  64
PR_STATIC_ASSERT ( PR_UINT16_MAX + ( PR_UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) ); 65
------------------------------
2 ../data/NVD/CVE_2012_4186_VULN_nsWaveReader__LoadFormatChunk.c PR_STATIC_ASSERT ( PR_UINT16_MAX + ( PR_UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) ) 65
bool
CVE_2012_4186_VULN_nsWaveReader::LoadFormatChunk() 2
PRUint32 fmtSize , rate , channels , frameSize , sampleFormat ; 4
char waveFormat [ WAVE_FORMAT_CHUNK_SIZE ] ; 5
const char * p = waveFormat ; 6
if ( ! ScanForwardUntil ( FRMT_CHUNK_MAGIC , & fmtSize ) )  14
if ( ! ReadAll ( waveFormat , sizeof ( waveFormat ) ) )  18
if ( ReadUint16LE ( & p ) != WAVE_FORMAT_ENCODING_PCM )  28
p += 4; 37
if ( fmtSize > WAVE_FORMAT_CHUNK_SIZE )  48
char extLength [ 2 ] ; 49
if ( ! ReadAll ( extLength , sizeof ( extLength ) ) )  52
PRUint16 extra = ReadUint16LE ( & p ) ; 57
if ( fmtSize - ( WAVE_FORMAT_CHUNK_SIZE + 2 ) != extra )  58
extra += extra % 2; 62
if ( extra > 0 )  64
PR_STATIC_ASSERT ( PR_UINT16_MAX + ( PR_UINT16_MAX % 2 ) < UINT_MAX / sizeof ( char ) ); 65
------------------------------
3 ../data/NVD/CVE_2012_4287_PATCHED_dissect_bson_document.c final_offset = offset + document_length 38
static int
CVE_2012_4287_PATCHED_dissect_bson_document(tvbuff_t *tvb, packet_info *pinfo, guint offset, proto_tree *tree, int hf_mongo_doc, int nest_level) 2
gint32 document_length ; 4
guint final_offset ; 5
document_length = tvb_get_letohl ( tvb , offset ); 9
if ( document_length == 5 )  31
final_offset = offset + document_length; 38
while ( offset < final_offset - 1 )  153
------------------------------
4 ../data/NVD/CVE_2012_4287_VULN_dissect_bson_document.c final_offset = offset + document_length 22
static int
CVE_2012_4287_VULN_dissect_bson_document(tvbuff_t *tvb, guint offset, proto_tree *tree, int hf_mongo_doc) 2
gint32 document_length ; 4
guint final_offset ; 5
document_length = tvb_get_letohl ( tvb , offset ); 9
if ( document_length == 5 )  10
final_offset = offset + document_length; 22
while ( offset < final_offset - 1 )  137
------------------------------
5 ../data/NVD/CVE_2012_4288_PATCHED_dissect_xtp_ecntl.c len = len + XTP_HEADER_LEN - offset 40
static void
CVE_2012_4288_PATCHED_dissect_xtp_ecntl(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,
guint32 offset) 3
guint32 len = tvb_length_remaining ( tvb , offset ) ; 4
if ( len < MIN_XTP_ECNTL_PKT_LEN )  16
offset += 8; 28
offset += 8; 33
offset += 4; 36
offset += 4; 39
len = len + XTP_HEADER_LEN - offset; 40
if ( len != spans_len )  43
expert_add_info_format ( pinfo , top_ti , PI_MALFORMED , PI_ERROR , "Number of spans (%u) incorrect. Should be %u." , ecntl -> nspan , len ); 44
------------------------------
6 ../data/NVD/CVE_2012_4288_VULN_dissect_xtp_ecntl.c len = len + XTP_HEADER_LEN - offset 41
static void
CVE_2012_4288_VULN_dissect_xtp_ecntl(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,
guint32 offset) 3
guint32 len = tvb_length_remaining ( tvb , offset ) ; 4
if ( len < MIN_XTP_ECNTL_PKT_LEN )  17
offset += 8; 29
offset += 8; 34
offset += 4; 37
offset += 4; 40
len = len + XTP_HEADER_LEN - offset; 41
if ( len != spans_len )  43
proto_item_append_text ( top_ti , ", bogus spans field length (%u, must be %u)" , len , spans_len ); 44
------------------------------
7 ../data/NVD/CVE_2012_4293_PATCHED_dissect_ecat_eoe.c anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_macfilter , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_MACFILTER_LEN ) , ENC_NA ) 134
static void CVE_2012_4293_PATCHED_dissect_ecat_eoe(tvbuff_t *tvb, gint offset, packet_info *pinfo, proto_tree *tree) 1
proto_item * anItem = NULL , * aparent = NULL ; 6
guint eoe_length = tvb_reported_length ( tvb ) - offset ; 11
if ( tree )  13
anItem = proto_tree_add_item ( tree , hf_ecat_mailbox_eoe , tvb , offset , eoe_length , ENC_NA ); 15
if ( eoe_length >= ETHERCAT_EOE_HEADER_LEN )  22
ETHERCAT_EOE_HEADER eoe ; 24
ecat_eoe_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe ); 33
anItem = proto_tree_add_item ( ecat_eoe_tree , hf_ecat_mailbox_eoe_fraghead , tvb , offset , 4 , ENC_NA ); 35
ecat_fraghead_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_fraghead ); 37
switch ( eoe . anEoeHeaderInfoUnion . v . Type )  43
offset += ETHERCAT_EOE_HEADER_LEN; 94
if ( eoe_length - offset >= ETHERCAT_EOE_INIT_LEN )  96
offset += 4; 107
offset += ETHERNET_ADDRESS_LEN; 110
offset += 4; 113
offset += 4; 116
offset += 4; 119
offset += 4; 122
offset += ETHERCAT_EOE_HEADER_LEN; 133
anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_macfilter , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_MACFILTER_LEN ) , ENC_NA ); 134
ecat_eoe_macfilter_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter ); 139
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_macfiltercount , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); 147
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_maskcount , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); 148
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_nobroadcasts , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); 149
anItem = proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_filter , tvb , offset , 16 * ETHERNET_ADDRESS_LEN , ENC_NA ); 153
ecat_eoe_macfilter_filter_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter_filter ); 154
proto_tree_add_item ( ecat_eoe_macfilter_filter_tree , hf_ecat_mailbox_eoe_macfilter_filters [ nCnt ] , tvb , offset + nCnt * ETHERNET_ADDRESS_LEN , ETHERNET_ADDRESS_LEN , ENC_NA ); 156
anItem = proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_filtermask , tvb , offset , 4 * sizeof ( guint32 ) , ENC_NA ); 159
ecat_eoe_macfilter_filtermask_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter_filtermask ); 160
proto_tree_add_item ( ecat_eoe_macfilter_filtermask_tree , hf_ecat_mailbox_eoe_macfilter_filtermasks [ nCnt ] , tvb , offset + nCnt * sizeof ( guint32 ) , sizeof ( guint32 ) , ENC_NA ); 162
proto_item_append_text ( anItem , " - Invalid length!" ); 165
------------------------------
8 ../data/NVD/CVE_2012_4293_PATCHED_dissect_ecat_eoe.c anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_init , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_INIT_LEN ) , ENC_NA ) 95
static void CVE_2012_4293_PATCHED_dissect_ecat_eoe(tvbuff_t *tvb, gint offset, packet_info *pinfo, proto_tree *tree) 1
proto_item * anItem = NULL , * aparent = NULL ; 6
guint eoe_length = tvb_reported_length ( tvb ) - offset ; 11
if ( tree )  13
anItem = proto_tree_add_item ( tree , hf_ecat_mailbox_eoe , tvb , offset , eoe_length , ENC_NA ); 15
if ( eoe_length >= ETHERCAT_EOE_HEADER_LEN )  22
ETHERCAT_EOE_HEADER eoe ; 24
ecat_eoe_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe ); 33
anItem = proto_tree_add_item ( ecat_eoe_tree , hf_ecat_mailbox_eoe_fraghead , tvb , offset , 4 , ENC_NA ); 35
ecat_fraghead_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_fraghead ); 37
switch ( eoe . anEoeHeaderInfoUnion . v . Type )  43
offset += ETHERCAT_EOE_HEADER_LEN; 94
anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_init , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_INIT_LEN ) , ENC_NA ); 95
ecat_eoe_init_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_init ); 98
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_macaddr , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 100
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_ipaddr , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 101
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_subnetmask , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 102
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_defaultgateway , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 103
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_dnsserver , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 104
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_dnsname , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 105
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_append_timestamp , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 106
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_macaddr , tvb , offset , ETHERNET_ADDRESS_LEN , ENC_NA ); 109
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_ipaddr , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 112
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_subnetmask , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 115
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_defaultgateway , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 118
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_dnsserver , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 121
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_dnsname , tvb , offset , 32 , ENC_ASCII | ENC_NA ); 124
proto_item_append_text ( anItem , " - Invalid length!" ); 127
ecat_eoe_macfilter_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter ); 139
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_macfiltercount , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); 147
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_maskcount , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); 148
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_nobroadcasts , tvb , offset , 2 , ENC_LITTLE_ENDIAN ); 149
anItem = proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_filter , tvb , offset , 16 * ETHERNET_ADDRESS_LEN , ENC_NA ); 153
ecat_eoe_macfilter_filter_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter_filter ); 154
proto_tree_add_item ( ecat_eoe_macfilter_filter_tree , hf_ecat_mailbox_eoe_macfilter_filters [ nCnt ] , tvb , offset + nCnt * ETHERNET_ADDRESS_LEN , ETHERNET_ADDRESS_LEN , ENC_NA ); 156
anItem = proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_filtermask , tvb , offset , 4 * sizeof ( guint32 ) , ENC_NA ); 159
ecat_eoe_macfilter_filtermask_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter_filtermask ); 160
proto_tree_add_item ( ecat_eoe_macfilter_filtermask_tree , hf_ecat_mailbox_eoe_macfilter_filtermasks [ nCnt ] , tvb , offset + nCnt * sizeof ( guint32 ) , sizeof ( guint32 ) , ENC_NA ); 162
proto_item_append_text ( anItem , " - Invalid length!" ); 165
------------------------------
9 ../data/NVD/CVE_2012_4293_PATCHED_dissect_ecat_eoe.c next_tvb = tvb_new_subset ( tvb , offset , eoe_length - offset , eoe_length - offset ) 79
static void CVE_2012_4293_PATCHED_dissect_ecat_eoe(tvbuff_t *tvb, gint offset, packet_info *pinfo, proto_tree *tree) 1
tvbuff_t * next_tvb ; 5
guint eoe_length = tvb_reported_length ( tvb ) - offset ; 11
if ( eoe_length >= ETHERCAT_EOE_HEADER_LEN )  22
ETHERCAT_EOE_HEADER eoe ; 24
switch ( eoe . anEoeHeaderInfoUnion . v . Type )  43
offset += ETHERCAT_EOE_HEADER_LEN; 74
if ( eoe . anEoeHeaderDataUnion . v . Fragment == 0 )  77
next_tvb = tvb_new_subset ( tvb , offset , eoe_length - offset , eoe_length - offset ); 79
call_dissector ( eth_handle , next_tvb , pinfo , ecat_eoe_tree ); 80
------------------------------
10 ../data/NVD/CVE_2012_4293_VULN_dissect_ecat_eoe.c anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_macfilter , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_MACFILTER_LEN ) , ENC_NA ) 134
static void CVE_2012_4293_VULN_dissect_ecat_eoe(tvbuff_t *tvb, gint offset, packet_info *pinfo, proto_tree *tree) 1
proto_item * anItem = NULL , * aparent = NULL ; 6
guint eoe_length = tvb_reported_length ( tvb ) - offset ; 11
if ( tree )  13
anItem = proto_tree_add_item ( tree , hf_ecat_mailbox_eoe , tvb , offset , eoe_length , ENC_NA ); 15
if ( eoe_length >= ETHERCAT_EOE_HEADER_LEN )  22
ETHERCAT_EOE_HEADER eoe ; 24
ecat_eoe_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe ); 33
anItem = proto_tree_add_item ( ecat_eoe_tree , hf_ecat_mailbox_eoe_fraghead , tvb , offset , 4 , ENC_NA ); 35
ecat_fraghead_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_fraghead ); 37
switch ( eoe . anEoeHeaderInfoUnion . v . Type )  43
offset += ETHERCAT_EOE_HEADER_LEN; 133
anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_macfilter , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_MACFILTER_LEN ) , ENC_NA ); 134
ecat_eoe_macfilter_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter ); 139
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_macfiltercount , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 140
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_maskcount , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 141
proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_nobroadcasts , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 142
anItem = proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_filter , tvb , offset , 16 * ETHERNET_ADDRESS_LEN , ENC_NA ); 146
ecat_eoe_macfilter_filter_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter_filter ); 147
proto_tree_add_item ( ecat_eoe_macfilter_filter_tree , hf_ecat_mailbox_eoe_macfilter_filters [ nCnt ] , tvb , offset + nCnt * ETHERNET_ADDRESS_LEN , ETHERNET_ADDRESS_LEN , ENC_NA ); 149
anItem = proto_tree_add_item ( ecat_eoe_macfilter_tree , hf_ecat_mailbox_eoe_macfilter_filtermask , tvb , offset , 4 * sizeof ( guint32 ) , ENC_NA ); 152
ecat_eoe_macfilter_filtermask_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_macfilter_filtermask ); 153
proto_tree_add_item ( ecat_eoe_macfilter_filtermask_tree , hf_ecat_mailbox_eoe_macfilter_filtermasks [ nCnt ] , tvb , offset + nCnt * sizeof ( guint32 ) , sizeof ( guint32 ) , ENC_NA ); 155
proto_item_append_text ( anItem , " - Invalid length!" ); 158
------------------------------
11 ../data/NVD/CVE_2012_4293_VULN_dissect_ecat_eoe.c anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_init , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_INIT_LEN ) , ENC_NA ) 95
static void CVE_2012_4293_VULN_dissect_ecat_eoe(tvbuff_t *tvb, gint offset, packet_info *pinfo, proto_tree *tree) 1
proto_item * anItem = NULL , * aparent = NULL ; 6
guint eoe_length = tvb_reported_length ( tvb ) - offset ; 11
if ( tree )  13
anItem = proto_tree_add_item ( tree , hf_ecat_mailbox_eoe , tvb , offset , eoe_length , ENC_NA ); 15
if ( eoe_length >= ETHERCAT_EOE_HEADER_LEN )  22
ETHERCAT_EOE_HEADER eoe ; 24
ecat_eoe_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe ); 33
anItem = proto_tree_add_item ( ecat_eoe_tree , hf_ecat_mailbox_eoe_fraghead , tvb , offset , 4 , ENC_NA ); 35
ecat_fraghead_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_fraghead ); 37
switch ( eoe . anEoeHeaderInfoUnion . v . Type )  43
offset += ETHERCAT_EOE_HEADER_LEN; 74
offset += ETHERCAT_EOE_HEADER_LEN; 94
anItem = proto_tree_add_item ( ecat_fraghead_tree , hf_ecat_mailbox_eoe_init , tvb , offset , MIN ( eoe_length - offset , ETHERCAT_EOE_INIT_LEN ) , ENC_NA ); 95
ecat_eoe_init_tree = proto_item_add_subtree ( anItem , ett_ecat_mailbox_eoe_init ); 98
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_macaddr , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 100
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_ipaddr , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 101
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_subnetmask , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 102
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_defaultgateway , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 103
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_dnsserver , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 104
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_contains_dnsname , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 105
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_append_timestamp , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 106
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_macaddr , tvb , offset , ETHERNET_ADDRESS_LEN , ENC_NA ); 109
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_ipaddr , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 112
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_subnetmask , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 115
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_defaultgateway , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 118
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_dnsserver , tvb , offset , 4 , ENC_LITTLE_ENDIAN ); 121
proto_tree_add_item ( ecat_eoe_init_tree , hf_ecat_mailbox_eoe_init_dnsname , tvb , offset , 32 , ENC_ASCII | ENC_NA ); 124
proto_item_append_text ( anItem , " - Invalid length!" ); 127
------------------------------
12 ../data/NVD/CVE_2012_4293_VULN_dissect_ecat_eoe.c next_tvb = tvb_new_subset ( tvb , offset , eoe_length - offset , eoe_length - offset ) 79
static void CVE_2012_4293_VULN_dissect_ecat_eoe(tvbuff_t *tvb, gint offset, packet_info *pinfo, proto_tree *tree) 1
tvbuff_t * next_tvb ; 5
guint eoe_length = tvb_reported_length ( tvb ) - offset ; 11
if ( eoe_length >= ETHERCAT_EOE_HEADER_LEN )  22
ETHERCAT_EOE_HEADER eoe ; 24
switch ( eoe . anEoeHeaderInfoUnion . v . Type )  43
offset += ETHERCAT_EOE_HEADER_LEN; 74
if ( eoe . anEoeHeaderDataUnion . v . Fragment == 0 )  77
next_tvb = tvb_new_subset ( tvb , offset , eoe_length - offset , eoe_length - offset ); 79
call_dissector ( eth_handle , next_tvb , pinfo , ecat_eoe_tree ); 80
------------------------------
13 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c e_hdr_len = STATS_COMMON_FIELDS_LEN + STATS_ETHERNETTAP_FIELDS_LEN 138
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
guint16 e_hdr_len ; 22
e_hdr_len = STATS_COMMON_FIELDS_LEN + STATS_ETHERNETTAP_FIELDS_LEN; 138
wth -> phdr . len = ( actual_octets - 4 ) + e_hdr_len; 139
wth -> phdr . caplen = ( msdu_length - 4 ) + e_hdr_len; 140
wth -> phdr . presence_flags = WTAP_HAS_TS; 142
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
------------------------------
14 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c delta_b = sig_ts - s_time 125
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
register int i ;
register guint8 * s_ptr , * m_ptr ; 6
guint16 msdu_length , actual_octets ; 7
guint8 flow_seq ; 8
guint16 l4id , info , validityBits ; 14
guint32 flow_id , d_time ; 17
int f_flow ; 18
guint32 frame_type ; 19
int mac_len , sig_off , pay_off ; 23
guint64 sig_ts , tsid ; 24
guint64 delta_b ; 25
m_ptr = & ( rec [ 0 ] ); 29
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
msdu_length = pntohs ( & s_ptr [ vwr -> OCTET_OFF ] ); 32
if ( msdu_length > ( rec_size - ( int ) vwr -> STATS_LEN ) )  36
msdu_length = ( rec_size - ( int ) vwr -> STATS_LEN ); 37
flow_seq = s_ptr [ vwr -> FLOWSEQ_OFF ]; 41
frame_type = pntohl ( & s_ptr [ vwr -> FRAME_TYPE_OFF ] ); 42
if ( vwr -> FPGA_VERSION == vVW510024_E_FPGA )  44
validityBits = pntohs ( & s_ptr [ vwr -> VALID_OFF ] ); 45
f_flow = validityBits & vwr -> FLOW_VALID; 46
mac_len = ( validityBits & vwr -> IS_VLAN ) ? 16 : 14; 48
f_flow = s_ptr [ vwr -> VALID_OFF ] & vwr -> FLOW_VALID; 54
mac_len = ( frame_type & vwr -> IS_VLAN ) ? 16 : 14; 55
flow_id = pntoh24 ( & s_ptr [ vwr -> FLOWID_OFF ] ); 64
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
if ( frame_type & vwr -> IS_TCP )  91
pay_off = mac_len + 40; 93
if ( frame_type & vwr -> IS_UDP )  95
pay_off = mac_len + 28; 97
if ( frame_type & vwr -> IS_ICMP )  99
pay_off = mac_len + 24; 101
if ( frame_type & vwr -> IS_IGMP )  103
pay_off = mac_len + 28; 105
pay_off = mac_len + 20; 109
sig_off = find_signature ( m_ptr , pay_off , flow_id , flow_seq ); 112
if ( ( m_ptr [ sig_off ] == 0xdd ) && ( sig_off + 15 <= msdu_length ) && ( f_flow != 0 ) )  113
sig_ts = get_signature_ts ( m_ptr , sig_off ); 114
sig_ts = 0; 116
if ( ! IS_TX )  119
if ( sig_ts < s_time )  120
delta_b = sig_ts - s_time; 125
if ( delta_b > 0x10000000 )  126
latency = ( guint32 ) delta_b; 129
common_hdr . vw_latency = ( guint32 ) latency; 163
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
15 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c latency = ( guint32 ) ( s_time - sig_ts ) 121
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
register int i ;
register guint8 * s_ptr , * m_ptr ; 6
guint16 msdu_length , actual_octets ; 7
guint8 flow_seq ; 8
guint16 l4id , info , validityBits ; 14
guint32 flow_id , d_time ; 17
int f_flow ; 18
guint32 frame_type ; 19
int mac_len , sig_off , pay_off ; 23
guint64 sig_ts , tsid ; 24
m_ptr = & ( rec [ 0 ] ); 29
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
msdu_length = pntohs ( & s_ptr [ vwr -> OCTET_OFF ] ); 32
if ( msdu_length > ( rec_size - ( int ) vwr -> STATS_LEN ) )  36
msdu_length = ( rec_size - ( int ) vwr -> STATS_LEN ); 37
flow_seq = s_ptr [ vwr -> FLOWSEQ_OFF ]; 41
frame_type = pntohl ( & s_ptr [ vwr -> FRAME_TYPE_OFF ] ); 42
if ( vwr -> FPGA_VERSION == vVW510024_E_FPGA )  44
validityBits = pntohs ( & s_ptr [ vwr -> VALID_OFF ] ); 45
f_flow = validityBits & vwr -> FLOW_VALID; 46
mac_len = ( validityBits & vwr -> IS_VLAN ) ? 16 : 14; 48
f_flow = s_ptr [ vwr -> VALID_OFF ] & vwr -> FLOW_VALID; 54
mac_len = ( frame_type & vwr -> IS_VLAN ) ? 16 : 14; 55
flow_id = pntoh24 ( & s_ptr [ vwr -> FLOWID_OFF ] ); 64
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
if ( frame_type & vwr -> IS_TCP )  91
pay_off = mac_len + 40; 93
if ( frame_type & vwr -> IS_UDP )  95
pay_off = mac_len + 28; 97
if ( frame_type & vwr -> IS_ICMP )  99
pay_off = mac_len + 24; 101
if ( frame_type & vwr -> IS_IGMP )  103
pay_off = mac_len + 28; 105
pay_off = mac_len + 20; 109
sig_off = find_signature ( m_ptr , pay_off , flow_id , flow_seq ); 112
if ( ( m_ptr [ sig_off ] == 0xdd ) && ( sig_off + 15 <= msdu_length ) && ( f_flow != 0 ) )  113
sig_ts = get_signature_ts ( m_ptr , sig_off ); 114
sig_ts = 0; 116
if ( ! IS_TX )  119
if ( sig_ts < s_time )  120
latency = ( guint32 ) ( s_time - sig_ts ); 121
common_hdr . vw_latency = ( guint32 ) latency; 163
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
16 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c end_time = e_time / NS_IN_US 89
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
guint64 end_time ; 13
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
e_time = pcoreytohll ( & s_ptr [ vwr -> ENDT_OFF ] ); 78
end_time = e_time / NS_IN_US; 89
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
17 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c s_usec = start_time - ( s_sec * US_IN_SEC ) 86
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
------------------------------
18 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c s_sec = ( start_time / US_IN_SEC ) 85
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
------------------------------
19 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c start_time = s_time / NS_IN_US 84
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
20 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c d_time = ( guint32 ) ( ( e_time - s_time ) ) 81
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
guint32 flow_id , d_time ; 17
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
e_time = pcoreytohll ( & s_ptr [ vwr -> ENDT_OFF ] ); 78
d_time = ( guint32 ) ( ( e_time - s_time ) ); 81
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
21 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c tsid = ( tsid << 8 ) | s_ptr [ vwr -> LATVAL_OFF + i ] 70
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
guint64 sig_ts , tsid ; 24
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
tsid = ( s_ptr [ vwr -> LATVAL_OFF + 6 ] << 8 ) | ( s_ptr [ vwr -> LATVAL_OFF + 7 ] ); 68
for (i = 0; i < 4; i++) 69
tsid = ( tsid << 8 ) | s_ptr [ vwr -> LATVAL_OFF + i ]; 70
------------------------------
22 ../data/NVD/CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet.c s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ) 30
static void CVE_2012_4298_PATCHED_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
msdu_length = pntohs ( & s_ptr [ vwr -> OCTET_OFF ] ); 32
actual_octets = msdu_length; 33
if ( msdu_length > ( rec_size - ( int ) vwr -> STATS_LEN ) )  36
vc_id = pntohs ( & s_ptr [ vwr -> VCID_OFF ] ) & vwr -> VCID_MASK; 40
flow_seq = s_ptr [ vwr -> FLOWSEQ_OFF ]; 41
frame_type = pntohl ( & s_ptr [ vwr -> FRAME_TYPE_OFF ] ); 42
validityBits = pntohs ( & s_ptr [ vwr -> VALID_OFF ] ); 45
f_flow = validityBits & vwr -> FLOW_VALID; 46
mac_len = ( validityBits & vwr -> IS_VLAN ) ? 16 : 14; 48
errors = pntohs ( & s_ptr [ vwr -> ERRORS_OFF ] ); 51
f_flow = s_ptr [ vwr -> VALID_OFF ] & vwr -> FLOW_VALID; 54
mac_len = ( frame_type & vwr -> IS_VLAN ) ? 16 : 14; 55
errors = pntohs ( & s_ptr [ vwr -> ERRORS_OFF ] ); 59
info = pntohs ( & s_ptr [ vwr -> INFO_OFF ] ); 62
flow_id = pntoh24 ( & s_ptr [ vwr -> FLOWID_OFF ] ); 64
tsid = ( s_ptr [ vwr -> LATVAL_OFF + 6 ] << 8 ) | ( s_ptr [ vwr -> LATVAL_OFF + 7 ] ); 68
tsid = ( tsid << 8 ) | s_ptr [ vwr -> LATVAL_OFF + i ]; 70
l4id = pntohs ( & s_ptr [ vwr -> L4ID_OFF ] ); 73
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
e_time = pcoreytohll ( & s_ptr [ vwr -> ENDT_OFF ] ); 78
d_time = ( guint32 ) ( ( e_time - s_time ) ); 81
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
end_time = e_time / NS_IN_US; 89
if ( frame_type & vwr -> IS_TCP )  91
pay_off = mac_len + 40; 93
if ( frame_type & vwr -> IS_UDP )  95
pay_off = mac_len + 28; 97
if ( frame_type & vwr -> IS_ICMP )  99
pay_off = mac_len + 24; 101
if ( frame_type & vwr -> IS_IGMP )  103
pay_off = mac_len + 28; 105
pay_off = mac_len + 20; 109
sig_off = find_signature ( m_ptr , pay_off , flow_id , flow_seq ); 112
if ( ( m_ptr [ sig_off ] == 0xdd ) && ( sig_off + 15 <= msdu_length ) && ( f_flow != 0 ) )  113
sig_ts = get_signature_ts ( m_ptr , sig_off ); 114
if ( sig_ts < s_time )  120
latency = ( guint32 ) ( s_time - sig_ts ); 121
delta_b = sig_ts - s_time; 125
if ( delta_b > 0x10000000 )  126
latency = ( guint32 ) delta_b; 129
wth -> phdr . len = ( actual_octets - 4 ) + e_hdr_len; 139
wth -> phdr . caplen = ( msdu_length - 4 ) + e_hdr_len; 140
wth -> phdr . presence_flags = WTAP_HAS_TS; 142
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
etap_hdr . vw_errors = ( guint32 ) errors; 153
etap_hdr . vw_info = ( guint16 ) info; 154
common_hdr . vw_msdu_length = ( guint16 ) msdu_length; 155
common_hdr . vw_flowid = ( guint32 ) flow_id; 158
common_hdr . vw_vcid = ( guint16 ) vc_id; 159
common_hdr . vw_seqnum = ( guint16 ) flow_seq; 160
if ( ! IS_TX && ( sig_ts != 0 ) )  162
common_hdr . vw_latency = ( guint32 ) latency; 163
common_hdr . vw_latency = 0; 165
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
etap_hdr . vw_l4id = ( guint32 ) l4id; 167
etap_hdr . vw_flags = 0; 168
etap_hdr . vw_flags |= RADIOTAP_VWF_TXF; 170
if ( errors & vwr -> FCS_ERROR )  171
etap_hdr . vw_flags |= RADIOTAP_VWF_FCSERR; 172
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
etap_hdr . it_pad2 = 0; 177
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
phtoles ( & data_ptr [ bytes_written ] , etap_hdr . it_len ); 210
phtoles ( & data_ptr [ bytes_written ] , etap_hdr . vw_flags ); 212
phtoles ( & data_ptr [ bytes_written ] , etap_hdr . vw_info ); 214
phtolel ( & data_ptr [ bytes_written ] , etap_hdr . vw_errors ); 219
phtolel ( & data_ptr [ bytes_written ] , etap_hdr . vw_l4id ); 221
if ( rec_size < ( ( int ) actual_octets + ( int ) vwr -> STATS_LEN ) )  228
memcpy ( & data_ptr [ bytes_written ] , m_ptr , msdu_length ); 230
if ( msdu_length >= 4 )  231
memcpy ( & data_ptr [ bytes_written ] , m_ptr , msdu_length - 4 ); 232
memcpy ( & data_ptr [ bytes_written ] , m_ptr , msdu_length ); 234
------------------------------
23 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c e_hdr_len = STATS_COMMON_FIELDS_LEN + STATS_ETHERNETTAP_FIELDS_LEN 138
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
guint16 e_hdr_len ; 22
e_hdr_len = STATS_COMMON_FIELDS_LEN + STATS_ETHERNETTAP_FIELDS_LEN; 138
wth -> phdr . len = ( actual_octets - 4 ) + e_hdr_len; 139
wth -> phdr . caplen = ( msdu_length - 4 ) + e_hdr_len; 140
wth -> phdr . presence_flags = WTAP_HAS_TS; 142
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
------------------------------
24 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c delta_b = sig_ts - s_time 125
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
register int i ;
register guint8 * s_ptr , * m_ptr ; 6
gint16 msdu_length , actual_octets ; 7
guint8 flow_seq ; 8
guint16 l4id , info , validityBits ; 14
guint32 flow_id , d_time ; 17
int f_flow ; 18
guint32 frame_type ; 19
int mac_len , sig_off , pay_off ; 23
guint64 sig_ts , tsid ; 24
guint64 delta_b ; 25
m_ptr = & ( rec [ 0 ] ); 29
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
msdu_length = pntohs ( & s_ptr [ vwr -> OCTET_OFF ] ); 32
if ( msdu_length > ( rec_size - ( int ) vwr -> STATS_LEN ) )  36
msdu_length = ( rec_size - ( int ) vwr -> STATS_LEN ); 37
flow_seq = s_ptr [ vwr -> FLOWSEQ_OFF ]; 41
frame_type = pntohl ( & s_ptr [ vwr -> FRAME_TYPE_OFF ] ); 42
if ( vwr -> FPGA_VERSION == vVW510024_E_FPGA )  44
validityBits = pntohs ( & s_ptr [ vwr -> VALID_OFF ] ); 45
f_flow = validityBits & vwr -> FLOW_VALID; 46
mac_len = ( validityBits & vwr -> IS_VLAN ) ? 16 : 14; 48
f_flow = s_ptr [ vwr -> VALID_OFF ] & vwr -> FLOW_VALID; 54
mac_len = ( frame_type & vwr -> IS_VLAN ) ? 16 : 14; 55
flow_id = pntoh24 ( & s_ptr [ vwr -> FLOWID_OFF ] ); 64
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
if ( frame_type & vwr -> IS_TCP )  91
pay_off = mac_len + 40; 93
if ( frame_type & vwr -> IS_UDP )  95
pay_off = mac_len + 28; 97
if ( frame_type & vwr -> IS_ICMP )  99
pay_off = mac_len + 24; 101
if ( frame_type & vwr -> IS_IGMP )  103
pay_off = mac_len + 28; 105
pay_off = mac_len + 20; 109
sig_off = find_signature ( m_ptr , pay_off , flow_id , flow_seq ); 112
if ( ( m_ptr [ sig_off ] == 0xdd ) && ( sig_off + 15 <= msdu_length ) && ( f_flow != 0 ) )  113
sig_ts = get_signature_ts ( m_ptr , sig_off ); 114
sig_ts = 0; 116
if ( ! IS_TX )  119
if ( sig_ts < s_time )  120
delta_b = sig_ts - s_time; 125
if ( delta_b > 0x10000000 )  126
latency = ( guint32 ) delta_b; 129
common_hdr . vw_latency = ( guint32 ) latency; 163
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
25 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c latency = ( guint32 ) ( s_time - sig_ts ) 121
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
register int i ;
register guint8 * s_ptr , * m_ptr ; 6
gint16 msdu_length , actual_octets ; 7
guint8 flow_seq ; 8
guint16 l4id , info , validityBits ; 14
guint32 flow_id , d_time ; 17
int f_flow ; 18
guint32 frame_type ; 19
int mac_len , sig_off , pay_off ; 23
guint64 sig_ts , tsid ; 24
m_ptr = & ( rec [ 0 ] ); 29
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
msdu_length = pntohs ( & s_ptr [ vwr -> OCTET_OFF ] ); 32
if ( msdu_length > ( rec_size - ( int ) vwr -> STATS_LEN ) )  36
msdu_length = ( rec_size - ( int ) vwr -> STATS_LEN ); 37
flow_seq = s_ptr [ vwr -> FLOWSEQ_OFF ]; 41
frame_type = pntohl ( & s_ptr [ vwr -> FRAME_TYPE_OFF ] ); 42
if ( vwr -> FPGA_VERSION == vVW510024_E_FPGA )  44
validityBits = pntohs ( & s_ptr [ vwr -> VALID_OFF ] ); 45
f_flow = validityBits & vwr -> FLOW_VALID; 46
mac_len = ( validityBits & vwr -> IS_VLAN ) ? 16 : 14; 48
f_flow = s_ptr [ vwr -> VALID_OFF ] & vwr -> FLOW_VALID; 54
mac_len = ( frame_type & vwr -> IS_VLAN ) ? 16 : 14; 55
flow_id = pntoh24 ( & s_ptr [ vwr -> FLOWID_OFF ] ); 64
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
if ( frame_type & vwr -> IS_TCP )  91
pay_off = mac_len + 40; 93
if ( frame_type & vwr -> IS_UDP )  95
pay_off = mac_len + 28; 97
if ( frame_type & vwr -> IS_ICMP )  99
pay_off = mac_len + 24; 101
if ( frame_type & vwr -> IS_IGMP )  103
pay_off = mac_len + 28; 105
pay_off = mac_len + 20; 109
sig_off = find_signature ( m_ptr , pay_off , flow_id , flow_seq ); 112
if ( ( m_ptr [ sig_off ] == 0xdd ) && ( sig_off + 15 <= msdu_length ) && ( f_flow != 0 ) )  113
sig_ts = get_signature_ts ( m_ptr , sig_off ); 114
sig_ts = 0; 116
if ( ! IS_TX )  119
if ( sig_ts < s_time )  120
latency = ( guint32 ) ( s_time - sig_ts ); 121
common_hdr . vw_latency = ( guint32 ) latency; 163
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
26 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c end_time = e_time / NS_IN_US 89
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
guint64 end_time ; 13
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
e_time = pcoreytohll ( & s_ptr [ vwr -> ENDT_OFF ] ); 78
end_time = e_time / NS_IN_US; 89
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
27 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c s_usec = start_time - ( s_sec * US_IN_SEC ) 86
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
------------------------------
28 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c s_sec = ( start_time / US_IN_SEC ) 85
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
------------------------------
29 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c start_time = s_time / NS_IN_US 84
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
30 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c d_time = ( guint32 ) ( ( e_time - s_time ) ) 81
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
guint32 flow_id , d_time ; 17
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
e_time = pcoreytohll ( & s_ptr [ vwr -> ENDT_OFF ] ); 78
d_time = ( guint32 ) ( ( e_time - s_time ) ); 81
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
------------------------------
31 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c tsid = ( tsid << 8 ) | s_ptr [ vwr -> LATVAL_OFF + i ] 70
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
guint64 sig_ts , tsid ; 24
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
tsid = ( s_ptr [ vwr -> LATVAL_OFF + 6 ] << 8 ) | ( s_ptr [ vwr -> LATVAL_OFF + 7 ] ); 68
for (i = 0; i < 4; i++) 69
tsid = ( tsid << 8 ) | s_ptr [ vwr -> LATVAL_OFF + i ]; 70
------------------------------
32 ../data/NVD/CVE_2012_4298_VULN_vwr_read_rec_data_ethernet.c s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ) 30
static void CVE_2012_4298_VULN_vwr_read_rec_data_ethernet(wtap *wth, guint8 *data_ptr, guint8 *rec, int rec_size, int IS_TX) 1
vwr_t * vwr = ( vwr_t * ) wth -> priv ; 3
s_ptr = & ( rec [ rec_size - vwr -> STATS_LEN ] ); 30
msdu_length = pntohs ( & s_ptr [ vwr -> OCTET_OFF ] ); 32
actual_octets = msdu_length; 33
if ( msdu_length > ( rec_size - ( int ) vwr -> STATS_LEN ) )  36
vc_id = pntohs ( & s_ptr [ vwr -> VCID_OFF ] ) & vwr -> VCID_MASK; 40
flow_seq = s_ptr [ vwr -> FLOWSEQ_OFF ]; 41
frame_type = pntohl ( & s_ptr [ vwr -> FRAME_TYPE_OFF ] ); 42
validityBits = pntohs ( & s_ptr [ vwr -> VALID_OFF ] ); 45
f_flow = validityBits & vwr -> FLOW_VALID; 46
mac_len = ( validityBits & vwr -> IS_VLAN ) ? 16 : 14; 48
errors = pntohs ( & s_ptr [ vwr -> ERRORS_OFF ] ); 51
f_flow = s_ptr [ vwr -> VALID_OFF ] & vwr -> FLOW_VALID; 54
mac_len = ( frame_type & vwr -> IS_VLAN ) ? 16 : 14; 55
errors = pntohs ( & s_ptr [ vwr -> ERRORS_OFF ] ); 59
info = pntohs ( & s_ptr [ vwr -> INFO_OFF ] ); 62
flow_id = pntoh24 ( & s_ptr [ vwr -> FLOWID_OFF ] ); 64
tsid = ( s_ptr [ vwr -> LATVAL_OFF + 6 ] << 8 ) | ( s_ptr [ vwr -> LATVAL_OFF + 7 ] ); 68
tsid = ( tsid << 8 ) | s_ptr [ vwr -> LATVAL_OFF + i ]; 70
l4id = pntohs ( & s_ptr [ vwr -> L4ID_OFF ] ); 73
s_time = pcoreytohll ( & s_ptr [ vwr -> STARTT_OFF ] ); 77
e_time = pcoreytohll ( & s_ptr [ vwr -> ENDT_OFF ] ); 78
d_time = ( guint32 ) ( ( e_time - s_time ) ); 81
start_time = s_time / NS_IN_US; 84
s_sec = ( start_time / US_IN_SEC ); 85
s_usec = start_time - ( s_sec * US_IN_SEC ); 86
end_time = e_time / NS_IN_US; 89
if ( frame_type & vwr -> IS_TCP )  91
pay_off = mac_len + 40; 93
if ( frame_type & vwr -> IS_UDP )  95
pay_off = mac_len + 28; 97
if ( frame_type & vwr -> IS_ICMP )  99
pay_off = mac_len + 24; 101
if ( frame_type & vwr -> IS_IGMP )  103
pay_off = mac_len + 28; 105
pay_off = mac_len + 20; 109
sig_off = find_signature ( m_ptr , pay_off , flow_id , flow_seq ); 112
if ( ( m_ptr [ sig_off ] == 0xdd ) && ( sig_off + 15 <= msdu_length ) && ( f_flow != 0 ) )  113
sig_ts = get_signature_ts ( m_ptr , sig_off ); 114
if ( sig_ts < s_time )  120
latency = ( guint32 ) ( s_time - sig_ts ); 121
delta_b = sig_ts - s_time; 125
if ( delta_b > 0x10000000 )  126
latency = ( guint32 ) delta_b; 129
wth -> phdr . len = ( actual_octets - 4 ) + e_hdr_len; 139
wth -> phdr . caplen = ( msdu_length - 4 ) + e_hdr_len; 140
wth -> phdr . presence_flags = WTAP_HAS_TS; 142
wth -> phdr . ts . secs = ( time_t ) s_sec; 144
wth -> phdr . ts . nsecs = ( long ) ( s_usec * 1000 ); 145
wth -> phdr . pkt_encap = WTAP_ENCAP_IXVERIWAVE; 146
etap_hdr . vw_errors = ( guint32 ) errors; 153
etap_hdr . vw_info = ( guint16 ) info; 154
common_hdr . vw_msdu_length = ( guint16 ) msdu_length; 155
common_hdr . vw_flowid = ( guint32 ) flow_id; 158
common_hdr . vw_vcid = ( guint16 ) vc_id; 159
common_hdr . vw_seqnum = ( guint16 ) flow_seq; 160
if ( ! IS_TX && ( sig_ts != 0 ) )  162
common_hdr . vw_latency = ( guint32 ) latency; 163
common_hdr . vw_latency = 0; 165
common_hdr . vw_pktdur = ( guint32 ) d_time; 166
etap_hdr . vw_l4id = ( guint32 ) l4id; 167
etap_hdr . vw_flags = 0; 168
etap_hdr . vw_flags |= RADIOTAP_VWF_TXF; 170
if ( errors & vwr -> FCS_ERROR )  171
etap_hdr . vw_flags |= RADIOTAP_VWF_FCSERR; 172
common_hdr . vw_startt = start_time; 173
common_hdr . vw_endt = end_time; 174
common_hdr . vw_sig_ts = ( guint32 ) ( sig_ts ); 175
etap_hdr . it_pad2 = 0; 177
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_port_type ); 180
phtoles ( & data_ptr [ bytes_written ] , common_hdr . it_len ); 182
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_msdu_length ); 184
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_flowid ); 189
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_vcid ); 191
phtoles ( & data_ptr [ bytes_written ] , common_hdr . vw_seqnum ); 193
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_latency ); 195
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_sig_ts ); 197
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_startt ); 199
phtolell ( & data_ptr [ bytes_written ] , common_hdr . vw_endt ); 201
phtolel ( & data_ptr [ bytes_written ] , common_hdr . vw_pktdur ); 203
phtoles ( & data_ptr [ bytes_written ] , etap_hdr . it_len ); 210
phtoles ( & data_ptr [ bytes_written ] , etap_hdr . vw_flags ); 212
phtoles ( & data_ptr [ bytes_written ] , etap_hdr . vw_info ); 214
phtolel ( & data_ptr [ bytes_written ] , etap_hdr . vw_errors ); 219
phtolel ( & data_ptr [ bytes_written ] , etap_hdr . vw_l4id ); 221
if ( rec_size < ( ( int ) actual_octets + ( int ) vwr -> STATS_LEN ) )  228
memcpy ( & data_ptr [ bytes_written ] , m_ptr , msdu_length ); 230
if ( msdu_length >= 4 )  231
memcpy ( & data_ptr [ bytes_written ] , m_ptr , msdu_length - 4 ); 232
memcpy ( & data_ptr [ bytes_written ] , m_ptr , msdu_length ); 234
------------------------------
33 ../data/NVD/CVE_2012_4530_PATCHED_load_script.c cp = bprm -> buf + BINPRM_BUF_SIZE - 1 23
static int CVE_2012_4530_PATCHED_load_script(struct linux_binprm *bprm,struct pt_regs *regs) 1
char * cp , * i_name , * i_arg ; 3
if ( ( bprm -> buf [ 0 ] != '#' ) || ( bprm -> buf [ 1 ] != '!' ) || ( bprm -> recursion_depth > BINPRM_MAX_RECURSION ) )  8
bprm -> recursion_depth ++; 16
bprm -> file = NULL; 19
bprm -> buf [ BINPRM_BUF_SIZE - 1 ] = '\0'; 21
if ( ( cp = strchr ( bprm -> buf , '\n' ) ) == NULL )  22
cp = bprm -> buf + BINPRM_BUF_SIZE - 1; 23
* cp = '\0'; 24
while ( cp > bprm -> buf )  25
cp --; 26
if ( ( * cp == ' ' ) || ( * cp == '\t' ) )  27
* cp = '\0'; 28
for (cp = bprm->buf+2; (*cp == ' ') || (*cp == '\t'); cp++); 32
if ( * cp == '\0' )  33
i_name = cp; 35
for ( ; *cp && (*cp != ' ') && (*cp != '\t'); cp++) 37
while ( ( * cp == ' ' ) || ( * cp == '\t' ) )  39
* cp ++ = '\0'; 40
if ( * cp )  41
i_arg = cp; 42
strcpy ( interp , i_name ); 43
if ( i_arg )  60
retval = copy_strings_kernel ( 1 , & i_arg , bprm ); 61
if ( retval < 0 )  62
return retval ; 62
retval = copy_strings_kernel ( 1 , & i_name , bprm ); 65
if ( retval )  66
return retval ; 66
retval = bprm_change_interp ( interp , bprm ); 68
if ( retval < 0 )  69
return retval ; 70
file = open_exec ( interp ); 75
if ( IS_ERR ( file ) )  76
return PTR_ERR ( file ) ; 77
bprm -> file = file; 79
retval = prepare_binprm ( bprm ); 80
if ( retval < 0 )  81
return retval ; 82
return search_binary_handler ( bprm , regs ) ; 83
------------------------------
34 ../data/NVD/CVE_2012_4530_VULN_load_script.c cp = bprm -> buf + BINPRM_BUF_SIZE - 1 23
static int CVE_2012_4530_VULN_load_script(struct linux_binprm *bprm,struct pt_regs *regs) 1
char * cp , * i_name , * i_arg ; 3
if ( ( bprm -> buf [ 0 ] != '#' ) || ( bprm -> buf [ 1 ] != '!' ) || ( bprm -> recursion_depth > BINPRM_MAX_RECURSION ) )  8
bprm -> recursion_depth ++; 16
bprm -> file = NULL; 19
bprm -> buf [ BINPRM_BUF_SIZE - 1 ] = '\0'; 21
if ( ( cp = strchr ( bprm -> buf , '\n' ) ) == NULL )  22
cp = bprm -> buf + BINPRM_BUF_SIZE - 1; 23
* cp = '\0'; 24
while ( cp > bprm -> buf )  25
cp --; 26
if ( ( * cp == ' ' ) || ( * cp == '\t' ) )  27
* cp = '\0'; 28
for (cp = bprm->buf+2; (*cp == ' ') || (*cp == '\t'); cp++); 32
if ( * cp == '\0' )  33
i_name = cp; 35
for ( ; *cp && (*cp != ' ') && (*cp != '\t'); cp++) 37
while ( ( * cp == ' ' ) || ( * cp == '\t' ) )  39
* cp ++ = '\0'; 40
if ( * cp )  41
i_arg = cp; 42
strcpy ( interp , i_name ); 43
if ( i_arg )  60
retval = copy_strings_kernel ( 1 , & i_arg , bprm ); 61
if ( retval < 0 )  62
return retval ; 62
retval = copy_strings_kernel ( 1 , & i_name , bprm ); 65
if ( retval )  66
return retval ; 66
bprm -> interp = interp; 68
file = open_exec ( interp ); 73
if ( IS_ERR ( file ) )  74
return PTR_ERR ( file ) ; 75
bprm -> file = file; 77
retval = prepare_binprm ( bprm ); 78
if ( retval < 0 )  79
return retval ; 80
return search_binary_handler ( bprm , regs ) ; 81
------------------------------
35 ../data/NVD/CVE_2012_5237_PATCHED_dissect_hsrp.c offset = offset2 + len + 2 274
static int
CVE_2012_5237_PATCHED_dissect_hsrp(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
gchar dst [ 16 ] ; 5
if ( pinfo -> destport != UDP_PORT_HSRP && pinfo -> destport != UDP_PORT_HSRP2_V6 )  11
if ( pinfo -> dst . type == AT_IPv4 && strcmp ( dst , HSRP_DST_IP_ADDR ) == 0 )  19
if ( ( pinfo -> dst . type == AT_IPv4 && strcmp ( dst , HSRP2_DST_IP_ADDR ) == 0 ) || ( pinfo -> dst . type == AT_IPv6 && pinfo -> destport == UDP_PORT_HSRP2_V6 ) )  109
guint offset = 0 , offset2 ; 112
guint8 type , len ; 115
while ( tvb_reported_length_remaining ( tvb , offset ) > 0 )  124
type = tvb_get_guint8 ( tvb , offset ); 125
len = tvb_get_guint8 ( tvb , offset + 1 ); 126
offset2 = offset; 128
if ( type == 1 && len == 40 )  129
ti = proto_tree_add_uint_format ( hsrp_tree , hf_hsrp2_group_state_tlv , tvb , offset , 2 , type , "Group State TLV: Type=%d Len=%d" , type , len ); 136
offset += 2; 139
opcode = tvb_get_guint8 ( tvb , offset + 1 ); 141
col_add_fstr ( pinfo -> cinfo , COL_INFO , "%s" , val_to_str ( opcode , hsrp2_opcode_vals , "Unknown" ) ); 143
state = tvb_get_guint8 ( tvb , offset + 2 ); 147
col_append_fstr ( pinfo -> cinfo , COL_INFO , " (state %s)" , val_to_str ( state , hsrp2_state_vals , "Unknown" ) ); 149
if ( tree )  153
group_state_tlv = proto_item_add_subtree ( ti , ett_hsrp2_group_state_tlv ); 155
proto_tree_add_item ( group_state_tlv , hf_hsrp2_version , tvb , offset , 1 , ENC_BIG_ENDIAN ); 156
offset ++; 157
proto_tree_add_uint ( group_state_tlv , hf_hsrp2_opcode , tvb , offset , 1 , opcode ); 158
offset ++; 159
proto_tree_add_uint ( group_state_tlv , hf_hsrp2_state , tvb , offset , 1 , state ); 160
offset ++; 161
ipver = tvb_get_guint8 ( tvb , offset ); 162
proto_tree_add_uint ( group_state_tlv , hf_hsrp2_ipversion , tvb , offset , 1 , ipver ); 163
offset ++; 164
proto_tree_add_item ( group_state_tlv , hf_hsrp2_group , tvb , offset , 2 , ENC_BIG_ENDIAN ); 165
offset += 2; 166
proto_tree_add_item ( group_state_tlv , hf_hsrp2_identifier , tvb , offset , 6 , ENC_NA ); 167
offset += 6; 168
proto_tree_add_item ( group_state_tlv , hf_hsrp2_priority , tvb , offset , 4 , ENC_BIG_ENDIAN ); 169
offset += 4; 170
hellotime = tvb_get_ntohl ( tvb , offset ); 172
proto_tree_add_uint_format ( group_state_tlv , hf_hsrp2_hellotime , tvb , offset , 4 , hellotime , "Hellotime: %sDefault (%u)" , ( hellotime == HSRP2_DEFAULT_HELLOTIME ) ? "" : "Non-" , hellotime ); 173
offset += 4; 177
holdtime = tvb_get_ntohl ( tvb , offset ); 178
proto_tree_add_uint_format ( group_state_tlv , hf_hsrp2_holdtime , tvb , offset , 4 , holdtime , "Holdtime: %sDefault (%u)" , ( holdtime == HSRP2_DEFAULT_HOLDTIME ) ? "" : "Non-" , holdtime ); 179
offset += 4; 183
if ( ipver == 4 )  184
proto_tree_add_item ( group_state_tlv , hf_hsrp2_virt_ip_addr , tvb , offset , 4 , ENC_BIG_ENDIAN ); 186
if ( ipver == 6 )  187
proto_tree_add_item ( group_state_tlv , hf_hsrp2_virt_ip_addr_v6 , tvb , offset , 16 , ENC_NA ); 189
next_tvb = tvb_new_subset_remaining ( tvb , offset ); 192
call_dissector ( data_handle , next_tvb , pinfo , hsrp_tree ); 193
if ( type == 2 && len == 4 )  198
active = tvb_get_ntohs ( tvb , offset + 2 ); 201
passive = tvb_get_ntohs ( tvb , offset + 4 ); 202
col_add_fstr ( pinfo -> cinfo , COL_INFO , "Interface State TLV (Act=%d Pass=%d)" , active , passive ); 205
ti = proto_tree_add_uint_format ( hsrp_tree , hf_hsrp2_interface_state_tlv , tvb , offset , 1 , type , "Interface State TLV: Type=%d Len=%d" , type , len ); 210
offset += 2; 212
interface_state_tlv = proto_item_add_subtree ( ti , ett_hsrp2_interface_state_tlv ); 215
proto_tree_add_item ( interface_state_tlv , hf_hsrp2_active_group , tvb , offset , 2 , ENC_BIG_ENDIAN ); 216
offset += 2; 217
proto_tree_add_item ( interface_state_tlv , hf_hsrp2_passive_group , tvb , offset , 2 , ENC_BIG_ENDIAN ); 218
if ( type == 3 && len == 8 )  221
ti = proto_tree_add_uint_format ( hsrp_tree , hf_hsrp2_text_auth_tlv , tvb , offset , 1 , type , "Text Authentication TLV: Type=%d Len=%d" , type , len ); 227
offset += 2; 229
text_auth_tlv = proto_item_add_subtree ( ti , ett_hsrp2_text_auth_tlv ); 232
tvb_memcpy ( tvb , auth_buf , offset , 8 ); 234
proto_tree_add_string_format ( text_auth_tlv , hf_hsrp2_auth_data , tvb , offset , 8 , auth_buf , "Authentication Data: %sDefault (%s)" , ( tvb_strneql ( tvb , offset , "cisco" , strlen ( "cisco" ) ) ) == 0 ? "" : "Non-" , auth_buf ); 236
if ( type == 4 && len == 28 )  242
ti = proto_tree_add_uint_format ( hsrp_tree , hf_hsrp2_text_auth_tlv , tvb , offset , 1 , type , "MD5 Authentication TLV: Type=%d Len=%d" , type , len ); 247
offset += 2; 249
md5_auth_tlv = proto_item_add_subtree ( ti , ett_hsrp2_md5_auth_tlv ); 252
proto_tree_add_item ( md5_auth_tlv , hf_hsrp2_md5_algorithm , tvb , offset , 1 , ENC_BIG_ENDIAN ); 253
offset ++; 254
offset ++; 256
proto_tree_add_item ( md5_auth_tlv , hf_hsrp2_md5_flags , tvb , offset , 2 , ENC_BIG_ENDIAN ); 257
offset += 2; 258
proto_tree_add_item ( md5_auth_tlv , hf_hsrp2_md5_ip_address , tvb , offset , 4 , ENC_BIG_ENDIAN ); 259
offset += 4; 260
proto_tree_add_item ( md5_auth_tlv , hf_hsrp2_md5_key_id , tvb , offset , 4 , ENC_BIG_ENDIAN ); 261
offset += 4; 262
proto_tree_add_item ( md5_auth_tlv , hf_hsrp2_md5_auth_data , tvb , offset , 16 , ENC_BIG_ENDIAN ); 263
next_tvb = tvb_new_subset_remaining ( tvb , offset ); 269
call_dissector ( data_handle , next_tvb , pinfo , hsrp_tree ); 270
offset = offset2 + len + 2; 274
------------------------------
36 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c bitmap_size = glyph -> bpr * glyph -> bbx . height 456
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  328
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  344
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  372
if ( ft_memcmp ( line , "BITMAP" , 6 ) == 0 )  440
unsigned long bitmap_size ; 442
if ( ! ( p -> flags & _BDF_BBX ) )  445
glyph -> bpr = ( glyph -> bbx . width * p -> font -> bpp + 7 ) >> 3; 454
bitmap_size = glyph -> bpr * glyph -> bbx . height; 456
if ( glyph -> bpr > 0xFFFFU || bitmap_size > 0xFFFFU )  457
glyph -> bytes = ( unsigned short ) bitmap_size; 464
if ( FT_NEW_ARRAY ( glyph -> bitmap , glyph -> bytes ) )  466
------------------------------
37 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c glyph -> bpr = ( glyph -> bbx . width * p -> font -> bpp + 7 ) >> 3 454
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  328
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  344
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  372
if ( ft_memcmp ( line , "BITMAP" , 6 ) == 0 )  440
if ( ! ( p -> flags & _BDF_BBX ) )  445
glyph -> bpr = ( glyph -> bbx . width * p -> font -> bpp + 7 ) >> 3; 454
bitmap_size = glyph -> bpr * glyph -> bbx . height; 456
if ( glyph -> bpr > 0xFFFFU || bitmap_size > 0xFFFFU )  457
glyph -> bytes = ( unsigned short ) bitmap_size; 464
if ( FT_NEW_ARRAY ( glyph -> bitmap , glyph -> bytes ) )  466
------------------------------
38 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ) 395
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  328
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  344
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  372
if ( ! ( p -> flags & _BDF_ENCODING ) )  374
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 377
if ( error )  378
glyph -> bbx . width = _bdf_atos ( p -> list . field [ 1 ] , 0 , 10 ); 381
glyph -> bbx . height = _bdf_atos ( p -> list . field [ 2 ] , 0 , 10 ); 382
glyph -> bbx . x_offset = _bdf_atos ( p -> list . field [ 3 ] , 0 , 10 ); 383
glyph -> bbx . y_offset = _bdf_atos ( p -> list . field [ 4 ] , 0 , 10 ); 384
glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ); 387
glyph -> bbx . descent = ( short ) ( - glyph -> bbx . y_offset ); 388
p -> maxas = ( short ) FT_MAX ( glyph -> bbx . ascent , p -> maxas ); 392
p -> maxds = ( short ) FT_MAX ( glyph -> bbx . descent , p -> maxds ); 393
p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ); 395
p -> maxrb = ( short ) FT_MAX ( p -> rbearing , p -> maxrb ); 397
p -> minlb = ( short ) FT_MIN ( glyph -> bbx . x_offset , p -> minlb ); 398
p -> maxlb = ( short ) FT_MAX ( glyph -> bbx . x_offset , p -> maxlb ); 399
if ( ! ( p -> flags & _BDF_DWIDTH ) )  401
if ( p -> opts -> correct_metrics != 0 )  411
if ( p -> glyph_enc == - 1 )  424
p -> flags |= _BDF_SWIDTH_ADJ; 430
p -> flags |= _BDF_BBX; 435
if ( error && ( p -> flags & _BDF_GLYPH ) )  485
FT_FREE ( p -> glyph_name ); 486
------------------------------
39 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ) 387
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  328
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  344
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  372
if ( ! ( p -> flags & _BDF_ENCODING ) )  374
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 377
if ( error )  378
glyph -> bbx . width = _bdf_atos ( p -> list . field [ 1 ] , 0 , 10 ); 381
glyph -> bbx . height = _bdf_atos ( p -> list . field [ 2 ] , 0 , 10 ); 382
glyph -> bbx . x_offset = _bdf_atos ( p -> list . field [ 3 ] , 0 , 10 ); 383
glyph -> bbx . y_offset = _bdf_atos ( p -> list . field [ 4 ] , 0 , 10 ); 384
glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ); 387
glyph -> bbx . descent = ( short ) ( - glyph -> bbx . y_offset ); 388
p -> maxas = ( short ) FT_MAX ( glyph -> bbx . ascent , p -> maxas ); 392
p -> maxds = ( short ) FT_MAX ( glyph -> bbx . descent , p -> maxds ); 393
p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ); 395
p -> maxrb = ( short ) FT_MAX ( p -> rbearing , p -> maxrb ); 397
p -> minlb = ( short ) FT_MIN ( glyph -> bbx . x_offset , p -> minlb ); 398
p -> maxlb = ( short ) FT_MAX ( glyph -> bbx . x_offset , p -> maxlb ); 399
if ( ! ( p -> flags & _BDF_DWIDTH ) )  401
glyph -> dwidth = glyph -> bbx . width; 406
if ( p -> opts -> correct_metrics != 0 )  411
unsigned short sw = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) ; 414
if ( sw != glyph -> swidth )  420
glyph -> swidth = sw; 422
if ( p -> glyph_enc == - 1 )  424
_bdf_set_glyph_modified ( font -> nmod , glyph -> encoding ); 428
p -> flags |= _BDF_SWIDTH_ADJ; 430
p -> flags |= _BDF_BBX; 435
if ( error && ( p -> flags & _BDF_GLYPH ) )  485
FT_FREE ( p -> glyph_name ); 486
------------------------------
40 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c glyph -> swidth = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) 361
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  328
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  344
if ( ! ( p -> flags & _BDF_ENCODING ) )  346
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 349
if ( error )  350
glyph -> dwidth = ( unsigned short ) _bdf_atoul ( p -> list . field [ 1 ] , 0 , 10 ); 353
if ( ! ( p -> flags & _BDF_SWIDTH ) )  355
glyph -> swidth = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ); 361
------------------------------
41 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c mask_index = ( glyph -> bbx . width * p -> font -> bpp ) & 7 309
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
int c , mask_index ; 8
unsigned long i , slen , nibbles ; 11
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( p -> row >= ( unsigned long ) glyph -> bbx . height )  271
nibbles = glyph -> bpr << 1; 285
for ( i = 0; i < nibbles; i++ ) 288
c = line [ i ]; 290
if ( ! isdigok ( hdigits , c ) )  291
if ( i < nibbles && ! ( p -> flags & _BDF_GLYPH_WIDTH_CHECK ) )  300
p -> flags |= _BDF_GLYPH_WIDTH_CHECK; 304
mask_index = ( glyph -> bbx . width * p -> font -> bpp ) & 7; 309
* bp &= nibble_mask [ mask_index ]; 311
------------------------------
42 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c bp = glyph -> bitmap + p -> row * glyph -> bpr 286
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
unsigned char * bp ; 10
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( p -> row >= ( unsigned long ) glyph -> bbx . height )  271
bp = glyph -> bitmap + p -> row * glyph -> bpr; 286
* bp = ( FT_Byte ) ( ( * bp << 4 ) + a2i [ c ] ); 293
* ++ bp = 0; 295
* bp &= nibble_mask [ mask_index ]; 311
------------------------------
43 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c glyph = font -> unencoded + font -> unencoded_used 239
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( ! ( p -> flags & _BDF_GLYPH ) )  147
error = BDF_Err_Missing_Startchar_Field; 151
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 155
if ( error )  156
p -> glyph_enc = _bdf_atol ( p -> list . field [ 1 ] , 0 , 10 ); 159
if ( p -> glyph_enc < - 1 )  163
p -> glyph_enc = - 1; 164
if ( p -> glyph_enc == - 1 && p -> list . used > 2 )  167
p -> glyph_enc = _bdf_atol ( p -> list . field [ 2 ] , 0 , 10 ); 168
if ( p -> glyph_enc > 0 && ( size_t ) p -> glyph_enc >= sizeof ( p -> have ) / sizeof ( unsigned long ) * 32 )  174
if ( p -> glyph_enc >= 0 )  186
if ( _bdf_glyph_modified ( p -> have , p -> glyph_enc ) )  188
p -> glyph_enc = - 1; 194
font -> modified = 1; 195
if ( p -> glyph_enc >= 0 )  201
if ( p -> opts -> keep_unencoded != 0 )  226
if ( font -> unencoded_used == font -> unencoded_size )  229
if ( FT_RENEW_ARRAY ( font -> unencoded , font -> unencoded_size , font -> unencoded_size + 4 ) )  231
font -> unencoded_size += 4; 236
glyph = font -> unencoded + font -> unencoded_used; 239
glyph -> name = p -> glyph_name; 240
glyph -> encoding = font -> unencoded_used ++; 241
------------------------------
44 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c glyph = font -> glyphs + font -> glyphs_used ++ 215
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( ! ( p -> flags & _BDF_GLYPH ) )  147
error = BDF_Err_Missing_Startchar_Field; 151
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 155
if ( error )  156
p -> glyph_enc = _bdf_atol ( p -> list . field [ 1 ] , 0 , 10 ); 159
if ( p -> glyph_enc < - 1 )  163
p -> glyph_enc = - 1; 164
if ( p -> glyph_enc == - 1 && p -> list . used > 2 )  167
p -> glyph_enc = _bdf_atol ( p -> list . field [ 2 ] , 0 , 10 ); 168
if ( p -> glyph_enc > 0 && ( size_t ) p -> glyph_enc >= sizeof ( p -> have ) / sizeof ( unsigned long ) * 32 )  174
if ( p -> glyph_enc >= 0 )  186
if ( _bdf_glyph_modified ( p -> have , p -> glyph_enc ) )  188
p -> glyph_enc = - 1; 194
font -> modified = 1; 195
if ( p -> glyph_enc >= 0 )  201
if ( font -> glyphs_used == font -> glyphs_size )  205
if ( FT_RENEW_ARRAY ( font -> glyphs , font -> glyphs_size , font -> glyphs_size + 64 ) )  207
font -> glyphs_size += 64; 212
glyph = font -> glyphs + font -> glyphs_used ++; 215
glyph -> name = p -> glyph_name; 216
glyph -> encoding = p -> glyph_enc; 217
------------------------------
45 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c bitmap_size = glyph -> bpr * glyph -> bbx . height 455
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  327
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  343
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  371
if ( ft_memcmp ( line , "BITMAP" , 6 ) == 0 )  439
unsigned long bitmap_size ; 441
if ( ! ( p -> flags & _BDF_BBX ) )  444
glyph -> bpr = ( glyph -> bbx . width * p -> font -> bpp + 7 ) >> 3; 453
bitmap_size = glyph -> bpr * glyph -> bbx . height; 455
if ( glyph -> bpr > 0xFFFFU || bitmap_size > 0xFFFFU )  456
glyph -> bytes = ( unsigned short ) bitmap_size; 463
if ( FT_NEW_ARRAY ( glyph -> bitmap , glyph -> bytes ) )  465
------------------------------
46 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c glyph -> bpr = ( glyph -> bbx . width * p -> font -> bpp + 7 ) >> 3 453
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  327
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  343
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  371
if ( ft_memcmp ( line , "BITMAP" , 6 ) == 0 )  439
if ( ! ( p -> flags & _BDF_BBX ) )  444
glyph -> bpr = ( glyph -> bbx . width * p -> font -> bpp + 7 ) >> 3; 453
bitmap_size = glyph -> bpr * glyph -> bbx . height; 455
if ( glyph -> bpr > 0xFFFFU || bitmap_size > 0xFFFFU )  456
glyph -> bytes = ( unsigned short ) bitmap_size; 463
if ( FT_NEW_ARRAY ( glyph -> bitmap , glyph -> bytes ) )  465
------------------------------
47 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ) 394
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  327
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  343
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  371
if ( ! ( p -> flags & _BDF_ENCODING ) )  373
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 376
if ( error )  377
glyph -> bbx . width = _bdf_atos ( p -> list . field [ 1 ] , 0 , 10 ); 380
glyph -> bbx . height = _bdf_atos ( p -> list . field [ 2 ] , 0 , 10 ); 381
glyph -> bbx . x_offset = _bdf_atos ( p -> list . field [ 3 ] , 0 , 10 ); 382
glyph -> bbx . y_offset = _bdf_atos ( p -> list . field [ 4 ] , 0 , 10 ); 383
glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ); 386
glyph -> bbx . descent = ( short ) ( - glyph -> bbx . y_offset ); 387
p -> maxas = ( short ) FT_MAX ( glyph -> bbx . ascent , p -> maxas ); 391
p -> maxds = ( short ) FT_MAX ( glyph -> bbx . descent , p -> maxds ); 392
p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ); 394
p -> maxrb = ( short ) FT_MAX ( p -> rbearing , p -> maxrb ); 396
p -> minlb = ( short ) FT_MIN ( glyph -> bbx . x_offset , p -> minlb ); 397
p -> maxlb = ( short ) FT_MAX ( glyph -> bbx . x_offset , p -> maxlb ); 398
if ( ! ( p -> flags & _BDF_DWIDTH ) )  400
if ( p -> opts -> correct_metrics != 0 )  410
if ( p -> glyph_enc == - 1 )  423
p -> flags |= _BDF_SWIDTH_ADJ; 429
p -> flags |= _BDF_BBX; 434
if ( error && ( p -> flags & _BDF_GLYPH ) )  484
FT_FREE ( p -> glyph_name ); 485
------------------------------
48 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ) 386
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  327
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  343
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  371
if ( ! ( p -> flags & _BDF_ENCODING ) )  373
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 376
if ( error )  377
glyph -> bbx . width = _bdf_atos ( p -> list . field [ 1 ] , 0 , 10 ); 380
glyph -> bbx . height = _bdf_atos ( p -> list . field [ 2 ] , 0 , 10 ); 381
glyph -> bbx . x_offset = _bdf_atos ( p -> list . field [ 3 ] , 0 , 10 ); 382
glyph -> bbx . y_offset = _bdf_atos ( p -> list . field [ 4 ] , 0 , 10 ); 383
glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ); 386
glyph -> bbx . descent = ( short ) ( - glyph -> bbx . y_offset ); 387
p -> maxas = ( short ) FT_MAX ( glyph -> bbx . ascent , p -> maxas ); 391
p -> maxds = ( short ) FT_MAX ( glyph -> bbx . descent , p -> maxds ); 392
p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ); 394
p -> maxrb = ( short ) FT_MAX ( p -> rbearing , p -> maxrb ); 396
p -> minlb = ( short ) FT_MIN ( glyph -> bbx . x_offset , p -> minlb ); 397
p -> maxlb = ( short ) FT_MAX ( glyph -> bbx . x_offset , p -> maxlb ); 398
if ( ! ( p -> flags & _BDF_DWIDTH ) )  400
glyph -> dwidth = glyph -> bbx . width; 405
if ( p -> opts -> correct_metrics != 0 )  410
unsigned short sw = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) ; 413
if ( sw != glyph -> swidth )  419
glyph -> swidth = sw; 421
if ( p -> glyph_enc == - 1 )  423
_bdf_set_glyph_modified ( font -> nmod , glyph -> encoding ); 427
p -> flags |= _BDF_SWIDTH_ADJ; 429
p -> flags |= _BDF_BBX; 434
if ( error && ( p -> flags & _BDF_GLYPH ) )  484
FT_FREE ( p -> glyph_name ); 485
------------------------------
49 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c glyph -> swidth = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) 360
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  327
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  343
if ( ! ( p -> flags & _BDF_ENCODING ) )  345
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 348
if ( error )  349
glyph -> dwidth = ( unsigned short ) _bdf_atoul ( p -> list . field [ 1 ] , 0 , 10 ); 352
if ( ! ( p -> flags & _BDF_SWIDTH ) )  354
glyph -> swidth = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ); 360
------------------------------
50 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c mask_index = ( glyph -> bbx . width * p -> font -> bpp ) & 7 308
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
int c , mask_index ; 8
unsigned long i , slen , nibbles ; 11
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( p -> row >= ( unsigned long ) glyph -> bbx . height )  270
nibbles = glyph -> bpr << 1; 284
for ( i = 0; i < nibbles; i++ ) 287
c = line [ i ]; 289
if ( ! isdigok ( hdigits , c ) )  290
if ( i < nibbles && ! ( p -> flags & _BDF_GLYPH_WIDTH_CHECK ) )  299
p -> flags |= _BDF_GLYPH_WIDTH_CHECK; 303
mask_index = ( glyph -> bbx . width * p -> font -> bpp ) & 7; 308
* bp &= nibble_mask [ mask_index ]; 310
------------------------------
51 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c bp = glyph -> bitmap + p -> row * glyph -> bpr 285
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
unsigned char * bp ; 10
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( p -> row >= ( unsigned long ) glyph -> bbx . height )  270
bp = glyph -> bitmap + p -> row * glyph -> bpr; 285
* bp = ( FT_Byte ) ( ( * bp << 4 ) + a2i [ c ] ); 292
* ++ bp = 0; 294
* bp &= nibble_mask [ mask_index ]; 310
------------------------------
52 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c glyph = font -> unencoded + font -> unencoded_used 238
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( ! ( p -> flags & _BDF_GLYPH ) )  147
error = BDF_Err_Missing_Startchar_Field; 151
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 155
if ( error )  156
p -> glyph_enc = _bdf_atol ( p -> list . field [ 1 ] , 0 , 10 ); 159
if ( p -> glyph_enc < - 1 )  163
p -> glyph_enc = - 1; 164
if ( p -> glyph_enc == - 1 && p -> list . used > 2 )  167
p -> glyph_enc = _bdf_atol ( p -> list . field [ 2 ] , 0 , 10 ); 168
if ( p -> glyph_enc > 0 && ( size_t ) p -> glyph_enc >= sizeof ( p -> have ) * 8 )  174
if ( p -> glyph_enc >= 0 )  185
if ( _bdf_glyph_modified ( p -> have , p -> glyph_enc ) )  187
p -> glyph_enc = - 1; 193
font -> modified = 1; 194
if ( p -> glyph_enc >= 0 )  200
if ( p -> opts -> keep_unencoded != 0 )  225
if ( font -> unencoded_used == font -> unencoded_size )  228
if ( FT_RENEW_ARRAY ( font -> unencoded , font -> unencoded_size , font -> unencoded_size + 4 ) )  230
font -> unencoded_size += 4; 235
glyph = font -> unencoded + font -> unencoded_used; 238
glyph -> name = p -> glyph_name; 239
glyph -> encoding = font -> unencoded_used ++; 240
------------------------------
53 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c glyph = font -> glyphs + font -> glyphs_used ++ 214
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( ! ( p -> flags & _BDF_GLYPH ) )  147
error = BDF_Err_Missing_Startchar_Field; 151
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 155
if ( error )  156
p -> glyph_enc = _bdf_atol ( p -> list . field [ 1 ] , 0 , 10 ); 159
if ( p -> glyph_enc < - 1 )  163
p -> glyph_enc = - 1; 164
if ( p -> glyph_enc == - 1 && p -> list . used > 2 )  167
p -> glyph_enc = _bdf_atol ( p -> list . field [ 2 ] , 0 , 10 ); 168
if ( p -> glyph_enc > 0 && ( size_t ) p -> glyph_enc >= sizeof ( p -> have ) * 8 )  174
if ( p -> glyph_enc >= 0 )  185
if ( _bdf_glyph_modified ( p -> have , p -> glyph_enc ) )  187
p -> glyph_enc = - 1; 193
font -> modified = 1; 194
if ( p -> glyph_enc >= 0 )  200
if ( font -> glyphs_used == font -> glyphs_size )  204
if ( FT_RENEW_ARRAY ( font -> glyphs , font -> glyphs_size , font -> glyphs_size + 64 ) )  206
font -> glyphs_size += 64; 211
glyph = font -> glyphs + font -> glyphs_used ++; 214
glyph -> name = p -> glyph_name; 215
glyph -> encoding = p -> glyph_enc; 216
------------------------------
54 ../data/NVD/CVE_2012_6053_VULN_dissect_usb_interface_descriptor.c offset = old_offset + len 75
static int
CVE_2012_6053_VULN_dissect_usb_interface_descriptor(packet_info *pinfo, proto_tree *parent_tree, tvbuff_t *tvb, int offset, usb_trans_info_t *usb_trans_info, usb_conv_info_t *usb_conv_info) 2
int old_offset = offset ; 6
guint8 len ; 7
len = tvb_get_guint8 ( tvb , offset ); 16
offset = old_offset + len; 75
return offset ; 77
------------------------------
55 ../data/NVD/CVE_2012_6055_PATCHED_dissect_3gpp2_service_option_profile.c offset = offset + sub_type_length - 2 32
static const gchar *
CVE_2012_6055_PATCHED_dissect_3gpp2_service_option_profile(proto_tree  *tree, tvbuff_t  *tvb, packet_info *pinfo) 2
int offset = 0 ; 4
guint8 sub_type , sub_type_length ; 5
offset += 4; 10
while ( tvb_length_remaining ( tvb , offset ) > 0 )  12
sub_type_length = tvb_get_guint8 ( tvb , offset + 1 ); 13
sub_type = tvb_get_guint8 ( tvb , offset ); 15
proto_tree_add_item ( tree , hf_a11_sub_type , tvb , offset , 1 , ENC_BIG_ENDIAN ); 16
offset ++; 17
pi = proto_tree_add_item ( tree , hf_a11_sub_type_length , tvb , offset , 1 , ENC_BIG_ENDIAN ); 18
offset ++; 19
if ( sub_type_length < 2 )  20
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Sub-Type Length should be at least 2" ); 21
sub_type_length = 2; 22
if ( sub_type == 1 )  24
proto_tree_add_item ( tree , hf_a11_serv_opt , tvb , offset , 1 , ENC_BIG_ENDIAN ); 25
offset ++; 26
proto_tree_add_item ( tree , hf_a11_max_num_serv_opt , tvb , offset , 1 , ENC_BIG_ENDIAN ); 28
offset ++; 29
offset = offset + sub_type_length - 2; 32
------------------------------
56 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c dup_tsn_offset = SACK_CHUNK_GAP_BLOCK_OFFSET + number_of_gap_blocks * SACK_CHUNK_GAP_BLOCK_LENGTH 95
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
gint gap_block_offset , dup_tsn_offset ; 6
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
dup_tsn_offset = SACK_CHUNK_GAP_BLOCK_OFFSET + number_of_gap_blocks * SACK_CHUNK_GAP_BLOCK_LENGTH; 95
proto_tree_add_item ( chunk_tree , hf_sack_chunk_duplicate_tsn , chunk_tvb , dup_tsn_offset , SACK_CHUNK_DUP_TSN_LENGTH , ENC_BIG_ENDIAN ); 97
dup_tsn_offset += SACK_CHUNK_DUP_TSN_LENGTH; 98
------------------------------
57 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ) 59
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
proto_tree * block_tree ; 9
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
proto_item * pi ; 40
proto_tree * pt ; 41
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
58 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ) 57
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
proto_tree * block_tree ; 9
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
proto_item * pi ; 40
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
59 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ) 53
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
proto_tree * block_tree ; 9
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
proto_item * pi ; 40
proto_tree * pt ; 41
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
PROTO_ITEM_SET_GENERATED ( pi ); 55
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
60 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ) 48
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
PROTO_ITEM_SET_GENERATED ( pi ); 55
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
sctp_ack_block ( pinfo , ha , chunk_tvb , block_tree , & tsn_start , cum_tsn_ack + end ); 63
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
61 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c tsn_start = cum_tsn_ack + start 46
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
guint32 tsn_start ; 42
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
tsn_start = cum_tsn_ack + start; 46
sctp_ack_block ( pinfo , ha , chunk_tvb , block_tree , & tsn_start , cum_tsn_ack + end ); 63
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
------------------------------
62 ../data/NVD/CVE_2012_6056_PATCHED_dissect_sack_chunk.c end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ) 45
static void
CVE_2012_6056_PATCHED_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
PROTO_ITEM_SET_GENERATED ( pi ); 55
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
sctp_ack_block ( pinfo , ha , chunk_tvb , block_tree , & tsn_start , cum_tsn_ack + end ); 63
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
tsns_gap_acked += ( end + 1 - start ); 66
if ( start > end )  69
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
if ( last_end > start )  72
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
last_end = end; 75
if ( tsns_gap_acked )  78
pi = proto_tree_add_uint ( chunk_tree , hf_sack_chunk_number_tsns_gap_acked , chunk_tvb , 0 , 0 , tsns_gap_acked ); 81
PROTO_ITEM_SET_GENERATED ( pi ); 82
if ( tsns_gap_acked > 100 )  87
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
63 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c dup_tsn_offset = SACK_CHUNK_GAP_BLOCK_OFFSET + number_of_gap_blocks * SACK_CHUNK_GAP_BLOCK_LENGTH 95
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
gint gap_block_offset , dup_tsn_offset ; 6
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
dup_tsn_offset = SACK_CHUNK_GAP_BLOCK_OFFSET + number_of_gap_blocks * SACK_CHUNK_GAP_BLOCK_LENGTH; 95
proto_tree_add_item ( chunk_tree , hf_sack_chunk_duplicate_tsn , chunk_tvb , dup_tsn_offset , SACK_CHUNK_DUP_TSN_LENGTH , ENC_BIG_ENDIAN ); 97
dup_tsn_offset += SACK_CHUNK_DUP_TSN_LENGTH; 98
------------------------------
64 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ) 59
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
proto_tree * block_tree ; 9
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
proto_item * pi ; 40
proto_tree * pt ; 41
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
65 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ) 57
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
proto_tree * block_tree ; 9
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
proto_item * pi ; 40
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
66 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ) 53
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
proto_tree * block_tree ; 9
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
proto_item * pi ; 40
proto_tree * pt ; 41
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
PROTO_ITEM_SET_GENERATED ( pi ); 55
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
67 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ) 48
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
proto_item * block_item ; 8
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
PROTO_ITEM_SET_GENERATED ( pi ); 55
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
sctp_ack_block ( pinfo , ha , chunk_tvb , block_tree , & tsn_start , cum_tsn_ack + end ); 63
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
PROTO_ITEM_SET_GENERATED ( pi ); 82
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
68 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c tsn_start = cum_tsn_ack + start 46
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
guint32 cum_tsn_ack ; 7
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
cum_tsn_ack = tvb_get_ntohl ( chunk_tvb , SACK_CHUNK_CUMULATIVE_TSN_ACK_OFFSET ); 33
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
guint32 tsn_start ; 42
start = tvb_get_ntohs ( chunk_tvb , gap_block_offset ); 44
tsn_start = cum_tsn_ack + start; 46
sctp_ack_block ( pinfo , ha , chunk_tvb , block_tree , & tsn_start , cum_tsn_ack + end ); 63
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
------------------------------
69 ../data/NVD/CVE_2012_6056_VULN_dissect_sack_chunk.c end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ) 45
static void
CVE_2012_6056_VULN_dissect_sack_chunk(packet_info* pinfo, tvbuff_t *chunk_tvb, proto_tree *chunk_tree, proto_item *chunk_item, proto_item *flags_item, sctp_half_assoc_t* ha) 2
guint16 number_of_gap_blocks , number_of_dup_tsns ; 4
guint16 gap_block_number , dup_tsn_number , start , end ; 5
gint gap_block_offset , dup_tsn_offset ; 6
number_of_gap_blocks = tvb_get_ntohs ( chunk_tvb , SACK_CHUNK_NUMBER_OF_GAP_BLOCKS_OFFSET ); 31
gap_block_offset = SACK_CHUNK_GAP_BLOCK_OFFSET; 32
for(gap_block_number = 1; gap_block_number <= number_of_gap_blocks; gap_block_number++) 39
end = tvb_get_ntohs ( chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH ); 45
block_item = proto_tree_add_text ( chunk_tree , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_LENGTH , "Gap Acknowledgement for TSN %u to %u" , cum_tsn_ack + start , cum_tsn_ack + end ); 48
block_tree = proto_item_add_subtree ( block_item , ett_sctp_sack_chunk_gap_block ); 49
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_start , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , ENC_BIG_ENDIAN ); 51
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_start ); 52
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_start_tsn , chunk_tvb , gap_block_offset , SACK_CHUNK_GAP_BLOCK_START_LENGTH , cum_tsn_ack + start ); 53
PROTO_ITEM_SET_GENERATED ( pi ); 55
pi = proto_tree_add_item ( block_tree , hf_sack_chunk_gap_block_end , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , ENC_BIG_ENDIAN ); 57
pt = proto_item_add_subtree ( pi , ett_sctp_sack_chunk_gap_block_end ); 58
pi = proto_tree_add_uint ( pt , hf_sack_chunk_gap_block_end_tsn , chunk_tvb , gap_block_offset + SACK_CHUNK_GAP_BLOCK_START_LENGTH , SACK_CHUNK_GAP_BLOCK_END_LENGTH , cum_tsn_ack + end ); 59
PROTO_ITEM_SET_GENERATED ( pi ); 61
sctp_ack_block ( pinfo , ha , chunk_tvb , block_tree , & tsn_start , cum_tsn_ack + end ); 63
gap_block_offset += SACK_CHUNK_GAP_BLOCK_LENGTH; 64
tsns_gap_acked += ( end + 1 - start ); 66
if ( start > end )  69
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_ERROR , "Malformed gap block" ); 70
if ( last_end > start )  72
expert_add_info_format ( pinfo , pi , PI_PROTOCOL , PI_WARN , "Gap blocks not in strict order" ); 73
last_end = end; 75
if ( tsns_gap_acked )  78
pi = proto_tree_add_uint ( chunk_tree , hf_sack_chunk_number_tsns_gap_acked , chunk_tvb , 0 , 0 , tsns_gap_acked ); 81
PROTO_ITEM_SET_GENERATED ( pi ); 82
if ( tsns_gap_acked > 100 )  87
expert_add_info_format ( pinfo , pi , PI_SEQUENCE , PI_WARN , "More than 100 TSNs were gap-acknowledged in this SACK" ); 88
------------------------------
70 ../data/NVD/CVE_2012_6060_PATCHED_dissect_iscsi_pdu.c immediate_data_length = offset - immediate_data_offset 298
static void
CVE_2012_6060_PATCHED_dissect_iscsi_pdu(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset, guint8 opcode, const char *opcode_str, guint32 data_segment_len, iscsi_session_t *iscsi_session, conversation_t *conversation) 2
proto_tree * ti = NULL ; 5
guint end_offset = offset + tvb_length_remaining ( tvb , offset ) ; 9
if ( tree )  167
proto_item * tp ; 168
tp = proto_tree_add_protocol_format ( tree , proto_iscsi , tvb , offset , - 1 , "iSCSI (%s)" , opcode_str ); 170
ti = proto_item_add_subtree ( tp , ett_iscsi ); 173
if ( opcode == ISCSI_OPCODE_NOP_OUT )  192
if ( opcode == ISCSI_OPCODE_NOP_IN )  205
if ( opcode == ISCSI_OPCODE_SCSI_COMMAND )  219
guint32 ahsLen = tvb_get_guint8 ( tvb , offset + 4 ) * 4 ; 221
offset = handleHeaderDigest ( iscsi_session , ti , tvb , offset , 48 + ahsLen ); 294
immediate_data_offset = offset; 296
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_immediate_data ); 297
immediate_data_length = offset - immediate_data_offset; 298
if ( immediate_data_length )  899
if ( tvb_len > ( int ) immediate_data_length )  902
tvb_len = immediate_data_length; 903
if ( tvb_rlen > ( int ) immediate_data_length )  905
tvb_rlen = immediate_data_length; 906
data_tvb = tvb_new_subset ( tvb , immediate_data_offset , tvb_len , tvb_rlen ); 907
dissect_scsi_payload ( data_tvb , pinfo , tree , TRUE , & cdata -> itlq , itl , 0 ); 908
------------------------------
71 ../data/NVD/CVE_2012_6060_VULN_dissect_iscsi_pdu.c immediate_data_length = offset - immediate_data_offset 298
static void
CVE_2012_6060_VULN_dissect_iscsi_pdu(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset, guint8 opcode, const char *opcode_str, guint32 data_segment_len, iscsi_session_t *iscsi_session, conversation_t *conversation) 2
proto_tree * ti = NULL ; 5
guint end_offset = offset + tvb_length_remaining ( tvb , offset ) ; 9
if ( tree )  167
proto_item * tp ; 168
tp = proto_tree_add_protocol_format ( tree , proto_iscsi , tvb , offset , - 1 , "iSCSI (%s)" , opcode_str ); 170
ti = proto_item_add_subtree ( tp , ett_iscsi ); 173
if ( opcode == ISCSI_OPCODE_NOP_OUT )  192
if ( opcode == ISCSI_OPCODE_NOP_IN )  205
if ( opcode == ISCSI_OPCODE_SCSI_COMMAND )  219
guint32 ahsLen = tvb_get_guint8 ( tvb , offset + 4 ) * 4 ; 221
offset = handleHeaderDigest ( iscsi_session , ti , tvb , offset , 48 + ahsLen ); 294
immediate_data_offset = offset; 296
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_immediate_data ); 297
immediate_data_length = offset - immediate_data_offset; 298
if ( immediate_data_length )  899
if ( tvb_len > ( int ) immediate_data_length )  902
tvb_len = immediate_data_length; 903
if ( tvb_rlen > ( int ) immediate_data_length )  905
tvb_rlen = immediate_data_length; 906
data_tvb = tvb_new_subset ( tvb , immediate_data_offset , tvb_len , tvb_rlen ); 907
dissect_scsi_payload ( data_tvb , pinfo , tree , TRUE , & cdata -> itlq , itl , 0 ); 908
------------------------------
72 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c dataOffset = offCur + cbHeader + vHeader 359
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
guint vHeader = 0 ; 15
char pdut ; 22
int dataOffset ; 29
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
guint tpiLen ; 311
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
vHeader += tpiLen; 330
while ( tCon )  331
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
------------------------------
73 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ) 326
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
char pdut ; 22
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
guint tpiLen ; 311
tvbuff_t * tmp_tvb ; 312
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
if ( tree )  324
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
------------------------------
74 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ) 320
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
char pdut ; 22
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
guint tpiLen ; 311
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
proto_item_set_len ( ti , cbHeader + vHeader ); 339
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
------------------------------
75 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ) 317
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
char pdut ; 22
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
guint tpiLen ; 311
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
proto_item_set_len ( ti , cbHeader + vHeader ); 339
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
------------------------------
76 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ) 150
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
char * szInfo ; 4
int offCur = 0 ; 5
gint returned_length , str_index = 0 ; 6
unsigned char b0 ; 8
unsigned char fRID ; 12
char pdut ; 22
szInfo = ep_alloc ( SZINFO_SIZE ); 33
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fRID = retransmission_indicator ( b0 ); 85
pdut = pdu_type ( b0 ); 86
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
psn = 0; 104
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
if ( fRID )  149
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
------------------------------
77 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ) 118
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
char * szInfo ; 4
int offCur = 0 ; 5
gint returned_length , str_index = 0 ; 6
unsigned char b0 ; 8
char pdut ; 22
szInfo = ep_alloc ( SZINFO_SIZE ); 33
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
pdut = pdu_type ( b0 ); 86
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
psn = 0; 104
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
------------------------------
78 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ) 106
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
char * szInfo ; 4
int offCur = 0 ; 5
gint returned_length , str_index = 0 ; 6
unsigned char b0 ; 8
char pdut ; 22
szInfo = ep_alloc ( SZINFO_SIZE ); 33
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
pdut = pdu_type ( b0 ); 86
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
------------------------------
79 ../data/NVD/CVE_2012_6061_PATCHED_dissect_wtp_common.c wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ) 73
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
offCur = 1; 47
while ( offCur < ( int ) tvb_reported_length ( tvb ) )  49
tvbuff_t * wtp_tvb ; 50
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 57
if ( b0 & 0x80 )  58
c_fieldlen = 2; 59
c_pdulen = ( ( b0 & 0x7f ) << 8 ) | tvb_get_guint8 ( tvb , offCur + 1 ); 60
c_fieldlen = 1; 62
c_pdulen = b0; 63
wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ); 73
CVE_2012_6061_PATCHED_dissect_wtp_common ( wtp_tvb , pinfo , wtp_tree ); 74
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
if ( tree )  41
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 1 , ENC_NA ); 42
wtp_tree = proto_item_add_subtree ( ti , ett_wtp_sub_pdu_tree ); 44
proto_item_append_text ( ti , ", PDU concatenation" ); 45
while ( offCur < ( int ) tvb_reported_length ( tvb ) )  49
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 57
if ( b0 & 0x80 )  58
c_pdulen = ( ( b0 & 0x7f ) << 8 ) | tvb_get_guint8 ( tvb , offCur + 1 ); 60
c_pdulen = b0; 63
if ( tree )  65
proto_tree_add_uint ( wtp_tree , hf_wtp_header_sub_pdu_size , tvb , offCur , c_fieldlen , c_pdulen ); 66
col_append_str ( pinfo -> cinfo , COL_INFO , ", " ); 70
wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ); 73
CVE_2012_6061_PATCHED_dissect_wtp_common ( wtp_tvb , pinfo , wtp_tree ); 74
static void
CVE_2012_6061_PATCHED_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
if ( tree )  41
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 1 , ENC_NA ); 42
wtp_tree = proto_item_add_subtree ( ti , ett_wtp_sub_pdu_tree ); 44
proto_item_append_text ( ti , ", PDU concatenation" ); 45
while ( offCur < ( int ) tvb_reported_length ( tvb ) )  49
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 57
if ( b0 & 0x80 )  58
c_pdulen = ( ( b0 & 0x7f ) << 8 ) | tvb_get_guint8 ( tvb , offCur + 1 ); 60
c_pdulen = b0; 63
if ( tree )  65
proto_tree_add_uint ( wtp_tree , hf_wtp_header_sub_pdu_size , tvb , offCur , c_fieldlen , c_pdulen ); 66
col_append_str ( pinfo -> cinfo , COL_INFO , ", " ); 70
wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ); 73
CVE_2012_6061_PATCHED_dissect_wtp_common ( wtp_tvb , pinfo , wtp_tree ); 74
offCur += c_fieldlen + c_pdulen; 75
if ( tree )  78
proto_item_append_text ( ti , ", PDU count: %u" , i ); 79
fCon = b0 & 0x80; 84
fRID = retransmission_indicator ( b0 ); 85
pdut = pdu_type ( b0 ); 86
printf ( "WTP packet %u: tree = %p, pdu = %s (%u) length: %u\n" , pinfo -> fd -> num , tree , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) , pdut , tvb_length ( tvb ) ); 89
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
fTTR = transmission_trailer ( b0 ); 102
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 103
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
fTTR = transmission_trailer ( b0 ); 114
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 115
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
fTTR = transmission_trailer ( b0 ); 130
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 131
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fRID )  149
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
if ( tree )  155
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 157
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 0 , ENC_NA ); 160
fprintf ( stderr , "dissect_wtp: (7) Returned from proto_tree_add_item\n" ); 162
wtp_tree = proto_item_add_subtree ( ti , ett_wtp ); 164
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 168
fprintf ( stderr , "dissect_wtp: offCur = %d\n" , offCur ); 169
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_continue , tvb , offCur , 1 , b0 ); 172
proto_tree_add_item ( wtp_tree , hf_wtp_header_pdu_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 180
switch ( pdut )  182
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 184
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 185
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 186
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 187
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_version , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 189
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_TIDNew , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 190
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_UP , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 191
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_Reserved , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 192
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_TransactionClass , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 193
proto_item_append_text ( ti ,
", PDU: Invoke (%u)"
", Transaction Class: %s (%u)" ,
INVOKE ,
val_to_str ( clsTransaction , vals_transaction_classes , "Undefined" ) ,
clsTransaction ) 199
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 203
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 204
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 205
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 206
proto_item_append_text ( ti , ", PDU: Result (%u)" , RESULT ); 207
proto_tree_add_item ( wtp_tree , hf_wtp_header_Ack_flag_TVETOK , tvb , offCur , 1 , ENC_BIG_ENDIAN ); 211
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 213
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 214
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 215
proto_item_append_text ( ti , ", PDU: ACK (%u)" , ACK ); 216
abortType = tvb_get_guint8 ( tvb , offCur ) & 0x07; 220
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 221
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 222
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 223
if ( abortType == PROVIDER )  225
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 227
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_provider , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 228
if ( abortType == USER )  238
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 240
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_user , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 241
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 254
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 255
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 256
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 257
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 259
proto_item_append_text ( ti ,
", PDU: Segmented Invoke (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_INVOKE , psn ) 263
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 267
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 268
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 269
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 270
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 272
proto_item_append_text ( ti ,
", PDU: Segmented Result (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_RESULT , psn ) 276
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 280
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 281
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 282
proto_tree_add_item ( wtp_tree , hf_wtp_header_missing_packets , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 284
for (i = 0; i < numMissing; i++) 286
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 4 + i , 1 , ENC_LITTLE_ENDIAN ); 288
proto_item_append_text ( ti ,
", PDU: Negative Ack (%u)"
", Missing Packets: %u" ,
NEGATIVE_ACK , numMissing ) 293
if ( fRID )  299
proto_item_append_text ( ti , ", Retransmission" ); 300
fprintf ( stderr , "dissect_wtp: (4) tree was %p\n" , tree ); 304
if ( fCon )  308
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
if ( tree )  324
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
if ( tree )  338
proto_item_set_len ( ti , cbHeader + vHeader ); 339
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 342
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
gboolean save_fragmented = pinfo -> fragmented ; 378
pinfo -> fragmented = TRUE; 380
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  428
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
if ( tree )  433
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  440
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (Unreassembled fragment %u)" , szInfo , psn ); 441
if ( tree )  445
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
pinfo -> fragmented = save_fragmented; 451
if ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( fTTR ) )  453
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  463
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 464
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  470
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 471
offCur += c_fieldlen + c_pdulen; 75
if ( tree )  78
proto_item_append_text ( ti , ", PDU count: %u" , i ); 79
fCon = b0 & 0x80; 84
fRID = retransmission_indicator ( b0 ); 85
pdut = pdu_type ( b0 ); 86
printf ( "WTP packet %u: tree = %p, pdu = %s (%u) length: %u\n" , pinfo -> fd -> num , tree , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) , pdut , tvb_length ( tvb ) ); 89
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
fTTR = transmission_trailer ( b0 ); 102
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 103
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
fTTR = transmission_trailer ( b0 ); 114
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 115
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
fTTR = transmission_trailer ( b0 ); 130
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 131
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fRID )  149
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
if ( tree )  155
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 157
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 0 , ENC_NA ); 160
fprintf ( stderr , "dissect_wtp: (7) Returned from proto_tree_add_item\n" ); 162
wtp_tree = proto_item_add_subtree ( ti , ett_wtp ); 164
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 168
fprintf ( stderr , "dissect_wtp: offCur = %d\n" , offCur ); 169
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_continue , tvb , offCur , 1 , b0 ); 172
proto_tree_add_item ( wtp_tree , hf_wtp_header_pdu_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 180
switch ( pdut )  182
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 184
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 185
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 186
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 187
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_version , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 189
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_TIDNew , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 190
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_UP , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 191
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_Reserved , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 192
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_TransactionClass , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 193
proto_item_append_text ( ti ,
", PDU: Invoke (%u)"
", Transaction Class: %s (%u)" ,
INVOKE ,
val_to_str ( clsTransaction , vals_transaction_classes , "Undefined" ) ,
clsTransaction ) 199
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 203
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 204
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 205
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 206
proto_item_append_text ( ti , ", PDU: Result (%u)" , RESULT ); 207
proto_tree_add_item ( wtp_tree , hf_wtp_header_Ack_flag_TVETOK , tvb , offCur , 1 , ENC_BIG_ENDIAN ); 211
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 213
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 214
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 215
proto_item_append_text ( ti , ", PDU: ACK (%u)" , ACK ); 216
abortType = tvb_get_guint8 ( tvb , offCur ) & 0x07; 220
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 221
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 222
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 223
if ( abortType == PROVIDER )  225
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 227
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_provider , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 228
if ( abortType == USER )  238
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 240
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_user , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 241
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 254
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 255
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 256
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 257
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 259
proto_item_append_text ( ti ,
", PDU: Segmented Invoke (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_INVOKE , psn ) 263
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 267
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 268
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 269
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 270
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 272
proto_item_append_text ( ti ,
", PDU: Segmented Result (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_RESULT , psn ) 276
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 280
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 281
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 282
proto_tree_add_item ( wtp_tree , hf_wtp_header_missing_packets , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 284
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 4 + i , 1 , ENC_LITTLE_ENDIAN ); 288
proto_item_append_text ( ti ,
", PDU: Negative Ack (%u)"
", Missing Packets: %u" ,
NEGATIVE_ACK , numMissing ) 293
if ( fRID )  299
proto_item_append_text ( ti , ", Retransmission" ); 300
fprintf ( stderr , "dissect_wtp: (4) tree was %p\n" , tree ); 304
if ( fCon )  308
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
if ( tree )  324
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
if ( tree )  338
proto_item_set_len ( ti , cbHeader + vHeader ); 339
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 342
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
gboolean save_fragmented = pinfo -> fragmented ; 378
pinfo -> fragmented = TRUE; 380
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  428
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
if ( tree )  433
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  440
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (Unreassembled fragment %u)" , szInfo , psn ); 441
if ( tree )  445
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
pinfo -> fragmented = save_fragmented; 451
if ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( fTTR ) )  453
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  463
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 464
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  470
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 471
offCur += c_fieldlen + c_pdulen; 75
------------------------------
80 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c dataOffset = offCur + cbHeader + vHeader 359
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
guint vHeader = 0 ; 15
char pdut ; 22
int dataOffset ; 29
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
unsigned char tpiLen ; 311
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
vHeader += tpiLen; 330
while ( tCon )  331
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
------------------------------
81 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ) 326
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
char pdut ; 22
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
unsigned char tpiLen ; 311
tvbuff_t * tmp_tvb ; 312
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
if ( tree )  324
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
------------------------------
82 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ) 320
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
char pdut ; 22
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
unsigned char tpiLen ; 311
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
proto_item_set_len ( ti , cbHeader + vHeader ); 339
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
------------------------------
83 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ) 317
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
unsigned char fCon ; 11
guint cbHeader = 0 ; 14
char pdut ; 22
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fCon = b0 & 0x80; 84
pdut = pdu_type ( b0 ); 86
switch ( pdut )  100
cbHeader = 4; 109
cbHeader = 4; 122
cbHeader = 4; 126
cbHeader = 3; 133
cbHeader = 3; 137
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fCon )  308
unsigned char tCon ; 309
unsigned char tByte ; 310
unsigned char tpiLen ; 311
vHeader = 0; 314
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
proto_item_set_len ( ti , cbHeader + vHeader ); 339
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
------------------------------
84 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ) 150
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
char * szInfo ; 4
int offCur = 0 ; 5
gint returned_length , str_index = 0 ; 6
unsigned char b0 ; 8
unsigned char fRID ; 12
char pdut ; 22
szInfo = ep_alloc ( SZINFO_SIZE ); 33
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
fRID = retransmission_indicator ( b0 ); 85
pdut = pdu_type ( b0 ); 86
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
psn = 0; 104
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
if ( fRID )  149
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
------------------------------
85 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ) 118
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
char * szInfo ; 4
int offCur = 0 ; 5
gint returned_length , str_index = 0 ; 6
unsigned char b0 ; 8
char pdut ; 22
szInfo = ep_alloc ( SZINFO_SIZE ); 33
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
pdut = pdu_type ( b0 ); 86
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
psn = 0; 104
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
------------------------------
86 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ) 106
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
char * szInfo ; 4
int offCur = 0 ; 5
gint returned_length , str_index = 0 ; 6
unsigned char b0 ; 8
char pdut ; 22
szInfo = ep_alloc ( SZINFO_SIZE ); 33
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
pdut = pdu_type ( b0 ); 86
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
------------------------------
87 ../data/NVD/CVE_2012_6061_VULN_dissect_wtp_common.c wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ) 73
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
int offCur = 0 ; 5
unsigned char b0 ; 8
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
offCur = 1; 47
while ( offCur < ( int ) tvb_reported_length ( tvb ) )  49
tvbuff_t * wtp_tvb ; 50
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 57
if ( b0 & 0x80 )  58
c_fieldlen = 2; 59
c_pdulen = ( ( b0 & 0x7f ) << 8 ) | tvb_get_guint8 ( tvb , offCur + 1 ); 60
c_fieldlen = 1; 62
c_pdulen = b0; 63
wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ); 73
CVE_2012_6061_VULN_dissect_wtp_common ( wtp_tvb , pinfo , wtp_tree ); 74
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
if ( tree )  41
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 1 , ENC_NA ); 42
wtp_tree = proto_item_add_subtree ( ti , ett_wtp_sub_pdu_tree ); 44
proto_item_append_text ( ti , ", PDU concatenation" ); 45
while ( offCur < ( int ) tvb_reported_length ( tvb ) )  49
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 57
if ( b0 & 0x80 )  58
c_pdulen = ( ( b0 & 0x7f ) << 8 ) | tvb_get_guint8 ( tvb , offCur + 1 ); 60
c_pdulen = b0; 63
if ( tree )  65
proto_tree_add_uint ( wtp_tree , hf_wtp_header_sub_pdu_size , tvb , offCur , c_fieldlen , c_pdulen ); 66
col_append_str ( pinfo -> cinfo , COL_INFO , ", " ); 70
wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ); 73
CVE_2012_6061_VULN_dissect_wtp_common ( wtp_tvb , pinfo , wtp_tree ); 74
static void
CVE_2012_6061_VULN_dissect_wtp_common(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree) 2
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 35
if ( b0 == 0 )  37
if ( tree )  41
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 1 , ENC_NA ); 42
wtp_tree = proto_item_add_subtree ( ti , ett_wtp_sub_pdu_tree ); 44
proto_item_append_text ( ti , ", PDU concatenation" ); 45
while ( offCur < ( int ) tvb_reported_length ( tvb ) )  49
b0 = tvb_get_guint8 ( tvb , offCur + 0 ); 57
if ( b0 & 0x80 )  58
c_pdulen = ( ( b0 & 0x7f ) << 8 ) | tvb_get_guint8 ( tvb , offCur + 1 ); 60
c_pdulen = b0; 63
if ( tree )  65
proto_tree_add_uint ( wtp_tree , hf_wtp_header_sub_pdu_size , tvb , offCur , c_fieldlen , c_pdulen ); 66
col_append_str ( pinfo -> cinfo , COL_INFO , ", " ); 70
wtp_tvb = tvb_new_subset ( tvb , offCur + c_fieldlen , c_pdulen , c_pdulen ); 73
CVE_2012_6061_VULN_dissect_wtp_common ( wtp_tvb , pinfo , wtp_tree ); 74
offCur += c_fieldlen + c_pdulen; 75
if ( tree )  78
proto_item_append_text ( ti , ", PDU count: %u" , i ); 79
fCon = b0 & 0x80; 84
fRID = retransmission_indicator ( b0 ); 85
pdut = pdu_type ( b0 ); 86
printf ( "WTP packet %u: tree = %p, pdu = %s (%u) length: %u\n" , pinfo -> fd -> num , tree , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) , pdut , tvb_length ( tvb ) ); 89
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
fTTR = transmission_trailer ( b0 ); 102
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 103
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
fTTR = transmission_trailer ( b0 ); 114
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 115
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
fTTR = transmission_trailer ( b0 ); 130
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 131
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fRID )  149
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
if ( tree )  155
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 157
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 0 , ENC_NA ); 160
fprintf ( stderr , "dissect_wtp: (7) Returned from proto_tree_add_item\n" ); 162
wtp_tree = proto_item_add_subtree ( ti , ett_wtp ); 164
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 168
fprintf ( stderr , "dissect_wtp: offCur = %d\n" , offCur ); 169
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_continue , tvb , offCur , 1 , b0 ); 172
proto_tree_add_item ( wtp_tree , hf_wtp_header_pdu_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 180
switch ( pdut )  182
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 184
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 185
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 186
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 187
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_version , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 189
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_TIDNew , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 190
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_UP , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 191
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_Reserved , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 192
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_TransactionClass , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 193
proto_item_append_text ( ti ,
", PDU: Invoke (%u)"
", Transaction Class: %s (%u)" ,
INVOKE ,
val_to_str ( clsTransaction , vals_transaction_classes , "Undefined" ) ,
clsTransaction ) 199
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 203
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 204
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 205
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 206
proto_item_append_text ( ti , ", PDU: Result (%u)" , RESULT ); 207
proto_tree_add_item ( wtp_tree , hf_wtp_header_Ack_flag_TVETOK , tvb , offCur , 1 , ENC_BIG_ENDIAN ); 211
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 213
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 214
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 215
proto_item_append_text ( ti , ", PDU: ACK (%u)" , ACK ); 216
abortType = tvb_get_guint8 ( tvb , offCur ) & 0x07; 220
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 221
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 222
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 223
if ( abortType == PROVIDER )  225
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 227
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_provider , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 228
proto_item_append_text ( ti ,
", PDU: Abort (%u)"
", Type: Provider (%u)"
", Reason: %s (%u)" ,
ABORT ,
PROVIDER ,
val_to_str ( reason , vals_abort_reason_provider , "Undefined" ) ,
reason ) 236
if ( abortType == USER )  238
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 240
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_user , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 241
proto_item_append_text ( ti ,
", PDU: Abort (%u)"
", Type: User (%u)"
", Reason: %s (%u)" ,
ABORT ,
PROVIDER ,
val_to_str_ext_const ( reason , & vals_wsp_reason_codes_ext , "Undefined" ) ,
reason ) 249
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 254
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 255
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 256
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 257
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 259
proto_item_append_text ( ti ,
", PDU: Segmented Invoke (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_INVOKE , psn ) 263
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 267
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 268
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 269
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 270
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 272
proto_item_append_text ( ti ,
", PDU: Segmented Result (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_RESULT , psn ) 276
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 280
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 281
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 282
proto_tree_add_item ( wtp_tree , hf_wtp_header_missing_packets , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 284
for (i = 0; i < numMissing; i++) 286
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 4 + i , 1 , ENC_LITTLE_ENDIAN ); 288
proto_item_append_text ( ti ,
", PDU: Negative Ack (%u)"
", Missing Packets: %u" ,
NEGATIVE_ACK , numMissing ) 293
if ( fRID )  299
proto_item_append_text ( ti , ", Retransmission" ); 300
fprintf ( stderr , "dissect_wtp: (4) tree was %p\n" , tree ); 304
if ( fCon )  308
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
if ( tree )  324
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
if ( tree )  338
proto_item_set_len ( ti , cbHeader + vHeader ); 339
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 342
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
gboolean save_fragmented = pinfo -> fragmented ; 378
pinfo -> fragmented = TRUE; 380
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  428
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
if ( tree )  433
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  440
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (Unreassembled fragment %u)" , szInfo , psn ); 441
if ( tree )  445
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
pinfo -> fragmented = save_fragmented; 451
if ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( fTTR ) )  453
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  463
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 464
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  470
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 471
offCur += c_fieldlen + c_pdulen; 75
if ( tree )  78
proto_item_append_text ( ti , ", PDU count: %u" , i ); 79
fCon = b0 & 0x80; 84
fRID = retransmission_indicator ( b0 ); 85
pdut = pdu_type ( b0 ); 86
printf ( "WTP packet %u: tree = %p, pdu = %s (%u) length: %u\n" , pinfo -> fd -> num , tree , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) , pdut , tvb_length ( tvb ) ); 89
returned_length = g_snprintf ( szInfo , SZINFO_SIZE , "WTP %s" , val_to_str ( pdut , vals_wtp_pdu_type , "Unknown PDU type 0x%x" ) ); 96
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 98
switch ( pdut )  100
fTTR = transmission_trailer ( b0 ); 102
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 103
clsTransaction = transaction_class ( tvb_get_guint8 ( tvb , offCur + 3 ) ); 105
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " Class %d" , clsTransaction ); 106
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 108
fTTR = transmission_trailer ( b0 ); 114
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 115
psn = tvb_get_guint8 ( tvb , offCur + 3 ); 116
if ( psn != 0 )  117
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " (%u)" , psn ); 118
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 120
fTTR = transmission_trailer ( b0 ); 130
TID = tvb_get_ntohs ( tvb , offCur + 1 ); 131
numMissing = tvb_get_guint8 ( tvb , offCur + 3 ); 142
cbHeader = numMissing + 4; 143
if ( fRID )  149
returned_length = g_snprintf ( & szInfo [ str_index ] , SZINFO_SIZE - str_index , " R" ); 150
str_index += MIN ( returned_length , SZINFO_SIZE - str_index ); 151
if ( tree )  155
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 157
ti = proto_tree_add_item ( tree , proto_wtp , tvb , offCur , 0 , ENC_NA ); 160
fprintf ( stderr , "dissect_wtp: (7) Returned from proto_tree_add_item\n" ); 162
wtp_tree = proto_item_add_subtree ( ti , ett_wtp ); 164
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 168
fprintf ( stderr , "dissect_wtp: offCur = %d\n" , offCur ); 169
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_continue , tvb , offCur , 1 , b0 ); 172
proto_tree_add_item ( wtp_tree , hf_wtp_header_pdu_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 180
switch ( pdut )  182
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 184
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 185
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 186
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 187
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_version , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 189
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_TIDNew , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 190
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_flag_UP , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 191
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_Reserved , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 192
proto_tree_add_item ( wtp_tree , hf_wtp_header_Inv_TransactionClass , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 193
proto_item_append_text ( ti ,
", PDU: Invoke (%u)"
", Transaction Class: %s (%u)" ,
INVOKE ,
val_to_str ( clsTransaction , vals_transaction_classes , "Undefined" ) ,
clsTransaction ) 199
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 203
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 204
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 205
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 206
proto_item_append_text ( ti , ", PDU: Result (%u)" , RESULT ); 207
proto_tree_add_item ( wtp_tree , hf_wtp_header_Ack_flag_TVETOK , tvb , offCur , 1 , ENC_BIG_ENDIAN ); 211
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 213
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 214
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 215
proto_item_append_text ( ti , ", PDU: ACK (%u)" , ACK ); 216
abortType = tvb_get_guint8 ( tvb , offCur ) & 0x07; 220
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_type , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 221
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 222
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 223
if ( abortType == PROVIDER )  225
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 227
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_provider , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 228
proto_item_append_text ( ti ,
", PDU: Abort (%u)"
", Type: Provider (%u)"
", Reason: %s (%u)" ,
ABORT ,
PROVIDER ,
val_to_str ( reason , vals_abort_reason_provider , "Undefined" ) ,
reason ) 236
if ( abortType == USER )  238
guint8 reason = tvb_get_guint8 ( tvb , offCur + 3 ) ; 240
proto_tree_add_item ( wtp_tree , hf_wtp_header_Abort_reason_user , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 241
proto_item_append_text ( ti ,
", PDU: Abort (%u)"
", Type: User (%u)"
", Reason: %s (%u)" ,
ABORT ,
PROVIDER ,
val_to_str_ext_const ( reason , & vals_wsp_reason_codes_ext , "Undefined" ) ,
reason ) 249
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 254
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 255
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 256
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 257
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 259
proto_item_append_text ( ti ,
", PDU: Segmented Invoke (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_INVOKE , psn ) 263
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_Trailer , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 267
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 268
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 269
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 270
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 272
proto_item_append_text ( ti ,
", PDU: Segmented Result (%u)"
", Packet Sequence Number: %u" ,
SEGMENTED_RESULT , psn ) 276
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_RID , tvb , offCur , 1 , ENC_LITTLE_ENDIAN ); 280
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID_response , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 281
proto_tree_add_item ( wtp_tree , hf_wtp_header_flag_TID , tvb , offCur + 1 , 2 , ENC_BIG_ENDIAN ); 282
proto_tree_add_item ( wtp_tree , hf_wtp_header_missing_packets , tvb , offCur + 3 , 1 , ENC_LITTLE_ENDIAN ); 284
proto_tree_add_item ( wtp_tree , hf_wtp_header_sequence_number , tvb , offCur + 4 + i , 1 , ENC_LITTLE_ENDIAN ); 288
proto_item_append_text ( ti ,
", PDU: Negative Ack (%u)"
", Missing Packets: %u" ,
NEGATIVE_ACK , numMissing ) 293
if ( fRID )  299
proto_item_append_text ( ti , ", Retransmission" ); 300
fprintf ( stderr , "dissect_wtp: (4) tree was %p\n" , tree ); 304
if ( fCon )  308
tByte = tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader ); 317
tCon = tByte & 0x80; 318
if ( tByte & 0x04 )  319
tpiLen = 2 + tvb_get_guint8 ( tvb , offCur + cbHeader + vHeader + 1 ); 320
tpiLen = 1 + ( tByte & 0x03 ); 323
if ( tree )  324
tmp_tvb = tvb_new_subset ( tvb , offCur + cbHeader + vHeader , tpiLen , tpiLen ); 326
wtp_handle_tpi ( wtp_tree , tmp_tvb ); 328
vHeader += tpiLen; 330
while ( tCon )  331
if ( tree )  338
proto_item_set_len ( ti , cbHeader + vHeader ); 339
fprintf ( stderr , "dissect_wtp: cbHeader = %d\n" , cbHeader ); 342
dataOffset = offCur + cbHeader + vHeader; 359
dataLen = tvb_reported_length_remaining ( tvb , dataOffset ); 360
if ( ( dataLen >= 0 ) && ! ( ( pdut == ACK ) || ( pdut == NEGATIVE_ACK ) || ( pdut == ABORT ) ) )  361
if ( ( ( pdut == SEGMENTED_INVOKE ) || ( pdut == SEGMENTED_RESULT ) || ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( ! fTTR ) ) ) && tvb_bytes_exist ( tvb , dataOffset , dataLen ) )  371
gboolean save_fragmented = pinfo -> fragmented ; 378
pinfo -> fragmented = TRUE; 380
fd_wtp = fragment_add_seq ( tvb , dataOffset , pinfo , TID , wtp_fragment_table , psn , dataLen , ! fTTR ); 381
wsp_tvb = process_reassembled_data ( tvb , dataOffset , pinfo , "Reassembled WTP" , fd_wtp , & wtp_frag_items , NULL , wtp_tree ); 407
printf ( "WTP: Packet %u %s -> %d: wsp_tvb = %p, fd_wtp = %p, frame = %u\n" , pinfo -> fd -> num , fd_wtp ? "Reassembled" : "Not reassembled" , fd_wtp ? fd_wtp -> reassembled_in : - 1 , wsp_tvb , fd_wtp ); 411
if ( fd_wtp )  419
reassembled_in = fd_wtp -> reassembled_in; 421
if ( pinfo -> fd -> num == reassembled_in )  422
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 425
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  428
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (WTP payload reassembled in packet %u)" , szInfo , fd_wtp -> reassembled_in ); 429
if ( tree )  433
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 434
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  440
col_append_fstr ( pinfo -> cinfo , COL_INFO , "%s (Unreassembled fragment %u)" , szInfo , psn ); 441
if ( tree )  445
proto_tree_add_text ( wtp_tree , tvb , dataOffset , - 1 , "Payload" ); 446
pinfo -> fragmented = save_fragmented; 451
if ( ( ( pdut == INVOKE ) || ( pdut == RESULT ) ) && ( fTTR ) )  453
wsp_tvb = tvb_new_subset_remaining ( tvb , dataOffset ); 456
call_dissector ( wsp_handle , wsp_tvb , pinfo , tree ); 458
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  463
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 464
if ( check_col ( pinfo -> cinfo , COL_INFO ) )  470
col_append_str ( pinfo -> cinfo , COL_INFO , szInfo ); 471
offCur += c_fieldlen + c_pdulen; 75
------------------------------
88 ../data/NVD/CVE_2012_6062_PATCHED_dissect_rtcp_app.c packet_len = packet_len - item_len - 1 277
static int
CVE_2012_6062_PATCHED_dissect_rtcp_app( tvbuff_t *tvb,packet_info *pinfo, int offset, proto_tree *tree,
unsigned int padding, unsigned int packet_len, guint rtcp_subtype,
guint32 app_length ) 4
unsigned int counter ; 6
char ascii_name [ 5 ] ; 7
guint sdes_type ; 8
guint item_len ; 9
static const char poc1_app_name_str [ ] = "PoC1" ; 14
offset += 4; 20
packet_len -= 4; 21
for( counter = 0; counter < 4; counter++ ) 24
ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ); 25
ascii_name [ 4 ] = '\0'; 27
if ( g_ascii_strncasecmp ( ascii_name , poc1_app_name_str , 4 ) == 0 )  32
guint8 t2timer_code , participants_code ; 35
offset += 4; 41
packet_len -= 4; 42
if ( packet_len == 0 )  44
if ( padding )  47
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 51
switch ( rtcp_subtype )  61
guint8 code ; 65
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  69
code = tvb_get_guint8 ( tvb , offset ); 75
offset += 1; 76
packet_len -= 1; 77
if ( code == 102 )  80
item_len = tvb_get_guint8 ( tvb , offset ); 82
offset += 1; 83
packet_len -= 1; 84
if ( item_len != 2 )  85
offset += 2; 90
packet_len -= 2; 91
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  100
code = tvb_get_guint8 ( tvb , offset ); 104
offset += 1; 105
packet_len -= 1; 106
if ( code == 103 )  111
item_len = tvb_get_guint8 ( tvb , offset ); 115
offset += 1; 116
packet_len -= 1; 117
if ( item_len != 8 )  118
offset += 8; 125
packet_len -= 8; 126
t2timer_code = tvb_get_guint8 ( tvb , offset ); 140
offset += 1; 141
packet_len -= 1; 142
if ( t2timer_code != 101 )  143
item_len = tvb_get_guint8 ( tvb , offset ); 146
offset += 1; 147
packet_len -= 1; 148
if ( item_len != 2 )  149
offset += item_len; 168
packet_len -= item_len; 169
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  175
participants_code = tvb_get_guint8 ( tvb , offset ); 179
offset += 1; 180
packet_len -= 1; 181
if ( participants_code != 100 )  182
item_len = tvb_get_guint8 ( tvb , offset ); 185
offset += 1; 186
packet_len -= 1; 187
if ( item_len != 2 )  188
offset += item_len; 206
packet_len -= item_len; 207
offset += 4; 222
packet_len -= 4; 223
sdes_type = tvb_get_guint8 ( tvb , offset ); 226
offset ++; 228
packet_len --; 229
if ( sdes_type != RTCP_SDES_CNAME )  230
item_len = tvb_get_guint8 ( tvb , offset ); 236
offset ++; 240
offset += item_len; 245
packet_len = packet_len - item_len - 1; 246
if ( packet_len == 0 )  256
sdes_type = tvb_get_guint8 ( tvb , offset ); 260
if ( sdes_type == RTCP_SDES_NAME )  261
offset ++; 263
packet_len --; 264
item_len = tvb_get_guint8 ( tvb , offset ); 267
packet_len = packet_len - item_len - 1; 277
if ( packet_len == 0 )  279
packet_len -= padding2; 287
packet_len -= 1; 297
packet_len -= 1; 303
packet_len -= item_len; 326
if ( ( int ) ( offset + packet_len ) >= offset )  530
offset += packet_len; 531
return offset ; 532
offset += 4; 538
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 545
if ( packet_len == 4 )  547
proto_item * mux_item = proto_tree_add_item ( tree , hf_rtcp_app_mux , tvb , offset , packet_len , ENC_NA ) ; 551
proto_tree * mux_tree = proto_item_add_subtree ( mux_item , ett_mux ) ; 552
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_mux , tvb , offset , 1 , ENC_BIG_ENDIAN ); 553
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_cp , tvb , offset , 1 , ENC_BIG_ENDIAN ); 554
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_selection , tvb , offset , 1 , ENC_BIG_ENDIAN ); 555
local_port = tvb_get_ntohs ( tvb , offset + 2 ); 556
proto_tree_add_uint ( mux_tree , hf_rtcp_app_mux_localmuxport , tvb , offset + 2 , 2 , local_port * 2 ); 557
proto_tree_add_item ( tree , hf_rtcp_app_data , tvb , offset , packet_len , ENC_NA ); 562
if ( ( int ) ( offset + packet_len ) >= offset )  564
offset += packet_len; 565
return offset ; 566
------------------------------
89 ../data/NVD/CVE_2012_6062_PATCHED_dissect_rtcp_app.c packet_len = packet_len - item_len - 1 246
static int
CVE_2012_6062_PATCHED_dissect_rtcp_app( tvbuff_t *tvb,packet_info *pinfo, int offset, proto_tree *tree,
unsigned int padding, unsigned int packet_len, guint rtcp_subtype,
guint32 app_length ) 4
unsigned int counter ; 6
char ascii_name [ 5 ] ; 7
guint sdes_type ; 8
guint item_len ; 9
static const char poc1_app_name_str [ ] = "PoC1" ; 14
offset += 4; 20
packet_len -= 4; 21
for( counter = 0; counter < 4; counter++ ) 24
ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ); 25
ascii_name [ 4 ] = '\0'; 27
if ( g_ascii_strncasecmp ( ascii_name , poc1_app_name_str , 4 ) == 0 )  32
guint8 t2timer_code , participants_code ; 35
offset += 4; 41
packet_len -= 4; 42
if ( packet_len == 0 )  44
if ( padding )  47
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 51
switch ( rtcp_subtype )  61
guint8 code ; 65
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  69
code = tvb_get_guint8 ( tvb , offset ); 75
offset += 1; 76
packet_len -= 1; 77
if ( code == 102 )  80
item_len = tvb_get_guint8 ( tvb , offset ); 82
offset += 1; 83
packet_len -= 1; 84
if ( item_len != 2 )  85
offset += 2; 90
packet_len -= 2; 91
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  100
code = tvb_get_guint8 ( tvb , offset ); 104
offset += 1; 105
packet_len -= 1; 106
if ( code == 103 )  111
item_len = tvb_get_guint8 ( tvb , offset ); 115
offset += 1; 116
packet_len -= 1; 117
if ( item_len != 8 )  118
offset += 8; 125
packet_len -= 8; 126
t2timer_code = tvb_get_guint8 ( tvb , offset ); 140
offset += 1; 141
packet_len -= 1; 142
if ( t2timer_code != 101 )  143
item_len = tvb_get_guint8 ( tvb , offset ); 146
offset += 1; 147
packet_len -= 1; 148
if ( item_len != 2 )  149
offset += item_len; 168
packet_len -= item_len; 169
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  175
participants_code = tvb_get_guint8 ( tvb , offset ); 179
offset += 1; 180
packet_len -= 1; 181
if ( participants_code != 100 )  182
item_len = tvb_get_guint8 ( tvb , offset ); 185
offset += 1; 186
packet_len -= 1; 187
if ( item_len != 2 )  188
offset += item_len; 206
packet_len -= item_len; 207
offset += 4; 222
packet_len -= 4; 223
sdes_type = tvb_get_guint8 ( tvb , offset ); 226
offset ++; 228
packet_len --; 229
if ( sdes_type != RTCP_SDES_CNAME )  230
item_len = tvb_get_guint8 ( tvb , offset ); 236
packet_len = packet_len - item_len - 1; 246
if ( packet_len == 0 )  256
packet_len --; 264
packet_len = packet_len - item_len - 1; 277
if ( packet_len == 0 )  279
packet_len -= padding2; 287
packet_len -= 1; 297
packet_len -= 1; 303
packet_len -= item_len; 326
if ( ( int ) ( offset + packet_len ) >= offset )  530
offset += packet_len; 531
return offset ; 532
offset += 4; 538
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 545
if ( packet_len == 4 )  547
proto_item * mux_item = proto_tree_add_item ( tree , hf_rtcp_app_mux , tvb , offset , packet_len , ENC_NA ) ; 551
proto_tree * mux_tree = proto_item_add_subtree ( mux_item , ett_mux ) ; 552
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_mux , tvb , offset , 1 , ENC_BIG_ENDIAN ); 553
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_cp , tvb , offset , 1 , ENC_BIG_ENDIAN ); 554
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_selection , tvb , offset , 1 , ENC_BIG_ENDIAN ); 555
local_port = tvb_get_ntohs ( tvb , offset + 2 ); 556
proto_tree_add_uint ( mux_tree , hf_rtcp_app_mux_localmuxport , tvb , offset + 2 , 2 , local_port * 2 ); 557
proto_tree_add_item ( tree , hf_rtcp_app_data , tvb , offset , packet_len , ENC_NA ); 562
if ( ( int ) ( offset + packet_len ) >= offset )  564
offset += packet_len; 565
return offset ; 566
------------------------------
90 ../data/NVD/CVE_2012_6062_PATCHED_dissect_rtcp_app.c ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ) 25
static int
CVE_2012_6062_PATCHED_dissect_rtcp_app( tvbuff_t *tvb,packet_info *pinfo, int offset, proto_tree *tree,
unsigned int padding, unsigned int packet_len, guint rtcp_subtype,
guint32 app_length ) 4
unsigned int counter ; 6
char ascii_name [ 5 ] ; 7
offset += 4; 20
for( counter = 0; counter < 4; counter++ ) 24
ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ); 25
ascii_name [ 4 ] = '\0'; 27
proto_tree_add_string ( tree , hf_rtcp_name_ascii , tvb , offset , 4 , ascii_name ); 28
if ( g_ascii_strncasecmp ( ascii_name , poc1_app_name_str , 4 ) == 0 )  32
col_add_fstr ( pinfo -> cinfo , COL_INFO , "(%s) %s" , ascii_name , val_to_str ( rtcp_subtype , rtcp_app_poc1_floor_cnt_type_vals , "unknown (%u)" ) ); 39
if ( g_ascii_strncasecmp ( ascii_name , mux_app_name_str , 4 ) == 0 )  534
col_append_fstr ( pinfo -> cinfo , COL_INFO , "( %s ) subtype=%u" , ascii_name , rtcp_subtype ); 537
if ( dissector_try_string ( rtcp_dissector_table , ascii_name , next_tvb , pinfo , tree ) )  576
col_append_fstr ( pinfo -> cinfo , COL_INFO , "( %s ) subtype=%u" , ascii_name , rtcp_subtype ); 593
------------------------------
91 ../data/NVD/CVE_2012_6062_VULN_dissect_rtcp_app.c packet_len = packet_len - item_len - 1 277
static int
CVE_2012_6062_VULN_dissect_rtcp_app( tvbuff_t *tvb,packet_info *pinfo, int offset, proto_tree *tree,
unsigned int padding, unsigned int packet_len, guint rtcp_subtype,
guint32 app_length ) 4
unsigned int counter ; 6
char ascii_name [ 5 ] ; 7
guint sdes_type ; 8
guint item_len ; 9
static const char poc1_app_name_str [ ] = "PoC1" ; 14
offset += 4; 20
packet_len -= 4; 21
for( counter = 0; counter < 4; counter++ ) 24
ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ); 25
ascii_name [ 4 ] = '\0'; 27
if ( g_ascii_strncasecmp ( ascii_name , poc1_app_name_str , 4 ) == 0 )  32
guint8 t2timer_code , participants_code ; 35
offset += 4; 41
packet_len -= 4; 42
if ( packet_len == 0 )  44
if ( padding )  47
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 51
switch ( rtcp_subtype )  61
guint8 code ; 65
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  69
code = tvb_get_guint8 ( tvb , offset ); 75
offset += 1; 76
packet_len -= 1; 77
if ( code == 102 )  80
item_len = tvb_get_guint8 ( tvb , offset ); 82
offset += 1; 83
packet_len -= 1; 84
if ( item_len != 2 )  85
offset += 2; 90
packet_len -= 2; 91
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  100
code = tvb_get_guint8 ( tvb , offset ); 104
offset += 1; 105
packet_len -= 1; 106
if ( code == 103 )  111
item_len = tvb_get_guint8 ( tvb , offset ); 115
offset += 1; 116
packet_len -= 1; 117
if ( item_len != 8 )  118
offset += 8; 125
packet_len -= 8; 126
t2timer_code = tvb_get_guint8 ( tvb , offset ); 140
offset += 1; 141
packet_len -= 1; 142
if ( t2timer_code != 101 )  143
item_len = tvb_get_guint8 ( tvb , offset ); 146
offset += 1; 147
packet_len -= 1; 148
if ( item_len != 2 )  149
offset += item_len; 168
packet_len -= item_len; 169
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  175
participants_code = tvb_get_guint8 ( tvb , offset ); 179
offset += 1; 180
packet_len -= 1; 181
if ( participants_code != 100 )  182
item_len = tvb_get_guint8 ( tvb , offset ); 185
offset += 1; 186
packet_len -= 1; 187
if ( item_len != 2 )  188
offset += item_len; 206
packet_len -= item_len; 207
offset += 4; 222
packet_len -= 4; 223
sdes_type = tvb_get_guint8 ( tvb , offset ); 226
offset ++; 228
packet_len --; 229
if ( sdes_type != RTCP_SDES_CNAME )  230
item_len = tvb_get_guint8 ( tvb , offset ); 236
offset ++; 240
offset += item_len; 245
packet_len = packet_len - item_len - 1; 246
if ( packet_len == 0 )  256
sdes_type = tvb_get_guint8 ( tvb , offset ); 260
if ( sdes_type == RTCP_SDES_NAME )  261
offset ++; 263
packet_len --; 264
item_len = tvb_get_guint8 ( tvb , offset ); 267
packet_len = packet_len - item_len - 1; 277
if ( packet_len == 0 )  279
packet_len -= padding2; 287
packet_len -= 1; 297
packet_len -= 1; 303
packet_len -= item_len; 326
packet_len --; 338
packet_len -= ( item_len + 1 ); 351
packet_len -= 4; 376
packet_len -= 4; 412
packet_len -= 4; 437
packet_len -= 4; 469
packet_len -= 4; 504
packet_len -= ( sdes_len2 + 2 ); 521
offset += packet_len; 530
return offset ; 531
offset += 4; 537
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 544
if ( packet_len == 4 )  546
proto_item * mux_item = proto_tree_add_item ( tree , hf_rtcp_app_mux , tvb , offset , packet_len , ENC_NA ) ; 550
proto_tree * mux_tree = proto_item_add_subtree ( mux_item , ett_mux ) ; 551
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_mux , tvb , offset , 1 , ENC_BIG_ENDIAN ); 552
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_cp , tvb , offset , 1 , ENC_BIG_ENDIAN ); 553
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_selection , tvb , offset , 1 , ENC_BIG_ENDIAN ); 554
local_port = tvb_get_ntohs ( tvb , offset + 2 ); 555
proto_tree_add_uint ( mux_tree , hf_rtcp_app_mux_localmuxport , tvb , offset + 2 , 2 , local_port * 2 ); 556
proto_tree_add_item ( tree , hf_rtcp_app_data , tvb , offset , packet_len , ENC_NA ); 561
offset += packet_len; 563
return offset ; 565
------------------------------
92 ../data/NVD/CVE_2012_6062_VULN_dissect_rtcp_app.c packet_len = packet_len - item_len - 1 246
static int
CVE_2012_6062_VULN_dissect_rtcp_app( tvbuff_t *tvb,packet_info *pinfo, int offset, proto_tree *tree,
unsigned int padding, unsigned int packet_len, guint rtcp_subtype,
guint32 app_length ) 4
unsigned int counter ; 6
char ascii_name [ 5 ] ; 7
guint sdes_type ; 8
guint item_len ; 9
static const char poc1_app_name_str [ ] = "PoC1" ; 14
offset += 4; 20
packet_len -= 4; 21
for( counter = 0; counter < 4; counter++ ) 24
ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ); 25
ascii_name [ 4 ] = '\0'; 27
if ( g_ascii_strncasecmp ( ascii_name , poc1_app_name_str , 4 ) == 0 )  32
guint8 t2timer_code , participants_code ; 35
offset += 4; 41
packet_len -= 4; 42
if ( packet_len == 0 )  44
if ( padding )  47
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 51
switch ( rtcp_subtype )  61
guint8 code ; 65
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  69
code = tvb_get_guint8 ( tvb , offset ); 75
offset += 1; 76
packet_len -= 1; 77
if ( code == 102 )  80
item_len = tvb_get_guint8 ( tvb , offset ); 82
offset += 1; 83
packet_len -= 1; 84
if ( item_len != 2 )  85
offset += 2; 90
packet_len -= 2; 91
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  100
code = tvb_get_guint8 ( tvb , offset ); 104
offset += 1; 105
packet_len -= 1; 106
if ( code == 103 )  111
item_len = tvb_get_guint8 ( tvb , offset ); 115
offset += 1; 116
packet_len -= 1; 117
if ( item_len != 8 )  118
offset += 8; 125
packet_len -= 8; 126
t2timer_code = tvb_get_guint8 ( tvb , offset ); 140
offset += 1; 141
packet_len -= 1; 142
if ( t2timer_code != 101 )  143
item_len = tvb_get_guint8 ( tvb , offset ); 146
offset += 1; 147
packet_len -= 1; 148
if ( item_len != 2 )  149
offset += item_len; 168
packet_len -= item_len; 169
if ( tvb_reported_length_remaining ( tvb , offset ) == 0 )  175
participants_code = tvb_get_guint8 ( tvb , offset ); 179
offset += 1; 180
packet_len -= 1; 181
if ( participants_code != 100 )  182
item_len = tvb_get_guint8 ( tvb , offset ); 185
offset += 1; 186
packet_len -= 1; 187
if ( item_len != 2 )  188
offset += item_len; 206
packet_len -= item_len; 207
offset += 4; 222
packet_len -= 4; 223
sdes_type = tvb_get_guint8 ( tvb , offset ); 226
offset ++; 228
packet_len --; 229
if ( sdes_type != RTCP_SDES_CNAME )  230
item_len = tvb_get_guint8 ( tvb , offset ); 236
packet_len = packet_len - item_len - 1; 246
if ( packet_len == 0 )  256
packet_len --; 264
packet_len = packet_len - item_len - 1; 277
if ( packet_len == 0 )  279
packet_len -= padding2; 287
packet_len -= 1; 297
packet_len -= 1; 303
packet_len -= item_len; 326
packet_len --; 338
packet_len -= ( item_len + 1 ); 351
packet_len -= 4; 376
packet_len -= 4; 412
packet_len -= 4; 437
packet_len -= 4; 469
packet_len -= 4; 504
packet_len -= ( sdes_len2 + 2 ); 521
offset += packet_len; 530
return offset ; 531
offset += 4; 537
packet_len -= tvb_get_guint8 ( tvb , offset + packet_len - 1 ); 544
if ( packet_len == 4 )  546
proto_item * mux_item = proto_tree_add_item ( tree , hf_rtcp_app_mux , tvb , offset , packet_len , ENC_NA ) ; 550
proto_tree * mux_tree = proto_item_add_subtree ( mux_item , ett_mux ) ; 551
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_mux , tvb , offset , 1 , ENC_BIG_ENDIAN ); 552
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_cp , tvb , offset , 1 , ENC_BIG_ENDIAN ); 553
proto_tree_add_item ( mux_tree , hf_rtcp_app_mux_selection , tvb , offset , 1 , ENC_BIG_ENDIAN ); 554
local_port = tvb_get_ntohs ( tvb , offset + 2 ); 555
proto_tree_add_uint ( mux_tree , hf_rtcp_app_mux_localmuxport , tvb , offset + 2 , 2 , local_port * 2 ); 556
proto_tree_add_item ( tree , hf_rtcp_app_data , tvb , offset , packet_len , ENC_NA ); 561
offset += packet_len; 563
return offset ; 565
------------------------------
93 ../data/NVD/CVE_2012_6062_VULN_dissect_rtcp_app.c ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ) 25
static int
CVE_2012_6062_VULN_dissect_rtcp_app( tvbuff_t *tvb,packet_info *pinfo, int offset, proto_tree *tree,
unsigned int padding, unsigned int packet_len, guint rtcp_subtype,
guint32 app_length ) 4
unsigned int counter ; 6
char ascii_name [ 5 ] ; 7
offset += 4; 20
for( counter = 0; counter < 4; counter++ ) 24
ascii_name [ counter ] = tvb_get_guint8 ( tvb , offset + counter ); 25
ascii_name [ 4 ] = '\0'; 27
proto_tree_add_string ( tree , hf_rtcp_name_ascii , tvb , offset , 4 , ascii_name ); 28
if ( g_ascii_strncasecmp ( ascii_name , poc1_app_name_str , 4 ) == 0 )  32
col_add_fstr ( pinfo -> cinfo , COL_INFO , "(%s) %s" , ascii_name , val_to_str ( rtcp_subtype , rtcp_app_poc1_floor_cnt_type_vals , "unknown (%u)" ) ); 39
if ( g_ascii_strncasecmp ( ascii_name , mux_app_name_str , 4 ) == 0 )  533
col_append_fstr ( pinfo -> cinfo , COL_INFO , "( %s ) subtype=%u" , ascii_name , rtcp_subtype ); 536
if ( dissector_try_string ( rtcp_dissector_table , ascii_name , next_tvb , pinfo , tree ) )  575
col_append_fstr ( pinfo -> cinfo , COL_INFO , "( %s ) subtype=%u" , ascii_name , rtcp_subtype ); 591
------------------------------
94 ../data/NVD/CVE_2012_6616_PATCHED_mov_text_decode_frame.c end = ptr + FFMIN ( 2 + AV_RB16 ( ptr ) , avpkt -> size ) 28
static int CVE_2012_6616_PATCHED_mov_text_decode_frame(AVCodecContext *avctx,
void *data, int *got_sub_ptr, AVPacket *avpkt) 2
const char * ptr = avpkt -> data ; 7
const char * end ; 8
if ( ! ptr || avpkt -> size < 2 )  10
if ( avpkt -> size == 2 )  20
end = ptr + FFMIN ( 2 + AV_RB16 ( ptr ) , avpkt -> size ); 28
text_to_ass ( & buf , ptr , end ); 40
------------------------------
95 ../data/NVD/CVE_2012_6616_VULN_mov_text_decode_frame.c end = ptr + FFMAX ( 2 + AV_RB16 ( ptr ) , avpkt -> size ) 28
static int CVE_2012_6616_VULN_mov_text_decode_frame(AVCodecContext *avctx,
void *data, int *got_sub_ptr, AVPacket *avpkt) 2
const char * ptr = avpkt -> data ; 7
const char * end ; 8
if ( ! ptr || avpkt -> size < 2 )  10
if ( avpkt -> size == 2 )  20
end = ptr + FFMAX ( 2 + AV_RB16 ( ptr ) , avpkt -> size ); 28
text_to_ass ( & buf , ptr , end ); 40
------------------------------
96 ../data/NVD/CVE_2012_6618_PATCHED_av_probe_input_buffer.c buftmp = av_realloc ( buf , probe_size + AVPROBE_PADDING_SIZE ) 32
int CVE_2012_6618_PATCHED_av_probe_input_buffer(AVIOContext *pb, AVInputFormat **fmt,
const char *filename, void *logctx,
unsigned int offset, unsigned int max_probe_size) 3
AVProbeData pd = { filename ? filename : "" , NULL , - offset } ; 5
unsigned char * buf = NULL ; 6
if ( ! max_probe_size )  9
max_probe_size = PROBE_BUF_MAX; 10
if ( max_probe_size > PROBE_BUF_MAX )  11
max_probe_size = PROBE_BUF_MAX; 12
if ( max_probe_size < PROBE_BUF_MIN )  13
if ( offset >= max_probe_size )  17
for(probe_size= PROBE_BUF_MIN; probe_size<=max_probe_size && !*fmt;
probe_size = FFMIN(probe_size<<1, FFMAX(max_probe_size, probe_size+1))) 22
int buf_offset = ( probe_size == PROBE_BUF_MIN ) ? 0 : probe_size >> 1 ; 24
void * buftmp ; 25
if ( probe_size < offset )  27
buftmp = av_realloc ( buf , probe_size + AVPROBE_PADDING_SIZE ); 32
if ( ! buftmp )  33
av_free ( buf ); 34
buf = buftmp; 37
if ( ( ret = avio_read ( pb , buf + buf_offset , probe_size - buf_offset ) ) < 0 )  38
if ( ret != AVERROR_EOF )  40
av_free ( buf ); 41
return ret ; 42
score = 0; 44
ret = 0; 45
pd . buf_size = buf_offset += ret; 47
pd . buf = & buf [ offset ]; 48
memset ( pd . buf + pd . buf_size , 0 , AVPROBE_PADDING_SIZE ); 50
* fmt = av_probe_input_format2 ( & pd , 1 , & score ); 53
if ( * fmt )  54
av_log ( logctx , AV_LOG_WARNING , "Format %s detected only with low score of %d, misdetection possible!\n" , ( * fmt ) -> name , score ); 56
av_log ( logctx , AV_LOG_DEBUG , "Format %s probed with size=%d and score=%d\n" , ( * fmt ) -> name , probe_size , score ); 58
if ( ! * fmt )  62
av_free ( buf ); 63
if ( ( ret = ffio_rewind_with_probe_data ( pb , buf , pd . buf_size ) ) < 0 )  68
av_free ( buf ); 69
return ret ; 71
------------------------------
97 ../data/NVD/CVE_2012_6618_VULN_av_probe_input_buffer.c buftmp = av_realloc ( buf , probe_size + AVPROBE_PADDING_SIZE ) 32
int CVE_2012_6618_VULN_av_probe_input_buffer(AVIOContext *pb, AVInputFormat **fmt,
const char *filename, void *logctx,
unsigned int offset, unsigned int max_probe_size) 3
AVProbeData pd = { filename ? filename : "" , NULL , - offset } ; 5
unsigned char * buf = NULL ; 6
if ( ! max_probe_size )  9
max_probe_size = PROBE_BUF_MAX; 10
if ( max_probe_size > PROBE_BUF_MAX )  11
max_probe_size = PROBE_BUF_MAX; 12
if ( max_probe_size < PROBE_BUF_MIN )  13
if ( offset >= max_probe_size )  17
for(probe_size= PROBE_BUF_MIN; probe_size<=max_probe_size && !*fmt;
probe_size = FFMIN(probe_size<<1, FFMAX(max_probe_size, probe_size+1))) 22
int buf_offset = ( probe_size == PROBE_BUF_MIN ) ? 0 : probe_size >> 1 ; 24
void * buftmp ; 25
if ( probe_size < offset )  27
buftmp = av_realloc ( buf , probe_size + AVPROBE_PADDING_SIZE ); 32
if ( ! buftmp )  33
av_free ( buf ); 34
buf = buftmp; 37
if ( ( ret = avio_read ( pb , buf + buf_offset , probe_size - buf_offset ) ) < 0 )  38
if ( ret != AVERROR_EOF )  40
av_free ( buf ); 41
return ret ; 42
score = 0; 44
ret = 0; 45
pd . buf_size += ret; 47
pd . buf = & buf [ offset ]; 48
memset ( pd . buf + pd . buf_size , 0 , AVPROBE_PADDING_SIZE ); 50
* fmt = av_probe_input_format2 ( & pd , 1 , & score ); 53
if ( * fmt )  54
av_log ( logctx , AV_LOG_WARNING , "Format %s detected only with low score of %d, misdetection possible!\n" , ( * fmt ) -> name , score ); 56
av_log ( logctx , AV_LOG_DEBUG , "Format %s probed with size=%d and score=%d\n" , ( * fmt ) -> name , probe_size , score ); 58
if ( ! * fmt )  62
av_free ( buf ); 63
if ( ( ret = ffio_rewind_with_probe_data ( pb , buf , pd . buf_size ) ) < 0 )  68
av_free ( buf ); 69
return ret ; 71
------------------------------
98 ../data/NVD/CVE_2012_6657_PATCHED_sock_setsockopt.c sk -> sk_lingertime = ( unsigned int ) ling . l_linger * HZ 157
int CVE_2012_6657_PATCHED_sock_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, unsigned int optlen) 2
struct sock * sk = sock -> sk ; 4
int val ; 5
struct linger ling ; 7
if ( optname == SO_BINDTODEVICE )  14
if ( optlen < sizeof ( int ) )  17
if ( get_user ( val , ( int __user * ) optval ) )  20
switch ( optname )  27
if ( optlen < sizeof ( ling ) )  141
if ( copy_from_user ( & ling , optval , sizeof ( ling ) ) )  145
if ( ! ling . l_onoff )  149
if ( ( unsigned int ) ling . l_linger >= MAX_SCHEDULE_TIMEOUT / HZ )  153
sk -> sk_lingertime = ( unsigned int ) ling . l_linger * HZ; 157
sock_set_flag ( sk , SOCK_LINGER ); 158
------------------------------
99 ../data/NVD/CVE_2012_6657_VULN_sock_setsockopt.c sk -> sk_lingertime = ( unsigned int ) ling . l_linger * HZ 156
int CVE_2012_6657_VULN_sock_setsockopt(struct socket *sock, int level, int optname,
char __user *optval, unsigned int optlen) 2
struct sock * sk = sock -> sk ; 4
int val ; 5
struct linger ling ; 7
if ( optname == SO_BINDTODEVICE )  14
if ( optlen < sizeof ( int ) )  17
if ( get_user ( val , ( int __user * ) optval ) )  20
switch ( optname )  27
if ( optlen < sizeof ( ling ) )  140
if ( copy_from_user ( & ling , optval , sizeof ( ling ) ) )  144
if ( ! ling . l_onoff )  148
if ( ( unsigned int ) ling . l_linger >= MAX_SCHEDULE_TIMEOUT / HZ )  152
sk -> sk_lingertime = ( unsigned int ) ling . l_linger * HZ; 156
sock_set_flag ( sk , SOCK_LINGER ); 157
------------------------------
100 ../data/NVD/CVE_2013_0310_PATCHED_cipso_v4_validate.c * option = opt + err_offset 136
int CVE_2013_0310_PATCHED_cipso_v4_validate(const struct sk_buff *skb, unsigned char **option) 1
unsigned char * opt = * option ; 3
unsigned char * tag ; 4
unsigned char opt_iter ; 5
unsigned char err_offset = 0 ; 6
u8 opt_len ; 7
u8 tag_len ; 8
u32 tag_iter ; 10
opt_len = opt [ 1 ]; 13
if ( opt_len < 8 )  14
err_offset = 1; 15
doi_def = cipso_v4_doi_search ( get_unaligned_be32 ( & opt [ 2 ] ) ); 20
if ( doi_def == NULL )  21
err_offset = 2; 22
opt_iter = CIPSO_V4_HDR_LEN; 26
tag = opt + opt_iter; 27
while ( opt_iter < opt_len )  28
for (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];) 29
if ( doi_def -> tags [ tag_iter ] == CIPSO_V4_TAG_INVALID || ++ tag_iter == CIPSO_V4_TAG_MAXCNT )  30
err_offset = opt_iter; 32
tag_len = tag [ 1 ]; 36
if ( tag_len > ( opt_len - opt_iter ) )  37
err_offset = opt_iter + 1; 38
switch ( tag [ 0 ] )  42
if ( tag_len < CIPSO_V4_TAG_RBM_BLEN )  44
err_offset = opt_iter + 1; 45
if ( cipso_v4_rbm_strictvalid )  56
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  57
err_offset = opt_iter + 3; 59
if ( tag_len > CIPSO_V4_TAG_RBM_BLEN && cipso_v4_map_cat_rbm_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  62
err_offset = opt_iter + 4; 66
if ( tag_len < CIPSO_V4_TAG_ENUM_BLEN )  72
err_offset = opt_iter + 1; 73
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  77
err_offset = opt_iter + 3; 79
if ( tag_len > CIPSO_V4_TAG_ENUM_BLEN && cipso_v4_map_cat_enum_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  82
err_offset = opt_iter + 4; 86
if ( tag_len < CIPSO_V4_TAG_RNG_BLEN )  91
err_offset = opt_iter + 1; 92
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  96
err_offset = opt_iter + 3; 98
if ( tag_len > CIPSO_V4_TAG_RNG_BLEN && cipso_v4_map_cat_rng_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  101
err_offset = opt_iter + 4; 105
if ( skb == NULL || ! ( skb -> dev -> flags & IFF_LOOPBACK ) )  115
err_offset = opt_iter; 116
if ( tag_len != CIPSO_V4_TAG_LOC_BLEN )  119
err_offset = opt_iter + 1; 120
err_offset = opt_iter; 125
tag += tag_len; 129
opt_iter += tag_len; 130
* option = opt + err_offset; 136
------------------------------
101 ../data/NVD/CVE_2013_0310_PATCHED_cipso_v4_validate.c tag = opt + opt_iter 27
int CVE_2013_0310_PATCHED_cipso_v4_validate(const struct sk_buff *skb, unsigned char **option) 1
unsigned char * opt = * option ; 3
unsigned char * tag ; 4
unsigned char opt_iter ; 5
u8 opt_len ; 7
opt_len = opt [ 1 ]; 13
if ( opt_len < 8 )  14
doi_def = cipso_v4_doi_search ( get_unaligned_be32 ( & opt [ 2 ] ) ); 20
if ( doi_def == NULL )  21
opt_iter = CIPSO_V4_HDR_LEN; 26
tag = opt + opt_iter; 27
while ( opt_iter < opt_len )  28
for (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];) 29
err_offset = opt_iter; 32
tag_len = tag [ 1 ]; 36
if ( tag_len > ( opt_len - opt_iter ) )  37
err_offset = opt_iter + 1; 38
switch ( tag [ 0 ] )  42
if ( tag_len < CIPSO_V4_TAG_RBM_BLEN )  44
err_offset = opt_iter + 1; 45
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  57
err_offset = opt_iter + 3; 59
if ( tag_len > CIPSO_V4_TAG_RBM_BLEN && cipso_v4_map_cat_rbm_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  62
err_offset = opt_iter + 4; 66
if ( tag_len < CIPSO_V4_TAG_ENUM_BLEN )  72
err_offset = opt_iter + 1; 73
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  77
err_offset = opt_iter + 3; 79
if ( tag_len > CIPSO_V4_TAG_ENUM_BLEN && cipso_v4_map_cat_enum_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  82
err_offset = opt_iter + 4; 86
if ( tag_len < CIPSO_V4_TAG_RNG_BLEN )  91
err_offset = opt_iter + 1; 92
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  96
err_offset = opt_iter + 3; 98
if ( tag_len > CIPSO_V4_TAG_RNG_BLEN && cipso_v4_map_cat_rng_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  101
err_offset = opt_iter + 4; 105
err_offset = opt_iter; 116
if ( tag_len != CIPSO_V4_TAG_LOC_BLEN )  119
err_offset = opt_iter + 1; 120
err_offset = opt_iter; 125
tag += tag_len; 129
opt_iter += tag_len; 130
* option = opt + err_offset; 136
return err_offset ; 137
------------------------------
102 ../data/NVD/CVE_2013_0310_VULN_cipso_v4_validate.c * option = opt + err_offset 134
int CVE_2013_0310_VULN_cipso_v4_validate(const struct sk_buff *skb, unsigned char **option) 1
unsigned char * opt = * option ; 3
unsigned char * tag ; 4
unsigned char opt_iter ; 5
unsigned char err_offset = 0 ; 6
u8 opt_len ; 7
u8 tag_len ; 8
u32 tag_iter ; 10
opt_len = opt [ 1 ]; 13
if ( opt_len < 8 )  14
err_offset = 1; 15
doi_def = cipso_v4_doi_search ( get_unaligned_be32 ( & opt [ 2 ] ) ); 20
if ( doi_def == NULL )  21
err_offset = 2; 22
opt_iter = CIPSO_V4_HDR_LEN; 26
tag = opt + opt_iter; 27
while ( opt_iter < opt_len )  28
for (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];) 29
if ( doi_def -> tags [ tag_iter ] == CIPSO_V4_TAG_INVALID || ++ tag_iter == CIPSO_V4_TAG_MAXCNT )  30
err_offset = opt_iter; 32
tag_len = tag [ 1 ]; 36
if ( tag_len > ( opt_len - opt_iter ) )  37
err_offset = opt_iter + 1; 38
switch ( tag [ 0 ] )  42
if ( tag_len < CIPSO_V4_TAG_RBM_BLEN )  44
err_offset = opt_iter + 1; 45
if ( cipso_v4_rbm_strictvalid )  56
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  57
err_offset = opt_iter + 3; 59
if ( tag_len > CIPSO_V4_TAG_RBM_BLEN && cipso_v4_map_cat_rbm_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  62
err_offset = opt_iter + 4; 66
if ( tag_len < CIPSO_V4_TAG_ENUM_BLEN )  72
err_offset = opt_iter + 1; 73
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  77
err_offset = opt_iter + 3; 79
if ( tag_len > CIPSO_V4_TAG_ENUM_BLEN && cipso_v4_map_cat_enum_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  82
err_offset = opt_iter + 4; 86
if ( tag_len < CIPSO_V4_TAG_RNG_BLEN )  91
err_offset = opt_iter + 1; 92
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  96
err_offset = opt_iter + 3; 98
if ( tag_len > CIPSO_V4_TAG_RNG_BLEN && cipso_v4_map_cat_rng_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  101
err_offset = opt_iter + 4; 105
if ( ! ( skb -> dev -> flags & IFF_LOOPBACK ) )  113
err_offset = opt_iter; 114
if ( tag_len != CIPSO_V4_TAG_LOC_BLEN )  117
err_offset = opt_iter + 1; 118
err_offset = opt_iter; 123
tag += tag_len; 127
opt_iter += tag_len; 128
* option = opt + err_offset; 134
------------------------------
103 ../data/NVD/CVE_2013_0310_VULN_cipso_v4_validate.c tag = opt + opt_iter 27
int CVE_2013_0310_VULN_cipso_v4_validate(const struct sk_buff *skb, unsigned char **option) 1
unsigned char * opt = * option ; 3
unsigned char * tag ; 4
unsigned char opt_iter ; 5
u8 opt_len ; 7
opt_len = opt [ 1 ]; 13
if ( opt_len < 8 )  14
doi_def = cipso_v4_doi_search ( get_unaligned_be32 ( & opt [ 2 ] ) ); 20
if ( doi_def == NULL )  21
opt_iter = CIPSO_V4_HDR_LEN; 26
tag = opt + opt_iter; 27
while ( opt_iter < opt_len )  28
for (tag_iter = 0; doi_def->tags[tag_iter] != tag[0];) 29
err_offset = opt_iter; 32
tag_len = tag [ 1 ]; 36
if ( tag_len > ( opt_len - opt_iter ) )  37
err_offset = opt_iter + 1; 38
switch ( tag [ 0 ] )  42
if ( tag_len < CIPSO_V4_TAG_RBM_BLEN )  44
err_offset = opt_iter + 1; 45
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  57
err_offset = opt_iter + 3; 59
if ( tag_len > CIPSO_V4_TAG_RBM_BLEN && cipso_v4_map_cat_rbm_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  62
err_offset = opt_iter + 4; 66
if ( tag_len < CIPSO_V4_TAG_ENUM_BLEN )  72
err_offset = opt_iter + 1; 73
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  77
err_offset = opt_iter + 3; 79
if ( tag_len > CIPSO_V4_TAG_ENUM_BLEN && cipso_v4_map_cat_enum_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  82
err_offset = opt_iter + 4; 86
if ( tag_len < CIPSO_V4_TAG_RNG_BLEN )  91
err_offset = opt_iter + 1; 92
if ( cipso_v4_map_lvl_valid ( doi_def , tag [ 3 ] ) < 0 )  96
err_offset = opt_iter + 3; 98
if ( tag_len > CIPSO_V4_TAG_RNG_BLEN && cipso_v4_map_cat_rng_valid ( doi_def , & tag [ 4 ] , tag_len - 4 ) < 0 )  101
err_offset = opt_iter + 4; 105
err_offset = opt_iter; 114
if ( tag_len != CIPSO_V4_TAG_LOC_BLEN )  117
err_offset = opt_iter + 1; 118
err_offset = opt_iter; 123
tag += tag_len; 127
opt_iter += tag_len; 128
* option = opt + err_offset; 134
return err_offset ; 135
------------------------------
104 ../data/NVD/CVE_2013_0311_PATCHED_translate_desc.c _iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ) 27
static int CVE_2013_0311_PATCHED_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
struct iovec * _iov ; 6
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
_iov = iov + ret; 24
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len - s , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
105 ../data/NVD/CVE_2013_0311_PATCHED_translate_desc.c _iov -> iov_len = min ( ( u64 ) len - s , size ) 26
static int CVE_2013_0311_PATCHED_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
struct iovec * _iov ; 6
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
_iov = iov + ret; 24
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len - s , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
106 ../data/NVD/CVE_2013_0311_PATCHED_translate_desc.c size = reg -> memory_size - addr + reg -> guest_phys_addr 25
static int CVE_2013_0311_PATCHED_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len - s , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
107 ../data/NVD/CVE_2013_0311_PATCHED_translate_desc.c _iov = iov + ret 24
static int CVE_2013_0311_PATCHED_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
struct iovec * _iov ; 6
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
_iov = iov + ret; 24
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len - s , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
108 ../data/NVD/CVE_2013_0311_VULN_translate_desc.c _iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ) 27
static int CVE_2013_0311_VULN_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
struct iovec * _iov ; 6
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
_iov = iov + ret; 24
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
109 ../data/NVD/CVE_2013_0311_VULN_translate_desc.c size = reg -> memory_size - addr + reg -> guest_phys_addr 25
static int CVE_2013_0311_VULN_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
110 ../data/NVD/CVE_2013_0311_VULN_translate_desc.c _iov = iov + ret 24
static int CVE_2013_0311_VULN_translate_desc(struct vhost_dev *dev, u64 addr, u32 len,
struct iovec iov[], int iov_size) 2
const struct vhost_memory_region * reg ; 4
struct vhost_memory * mem ; 5
struct iovec * _iov ; 6
u64 s = 0 ; 7
int ret = 0 ; 8
mem = rcu_dereference ( dev -> memory ); 12
while ( ( u64 ) len > s )  13
u64 size ; 14
if ( unlikely ( ret >= iov_size ) )  15
reg = find_region ( mem , addr , len ); 19
if ( unlikely ( ! reg ) )  20
_iov = iov + ret; 24
size = reg -> memory_size - addr + reg -> guest_phys_addr; 25
_iov -> iov_len = min ( ( u64 ) len , size ); 26
_iov -> iov_base = ( void __user * ) ( unsigned long ) ( reg -> userspace_addr + addr - reg -> guest_phys_addr ); 27
s += size; 29
addr += size; 30
------------------------------
111 ../data/NVD/CVE_2013_0756_PATCHED_obj_toSource.c vlength = end - vchars - parenChomp 144
static JSBool
CVE_2013_0756_PATCHED_obj_toSource(JSContext *cx, unsigned argc, Value *vp) 2
CallArgs args = CallArgsFromVp ( argc , vp ) ; 4
RootedObject obj ( cx , ToObject ( cx , args . thisv ( ) ) ) ; 7
if ( ! obj )  8
bool outermost = ( cx -> cycleDetectorSet . count ( ) == 0 ) ; 12
AutoCycleDetector detector ( cx , obj ) ; 14
if ( ! detector . init ( ) )  15
if ( detector . foundCycle ( ) )  17
StringBuffer buf ( cx ) ; 25
if ( outermost && ! buf . append ( '(' ) )  26
if ( ! buf . append ( '{' ) )  28
Value val [ 2 ] ; 31
JSString * gsop [ 2 ] ; 35
AutoIdVector idv ( cx ) ; 38
if ( ! GetPropertyNames ( cx , obj , JSITER_OWNONLY , & idv ) )  39
bool comma = false ; 42
for (size_t i = 0; i < idv.length(); ++i) 43
RootedId id ( cx , idv [ i ] ) ; 44
RootedObject obj2 ( cx ) ; 45
RootedShape shape ( cx ) ; 46
if ( ! JSObject :: lookupGeneric ( cx , obj , id , & obj2 , & shape ) )  47
int valcnt = 0 ; 51
if ( shape )  52
bool doGet = true ; 53
if ( obj2 -> isNative ( ) )  54
unsigned attrs = shape -> attributes ( ) ; 55
if ( attrs & JSPROP_GETTER )  56
doGet = false; 57
val [ valcnt ] = shape -> getterValue ( ); 58
gsop [ valcnt ] = cx -> runtime -> atomState . getAtom; 59
valcnt ++; 60
if ( attrs & JSPROP_SETTER )  62
doGet = false; 63
val [ valcnt ] = shape -> setterValue ( ); 64
gsop [ valcnt ] = cx -> runtime -> atomState . setAtom; 65
valcnt ++; 66
if ( doGet )  69
valcnt = 1; 70
gsop [ 0 ] = NULL; 71
MutableHandleValue vp = MutableHandleValue :: fromMarkedLocation ( & val [ 0 ] ) ; 72
if ( ! JSObject :: getGeneric ( cx , obj , obj , id , vp ) )  73
RawString s = ToString ( cx , IdToValue ( id ) ) ; 79
if ( ! s )  80
Rooted < JSLinearString * > idstr ( cx , s -> ensureLinear ( cx ) ) ; 82
if ( ! idstr )  83
if ( JSID_IS_ATOM ( id ) ? ! IsIdentifier ( idstr ) : ( ! JSID_IS_INT ( id ) || JSID_TO_INT ( id ) < 0 ) )  90
s = js_QuoteString ( cx , idstr , jschar ( '\'' ) ); 94
if ( ! s || ! ( idstr = s -> ensureLinear ( cx ) ) )  95
for (int j = 0; j < valcnt; j++) 99
if ( gsop [ j ] && val [ j ] . isUndefined ( ) )  104
RootedString valstr ( cx , js_ValueToSource ( cx , val [ j ] ) ) ; 108
if ( ! valstr )  109
const jschar * vchars = valstr -> getChars ( cx ) ; 111
if ( ! vchars )  112
size_t vlength = valstr -> length ( ) ; 114
if ( gsop [ j ] && IsFunctionObject ( val [ j ] ) )  120
const jschar * start = vchars ; 121
const jschar * end = vchars + vlength ; 122
uint8_t parenChomp = 0 ; 124
if ( vchars [ 0 ] == '(' )  125
vchars ++; 126
parenChomp = 1; 127
if ( vchars )  131
vchars = js_strchr_limit ( vchars , ' ' , end ); 132
if ( vchars )  138
vchars = js_strchr_limit ( vchars , '(' , end ); 139
if ( vchars )  141
if ( * vchars == ' ' )  142
vchars ++; 143
vlength = end - vchars - parenChomp; 144
gsop [ j ] = NULL; 146
vchars = start; 147
if ( comma && ! buf . append ( ", " ) )  151
comma = true; 153
if ( gsop [ j ] )  155
if ( ! buf . append ( gsop [ j ] ) || ! buf . append ( ' ' ) )  156
if ( ! buf . append ( idstr ) )  159
if ( ! buf . append ( gsop [ j ] ? ' ' : ':' ) )  161
if ( ! buf . append ( vchars , vlength ) )  164
------------------------------
112 ../data/NVD/CVE_2013_0756_VULN_obj_toSource.c vlength = end - vchars - parenChomp 182
static JSBool
CVE_2013_0756_VULN_obj_toSource(JSContext *cx, unsigned argc, Value *vp) 2
CallArgs args = CallArgsFromVp ( argc , vp ) ; 4
bool comma = false ; 6
const jschar * vchars ; 7
size_t vlength ; 8
Value * val ; 9
JSString * gsop [ 2 ] ; 10
Value localroot [ 4 ] ; 15
bool outermost = ( cx -> sharpObjectMap . depth == 0 ) ; 20
RootedObject obj ( cx , ToObject ( cx , args . thisv ( ) ) ) ; 22
if ( ! obj )  23
JSIdArray * ida ; 26
if ( ! js_EnterSharpObject ( cx , obj , & ida , & alreadySeen , & isSharp ) )  29
if ( ! ida )  32
StringBuffer buf ( cx ) ; 64
if ( outermost && ! buf . append ( '(' ) )  65
if ( ! buf . append ( '{' ) )  67
val = localroot + 2; 75
RootedId id ( cx ) ; 77
for (int i = 0; i < ida->length; i++) 78
id = ida -> vector [ i ]; 80
Rooted < JSLinearString * > idstr ( cx ) ; 81
RootedObject obj2 ( cx ) ; 83
RootedShape prop ( cx ) ; 84
if ( ! JSObject :: lookupGeneric ( cx , obj , id , & obj2 , & prop ) )  85
JSString * s = ToString ( cx , IdToValue ( id ) ) ; 92
if ( ! s || ! ( idstr = s -> ensureLinear ( cx ) ) )  93
int valcnt = 0 ; 96
if ( prop )  97
bool doGet = true ; 98
if ( obj2 -> isNative ( ) )  99
Shape * shape = ( Shape * ) prop ; 100
unsigned attrs = shape -> attributes ( ) ; 101
if ( attrs & JSPROP_GETTER )  102
doGet = false; 103
val [ valcnt ] = shape -> getterValue ( ); 104
gsop [ valcnt ] = cx -> runtime -> atomState . getAtom; 105
valcnt ++; 106
if ( attrs & JSPROP_SETTER )  108
doGet = false; 109
val [ valcnt ] = shape -> setterValue ( ); 110
gsop [ valcnt ] = cx -> runtime -> atomState . setAtom; 111
valcnt ++; 112
if ( doGet )  115
valcnt = 1; 116
gsop [ 0 ] = NULL; 117
MutableHandleValue vp = MutableHandleValue :: fromMarkedLocation ( & val [ 0 ] ) ; 118
if ( ! JSObject :: getGeneric ( cx , obj , obj , id , vp ) )  119
if ( JSID_IS_ATOM ( id ) ? ! IsIdentifier ( idstr ) : ( ! JSID_IS_INT ( id ) || JSID_TO_INT ( id ) < 0 ) )  128
s = js_QuoteString ( cx , idstr , jschar ( '\'' ) ); 131
if ( ! s || ! ( idstr = s -> ensureLinear ( cx ) ) )  132
for (int j = 0; j < valcnt; j++) 136
if ( gsop [ j ] && val [ j ] . isUndefined ( ) )  141
JSString * valstr = js_ValueToSource ( cx , val [ j ] ) ; 145
if ( ! valstr )  146
vchars = valstr -> getChars ( cx ); 149
if ( ! vchars )  150
vlength = valstr -> length ( ); 152
if ( gsop [ j ] && IsFunctionObject ( val [ j ] ) )  158
const jschar * start = vchars ; 159
const jschar * end = vchars + vlength ; 160
uint8_t parenChomp = 0 ; 162
if ( vchars [ 0 ] == '(' )  163
vchars ++; 164
parenChomp = 1; 165
if ( vchars )  169
vchars = js_strchr_limit ( vchars , ' ' , end ); 170
if ( vchars )  176
vchars = js_strchr_limit ( vchars , '(' , end ); 177
if ( vchars )  179
if ( * vchars == ' ' )  180
vchars ++; 181
vlength = end - vchars - parenChomp; 182
gsop [ j ] = NULL; 184
vchars = start; 185
if ( comma && ! buf . append ( ", " ) )  189
comma = true; 191
if ( gsop [ j ] )  193
if ( ! buf . append ( gsop [ j ] ) || ! buf . append ( ' ' ) )  194
if ( ! buf . append ( idstr ) )  197
if ( ! buf . append ( gsop [ j ] ? ' ' : ':' ) )  199
if ( ! buf . append ( vchars , vlength ) )  202
------------------------------
113 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c aMetrics . height = aMetrics . ascent + descent 402
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
uint32_t flowEndInTextRun ; 66
nsIFrame * lineContainer = aLineLayout . GetLineContainerFrame ( ) ; 67
gfxContext * ctx = aRenderingContext -> ThebesContext ( ) ; 68
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
gfxSkipCharsIterator iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ) ; 189
if ( mTextRun && iter . GetOriginalEnd ( ) < offset + length )  196
iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ); 202
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 229
gfxTextRun :: Metrics textMetrics ; 232
gfxFont :: BoundingBoxType boundingBoxType = IsFloatingFirstLetterChild ( ) ? gfxFont :: TIGHT_HINTED_OUTLINE_EXTENTS : gfxFont :: LOOSE_INK_EXTENTS ; 233
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
bool forceBreakAfter = false ; 241
if ( forceBreak >= offset + length )  242
forceBreakAfter = forceBreak == offset + length; 243
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
uint32_t transformedLength ; 253
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  254
transformedLength = flowEndInTextRun - transformedOffset; 259
gfxSkipCharsIterator iter ( provider . GetStart ( ) ) ; 263
transformedLength = iter . GetSkippedOffset ( ) - transformedOffset; 265
bool usedHyphenation ; 268
gfxFloat trimmedWidth = 0 ; 269
gfxFloat availWidth = aAvailableWidth ; 270
bool canTrimTrailingWhitespace = ! textStyle -> WhiteSpaceIsSignificant ( ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) ; 271
uint32_t transformedCharsFit = mTextRun -> BreakAndMeasureText ( transformedOffset , transformedLength , ( GetStateBits ( ) & TEXT_START_OF_LINE ) != 0 , availWidth , & provider , ! aLineLayout . LineIsBreakable ( ) , canTrimTrailingWhitespace ? & trimmedWidth : nullptr , & textMetrics , boundingBoxType , ctx , & usedHyphenation , & transformedLastBreak , textStyle -> WordCanWrap ( ) , & breakPriority ) ; 276
if ( ! length && ! textMetrics . mAscent && ! textMetrics . mDescent )  285
nsFontMetrics * fm = provider . GetFontMetrics ( ) ; 288
if ( fm )  289
textMetrics . mAscent = gfxFloat ( fm -> MaxAscent ( ) ); 290
textMetrics . mDescent = gfxFloat ( fm -> MaxDescent ( ) ); 291
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
if ( ( forceBreak >= 0 || forceBreakAfter ) && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  321
usedHyphenation = true; 323
bool brokeText = forceBreak >= 0 || transformedCharsFit < transformedLength ; 333
if ( canTrimTrailingWhitespace )  334
if ( brokeText || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  341
if ( ! ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  346
textMetrics . mAdvanceWidth += trimmedWidth; 351
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
if ( GetStateBits ( ) & TEXT_FIRST_LETTER )  377
textMetrics . mAscent = NS_MAX ( gfxFloat ( 0.0 ) , - textMetrics . mBoundingBox . Y ( ) ); 378
textMetrics . mDescent = NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mBoundingBox . YMost ( ) ); 379
aMetrics . width = NSToCoordCeil ( NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mAdvanceWidth ) ); 384
if ( transformedCharsFit == 0 && ! usedHyphenation )  386
if ( boundingBoxType != gfxFont :: LOOSE_INK_EXTENTS )  389
nsFontMetrics * fm = provider . GetFontMetrics ( ) ; 397
nscoord fontAscent = fm -> MaxAscent ( ) ; 398
nscoord fontDescent = fm -> MaxDescent ( ) ; 399
aMetrics . ascent = NS_MAX ( NSToCoordCeil ( textMetrics . mAscent ) , fontAscent ); 400
nscoord descent = NS_MAX ( NSToCoordCeil ( textMetrics . mDescent ) , fontDescent ) ; 401
aMetrics . height = aMetrics . ascent + descent; 402
NS_ASSERTION ( aMetrics . ascent >= 0 , "Negative ascent???" ); 405
NS_ASSERTION ( aMetrics . height - aMetrics . ascent >= 0 , "Negative descent???" ); 406
mAscent = aMetrics . ascent; 408
nsRect boundingBox = RoundOut ( textMetrics . mBoundingBox ) + nsPoint ( 0 , mAscent ) ; 411
aMetrics . SetOverflowAreasToDesiredBounds ( ); 412
aMetrics . VisualOverflow ( ) . UnionRect ( aMetrics . VisualOverflow ( ) , boundingBox ); 413
UnionAdditionalOverflow ( presContext , * aLineLayout . GetLineContainerRS ( ) , provider , & aMetrics . VisualOverflow ( ) , false ); 418
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
Invalidate ( aMetrics . VisualOverflow ( ) ); 522
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 526
------------------------------
114 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c aMetrics . height = aMetrics . ascent + NSToCoordCeil ( textMetrics . mDescent ) 392
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
uint32_t flowEndInTextRun ; 66
nsIFrame * lineContainer = aLineLayout . GetLineContainerFrame ( ) ; 67
gfxContext * ctx = aRenderingContext -> ThebesContext ( ) ; 68
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
gfxSkipCharsIterator iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ) ; 189
if ( mTextRun && iter . GetOriginalEnd ( ) < offset + length )  196
iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ); 202
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 229
gfxTextRun :: Metrics textMetrics ; 232
gfxFont :: BoundingBoxType boundingBoxType = IsFloatingFirstLetterChild ( ) ? gfxFont :: TIGHT_HINTED_OUTLINE_EXTENTS : gfxFont :: LOOSE_INK_EXTENTS ; 233
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
bool forceBreakAfter = false ; 241
if ( forceBreak >= offset + length )  242
forceBreakAfter = forceBreak == offset + length; 243
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
uint32_t transformedLength ; 253
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  254
transformedLength = flowEndInTextRun - transformedOffset; 259
gfxSkipCharsIterator iter ( provider . GetStart ( ) ) ; 263
transformedLength = iter . GetSkippedOffset ( ) - transformedOffset; 265
bool usedHyphenation ; 268
gfxFloat trimmedWidth = 0 ; 269
gfxFloat availWidth = aAvailableWidth ; 270
bool canTrimTrailingWhitespace = ! textStyle -> WhiteSpaceIsSignificant ( ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) ; 271
uint32_t transformedCharsFit = mTextRun -> BreakAndMeasureText ( transformedOffset , transformedLength , ( GetStateBits ( ) & TEXT_START_OF_LINE ) != 0 , availWidth , & provider , ! aLineLayout . LineIsBreakable ( ) , canTrimTrailingWhitespace ? & trimmedWidth : nullptr , & textMetrics , boundingBoxType , ctx , & usedHyphenation , & transformedLastBreak , textStyle -> WordCanWrap ( ) , & breakPriority ) ; 276
if ( ! length && ! textMetrics . mAscent && ! textMetrics . mDescent )  285
nsFontMetrics * fm = provider . GetFontMetrics ( ) ; 288
if ( fm )  289
textMetrics . mAscent = gfxFloat ( fm -> MaxAscent ( ) ); 290
textMetrics . mDescent = gfxFloat ( fm -> MaxDescent ( ) ); 291
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
if ( ( forceBreak >= 0 || forceBreakAfter ) && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  321
usedHyphenation = true; 323
bool brokeText = forceBreak >= 0 || transformedCharsFit < transformedLength ; 333
if ( canTrimTrailingWhitespace )  334
if ( brokeText || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  341
if ( ! ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  346
textMetrics . mAdvanceWidth += trimmedWidth; 351
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
if ( GetStateBits ( ) & TEXT_FIRST_LETTER )  377
textMetrics . mAscent = NS_MAX ( gfxFloat ( 0.0 ) , - textMetrics . mBoundingBox . Y ( ) ); 378
textMetrics . mDescent = NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mBoundingBox . YMost ( ) ); 379
aMetrics . width = NSToCoordCeil ( NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mAdvanceWidth ) ); 384
if ( transformedCharsFit == 0 && ! usedHyphenation )  386
if ( boundingBoxType != gfxFont :: LOOSE_INK_EXTENTS )  389
aMetrics . ascent = NSToCoordCeil ( textMetrics . mAscent ); 391
aMetrics . height = aMetrics . ascent + NSToCoordCeil ( textMetrics . mDescent ); 392
NS_ASSERTION ( aMetrics . ascent >= 0 , "Negative ascent???" ); 405
NS_ASSERTION ( aMetrics . height - aMetrics . ascent >= 0 , "Negative descent???" ); 406
mAscent = aMetrics . ascent; 408
nsRect boundingBox = RoundOut ( textMetrics . mBoundingBox ) + nsPoint ( 0 , mAscent ) ; 411
aMetrics . SetOverflowAreasToDesiredBounds ( ); 412
aMetrics . VisualOverflow ( ) . UnionRect ( aMetrics . VisualOverflow ( ) , boundingBox ); 413
UnionAdditionalOverflow ( presContext , * aLineLayout . GetLineContainerRS ( ) , provider , & aMetrics . VisualOverflow ( ) , false ); 418
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
Invalidate ( aMetrics . VisualOverflow ( ) ); 522
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 526
------------------------------
115 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c lastBreak = end . ConvertSkippedToOriginal ( transformedOffset + transformedLastBreak ) 316
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 229
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
if ( forceBreak >= offset + length )  242
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
uint32_t transformedLastBreak = 0 ; 267
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
if ( transformedLastBreak != PR_UINT32_MAX )  313
lastBreak = end . ConvertSkippedToOriginal ( transformedOffset + transformedLastBreak ); 316
if ( ! brokeText && lastBreak >= 0 )  361
aLineLayout . NotifyOptionalBreakPosition ( mContent , lastBreak , true , breakPriority ); 366
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
------------------------------
116 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c transformedLength = flowEndInTextRun - transformedOffset 259
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
uint32_t flowEndInTextRun ; 66
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 229
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
if ( forceBreak >= offset + length )  242
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
uint32_t transformedLength ; 253
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  254
transformedLength = flowEndInTextRun - transformedOffset; 259
uint32_t transformedCharsFit = mTextRun -> BreakAndMeasureText ( transformedOffset , transformedLength , ( GetStateBits ( ) & TEXT_START_OF_LINE ) != 0 , availWidth , & provider , ! aLineLayout . LineIsBreakable ( ) , canTrimTrailingWhitespace ? & trimmedWidth : nullptr , & textMetrics , boundingBoxType , ctx , & usedHyphenation , & transformedLastBreak , textStyle -> WordCanWrap ( ) , & breakPriority ) ; 276
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
end . SetSkippedOffset ( transformedOffset + transformedCharsFit ); 298
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
bool brokeText = forceBreak >= 0 || transformedCharsFit < transformedLength ; 333
if ( brokeText || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  341
if ( ! brokeText && lastBreak >= 0 )  361
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
if ( transformedCharsFit == 0 && ! usedHyphenation )  386
if ( transformedCharsFit > 0 )  430
if ( ! breakAfter && charsFit == length && ! emptyTextAtStartOfLine && transformedOffset + transformedLength == mTextRun -> GetLength ( ) && ( mTextRun -> GetFlags ( ) & nsTextFrameUtils :: TEXT_HAS_TRAILING_BREAK ) )  445
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
------------------------------
117 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c limitLength = forceBreak - offset 248
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
if ( forceBreak >= offset + length )  242
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
NS_ASSERTION ( limitLength >= 0 , "Weird break found!" ); 249
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  254
NS_ASSERTION ( offset + limitLength == int32_t ( frag -> GetLength ( ) ) , "Content offset/length out of bounds" ); 255
iter . SetOriginalOffset ( offset + limitLength ); 264
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
end . SetOriginalOffset ( offset + charsFit ); 318
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
if ( charsFit > 0 && charsFit == length && textStyle -> mHyphens != NS_STYLE_HYPHENS_NONE && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  434
if ( ! breakAfter && charsFit == length && ! emptyTextAtStartOfLine && transformedOffset + transformedLength == mTextRun -> GetLength ( ) && ( mTextRun -> GetFlags ( ) & nsTextFrameUtils :: TEXT_HAS_TRAILING_BREAK ) )  445
aStatus = contentLength == maxContentLength ? NS_FRAME_COMPLETE : NS_FRAME_NOT_COMPLETE; 465
if ( charsFit == 0 && length > 0 && ! usedHyphenation )  468
if ( contentLength > 0 && mContentOffset + contentLength - 1 == newLineOffset )  471
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 473
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 476
aStatus |= NS_INLINE_BREAK_FIRST_LETTER_COMPLETE; 480
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
int32_t numJustifiableCharacters = provider . ComputeJustifiableCharacters ( offset , charsFit ) ; 511
NS_ASSERTION ( numJustifiableCharacters <= charsFit , "Bad justifiable character count" ); 514
aLineLayout . SetTextJustificationWeights ( numJustifiableCharacters , charsFit - numJustifiableCharacters ); 516
SetLength ( contentLength , & aLineLayout , ALLOW_FRAME_CREATION_AND_DESTRUCTION ); 520
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 526
------------------------------
118 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c forceBreakAfter = forceBreak == offset + length 243
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
if ( forceBreak >= offset + length )  242
forceBreakAfter = forceBreak == offset + length; 243
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
if ( ( forceBreak >= 0 || forceBreakAfter ) && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  321
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
bool breakAfter = forceBreakAfter ; 442
if ( ! breakAfter && charsFit == length && ! emptyTextAtStartOfLine && transformedOffset + transformedLength == mTextRun -> GetLength ( ) && ( mTextRun -> GetFlags ( ) & nsTextFrameUtils :: TEXT_HAS_TRAILING_BREAK ) )  445
if ( breakAfter )  475
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
------------------------------
119 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c aMetrics . height = aMetrics . ascent + descent 395
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
uint32_t flowEndInTextRun ; 66
nsIFrame * lineContainer = aLineLayout . GetLineContainerFrame ( ) ; 67
gfxContext * ctx = aRenderingContext -> ThebesContext ( ) ; 68
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
gfxSkipCharsIterator iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ) ; 182
if ( mTextRun && iter . GetOriginalEnd ( ) < offset + length )  189
iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ); 195
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 222
gfxTextRun :: Metrics textMetrics ; 225
gfxFont :: BoundingBoxType boundingBoxType = IsFloatingFirstLetterChild ( ) ? gfxFont :: TIGHT_HINTED_OUTLINE_EXTENTS : gfxFont :: LOOSE_INK_EXTENTS ; 226
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
bool forceBreakAfter = false ; 234
if ( forceBreak >= offset + length )  235
forceBreakAfter = forceBreak == offset + length; 236
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
uint32_t transformedLength ; 246
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  247
transformedLength = flowEndInTextRun - transformedOffset; 252
gfxSkipCharsIterator iter ( provider . GetStart ( ) ) ; 256
transformedLength = iter . GetSkippedOffset ( ) - transformedOffset; 258
bool usedHyphenation ; 261
gfxFloat trimmedWidth = 0 ; 262
gfxFloat availWidth = aAvailableWidth ; 263
bool canTrimTrailingWhitespace = ! textStyle -> WhiteSpaceIsSignificant ( ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) ; 264
uint32_t transformedCharsFit = mTextRun -> BreakAndMeasureText ( transformedOffset , transformedLength , ( GetStateBits ( ) & TEXT_START_OF_LINE ) != 0 , availWidth , & provider , ! aLineLayout . LineIsBreakable ( ) , canTrimTrailingWhitespace ? & trimmedWidth : nullptr , & textMetrics , boundingBoxType , ctx , & usedHyphenation , & transformedLastBreak , textStyle -> WordCanWrap ( ) , & breakPriority ) ; 269
if ( ! length && ! textMetrics . mAscent && ! textMetrics . mDescent )  278
nsFontMetrics * fm = provider . GetFontMetrics ( ) ; 281
if ( fm )  282
textMetrics . mAscent = gfxFloat ( fm -> MaxAscent ( ) ); 283
textMetrics . mDescent = gfxFloat ( fm -> MaxDescent ( ) ); 284
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
if ( ( forceBreak >= 0 || forceBreakAfter ) && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  314
usedHyphenation = true; 316
bool brokeText = forceBreak >= 0 || transformedCharsFit < transformedLength ; 326
if ( canTrimTrailingWhitespace )  327
if ( brokeText || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  334
if ( ! ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  339
textMetrics . mAdvanceWidth += trimmedWidth; 344
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
if ( GetStateBits ( ) & TEXT_FIRST_LETTER )  370
textMetrics . mAscent = NS_MAX ( gfxFloat ( 0.0 ) , - textMetrics . mBoundingBox . Y ( ) ); 371
textMetrics . mDescent = NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mBoundingBox . YMost ( ) ); 372
aMetrics . width = NSToCoordCeil ( NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mAdvanceWidth ) ); 377
if ( transformedCharsFit == 0 && ! usedHyphenation )  379
if ( boundingBoxType != gfxFont :: LOOSE_INK_EXTENTS )  382
nsFontMetrics * fm = provider . GetFontMetrics ( ) ; 390
nscoord fontAscent = fm -> MaxAscent ( ) ; 391
nscoord fontDescent = fm -> MaxDescent ( ) ; 392
aMetrics . ascent = NS_MAX ( NSToCoordCeil ( textMetrics . mAscent ) , fontAscent ); 393
nscoord descent = NS_MAX ( NSToCoordCeil ( textMetrics . mDescent ) , fontDescent ) ; 394
aMetrics . height = aMetrics . ascent + descent; 395
NS_ASSERTION ( aMetrics . ascent >= 0 , "Negative ascent???" ); 398
NS_ASSERTION ( aMetrics . height - aMetrics . ascent >= 0 , "Negative descent???" ); 399
mAscent = aMetrics . ascent; 401
nsRect boundingBox = RoundOut ( textMetrics . mBoundingBox ) + nsPoint ( 0 , mAscent ) ; 404
aMetrics . SetOverflowAreasToDesiredBounds ( ); 405
aMetrics . VisualOverflow ( ) . UnionRect ( aMetrics . VisualOverflow ( ) , boundingBox ); 406
UnionAdditionalOverflow ( presContext , * aLineLayout . GetLineContainerRS ( ) , provider , & aMetrics . VisualOverflow ( ) , false ); 411
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
Invalidate ( aMetrics . VisualOverflow ( ) ); 515
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 519
------------------------------
120 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c aMetrics . height = aMetrics . ascent + NSToCoordCeil ( textMetrics . mDescent ) 385
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
uint32_t flowEndInTextRun ; 66
nsIFrame * lineContainer = aLineLayout . GetLineContainerFrame ( ) ; 67
gfxContext * ctx = aRenderingContext -> ThebesContext ( ) ; 68
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
gfxSkipCharsIterator iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ) ; 182
if ( mTextRun && iter . GetOriginalEnd ( ) < offset + length )  189
iter = EnsureTextRun ( nsTextFrame :: eInflated , ctx , lineContainer , aLineLayout . GetLine ( ) , & flowEndInTextRun ); 195
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 222
gfxTextRun :: Metrics textMetrics ; 225
gfxFont :: BoundingBoxType boundingBoxType = IsFloatingFirstLetterChild ( ) ? gfxFont :: TIGHT_HINTED_OUTLINE_EXTENTS : gfxFont :: LOOSE_INK_EXTENTS ; 226
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
bool forceBreakAfter = false ; 234
if ( forceBreak >= offset + length )  235
forceBreakAfter = forceBreak == offset + length; 236
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
uint32_t transformedLength ; 246
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  247
transformedLength = flowEndInTextRun - transformedOffset; 252
gfxSkipCharsIterator iter ( provider . GetStart ( ) ) ; 256
transformedLength = iter . GetSkippedOffset ( ) - transformedOffset; 258
bool usedHyphenation ; 261
gfxFloat trimmedWidth = 0 ; 262
gfxFloat availWidth = aAvailableWidth ; 263
bool canTrimTrailingWhitespace = ! textStyle -> WhiteSpaceIsSignificant ( ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) ; 264
uint32_t transformedCharsFit = mTextRun -> BreakAndMeasureText ( transformedOffset , transformedLength , ( GetStateBits ( ) & TEXT_START_OF_LINE ) != 0 , availWidth , & provider , ! aLineLayout . LineIsBreakable ( ) , canTrimTrailingWhitespace ? & trimmedWidth : nullptr , & textMetrics , boundingBoxType , ctx , & usedHyphenation , & transformedLastBreak , textStyle -> WordCanWrap ( ) , & breakPriority ) ; 269
if ( ! length && ! textMetrics . mAscent && ! textMetrics . mDescent )  278
nsFontMetrics * fm = provider . GetFontMetrics ( ) ; 281
if ( fm )  282
textMetrics . mAscent = gfxFloat ( fm -> MaxAscent ( ) ); 283
textMetrics . mDescent = gfxFloat ( fm -> MaxDescent ( ) ); 284
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
if ( ( forceBreak >= 0 || forceBreakAfter ) && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  314
usedHyphenation = true; 316
bool brokeText = forceBreak >= 0 || transformedCharsFit < transformedLength ; 326
if ( canTrimTrailingWhitespace )  327
if ( brokeText || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  334
if ( ! ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  339
textMetrics . mAdvanceWidth += trimmedWidth; 344
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
if ( GetStateBits ( ) & TEXT_FIRST_LETTER )  370
textMetrics . mAscent = NS_MAX ( gfxFloat ( 0.0 ) , - textMetrics . mBoundingBox . Y ( ) ); 371
textMetrics . mDescent = NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mBoundingBox . YMost ( ) ); 372
aMetrics . width = NSToCoordCeil ( NS_MAX ( gfxFloat ( 0.0 ) , textMetrics . mAdvanceWidth ) ); 377
if ( transformedCharsFit == 0 && ! usedHyphenation )  379
if ( boundingBoxType != gfxFont :: LOOSE_INK_EXTENTS )  382
aMetrics . ascent = NSToCoordCeil ( textMetrics . mAscent ); 384
aMetrics . height = aMetrics . ascent + NSToCoordCeil ( textMetrics . mDescent ); 385
NS_ASSERTION ( aMetrics . ascent >= 0 , "Negative ascent???" ); 398
NS_ASSERTION ( aMetrics . height - aMetrics . ascent >= 0 , "Negative descent???" ); 399
mAscent = aMetrics . ascent; 401
nsRect boundingBox = RoundOut ( textMetrics . mBoundingBox ) + nsPoint ( 0 , mAscent ) ; 404
aMetrics . SetOverflowAreasToDesiredBounds ( ); 405
aMetrics . VisualOverflow ( ) . UnionRect ( aMetrics . VisualOverflow ( ) , boundingBox ); 406
UnionAdditionalOverflow ( presContext , * aLineLayout . GetLineContainerRS ( ) , provider , & aMetrics . VisualOverflow ( ) , false ); 411
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
Invalidate ( aMetrics . VisualOverflow ( ) ); 515
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 519
------------------------------
121 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c lastBreak = end . ConvertSkippedToOriginal ( transformedOffset + transformedLastBreak ) 309
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 222
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
if ( forceBreak >= offset + length )  235
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
uint32_t transformedLastBreak = 0 ; 260
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
if ( transformedLastBreak != PR_UINT32_MAX )  306
lastBreak = end . ConvertSkippedToOriginal ( transformedOffset + transformedLastBreak ); 309
if ( ! brokeText && lastBreak >= 0 )  354
aLineLayout . NotifyOptionalBreakPosition ( mContent , lastBreak , true , breakPriority ); 359
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
------------------------------
122 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c transformedLength = flowEndInTextRun - transformedOffset 252
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
uint32_t flowEndInTextRun ; 66
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
uint32_t transformedOffset = provider . GetStart ( ) . GetSkippedOffset ( ) ; 222
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
if ( forceBreak >= offset + length )  235
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
uint32_t transformedLength ; 246
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  247
transformedLength = flowEndInTextRun - transformedOffset; 252
uint32_t transformedCharsFit = mTextRun -> BreakAndMeasureText ( transformedOffset , transformedLength , ( GetStateBits ( ) & TEXT_START_OF_LINE ) != 0 , availWidth , & provider , ! aLineLayout . LineIsBreakable ( ) , canTrimTrailingWhitespace ? & trimmedWidth : nullptr , & textMetrics , boundingBoxType , ctx , & usedHyphenation , & transformedLastBreak , textStyle -> WordCanWrap ( ) , & breakPriority ) ; 269
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
end . SetSkippedOffset ( transformedOffset + transformedCharsFit ); 291
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
bool brokeText = forceBreak >= 0 || transformedCharsFit < transformedLength ; 326
if ( brokeText || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  334
if ( ! brokeText && lastBreak >= 0 )  354
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
if ( transformedCharsFit == 0 && ! usedHyphenation )  379
if ( transformedCharsFit > 0 )  423
if ( ! breakAfter && charsFit == length && ! emptyTextAtStartOfLine && transformedOffset + transformedLength == mTextRun -> GetLength ( ) && ( mTextRun -> GetFlags ( ) & nsTextFrameUtils :: TEXT_HAS_TRAILING_BREAK ) )  438
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
------------------------------
123 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c limitLength = forceBreak - offset 241
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
if ( forceBreak >= offset + length )  235
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
NS_ASSERTION ( limitLength >= 0 , "Weird break found!" ); 242
if ( offset + limitLength >= int32_t ( frag -> GetLength ( ) ) )  247
NS_ASSERTION ( offset + limitLength == int32_t ( frag -> GetLength ( ) ) , "Content offset/length out of bounds" ); 248
iter . SetOriginalOffset ( offset + limitLength ); 257
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
end . SetOriginalOffset ( offset + charsFit ); 311
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
if ( charsFit > 0 && charsFit == length && textStyle -> mHyphens != NS_STYLE_HYPHENS_NONE && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  427
if ( ! breakAfter && charsFit == length && ! emptyTextAtStartOfLine && transformedOffset + transformedLength == mTextRun -> GetLength ( ) && ( mTextRun -> GetFlags ( ) & nsTextFrameUtils :: TEXT_HAS_TRAILING_BREAK ) )  438
aStatus = contentLength == maxContentLength ? NS_FRAME_COMPLETE : NS_FRAME_NOT_COMPLETE; 458
if ( charsFit == 0 && length > 0 && ! usedHyphenation )  461
if ( contentLength > 0 && mContentOffset + contentLength - 1 == newLineOffset )  464
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 466
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 469
aStatus |= NS_INLINE_BREAK_FIRST_LETTER_COMPLETE; 473
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
int32_t numJustifiableCharacters = provider . ComputeJustifiableCharacters ( offset , charsFit ) ; 504
NS_ASSERTION ( numJustifiableCharacters <= charsFit , "Bad justifiable character count" ); 507
aLineLayout . SetTextJustificationWeights ( numJustifiableCharacters , charsFit - numJustifiableCharacters ); 509
SetLength ( contentLength , & aLineLayout , ALLOW_FRAME_CREATION_AND_DESTRUCTION ); 513
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 519
------------------------------
124 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c forceBreakAfter = forceBreak == offset + length 236
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
if ( forceBreak >= offset + length )  235
forceBreakAfter = forceBreak == offset + length; 236
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
if ( ( forceBreak >= 0 || forceBreakAfter ) && HasSoftHyphenBefore ( frag , mTextRun , offset , end ) )  314
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
bool breakAfter = forceBreakAfter ; 435
if ( ! breakAfter && charsFit == length && ! emptyTextAtStartOfLine && transformedOffset + transformedLength == mTextRun -> GetLength ( ) && ( mTextRun -> GetFlags ( ) & nsTextFrameUtils :: TEXT_HAS_TRAILING_BREAK ) )  438
if ( breakAfter )  468
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
------------------------------
125 ../data/NVD/CVE_2013_0772_PATCHED_nsGIFDecoder2__DoLzw.c rowend = rowp + mGIFStruct . width 36
bool
CVE_2013_0772_PATCHED_nsGIFDecoder2::DoLzw(const uint8_t *q) 2
if ( ! mGIFStruct . rows_remaining )  4
uint32_t bpr = mGIFStruct . width ; 26
if ( ! mGIFStruct . images_decoded )  27
bpr *= sizeof ( uint32_t ); 28
if ( ! OutputRow ( ) )  33
rowp = mImageData + mGIFStruct . irow * bpr; 35
rowend = rowp + mGIFStruct . width; 36
if ( rowp == rowend )  72
if ( rowp == rowend )  122
------------------------------
126 ../data/NVD/CVE_2013_0772_PATCHED_nsGIFDecoder2__DoLzw.c rowp = mImageData + mGIFStruct . irow * bpr 35
bool
CVE_2013_0772_PATCHED_nsGIFDecoder2::DoLzw(const uint8_t *q) 2
if ( ! mGIFStruct . rows_remaining )  4
uint32_t bpr = mGIFStruct . width ; 26
if ( ! mGIFStruct . images_decoded )  27
bpr *= sizeof ( uint32_t ); 28
if ( ! OutputRow ( ) )  33
rowp = mImageData + mGIFStruct . irow * bpr; 35
rowend = rowp + mGIFStruct . width; 36
* rowp ++ = suffix [ code ] & mColorMask; 71
if ( rowp == rowend )  72
* rowp ++ = * -- stackp & mColorMask; 121
if ( rowp == rowend )  122
mGIFStruct . rowp = rowp; 140
------------------------------
127 ../data/NVD/CVE_2013_0772_PATCHED_nsGIFDecoder2__OutputRow.c drow_end = drow_start + row_dup 25
uint32_t CVE_2013_0772_PATCHED_nsGIFDecoder2::OutputRow() 1
int drow_start , drow_end ; 3
drow_start = drow_end = mGIFStruct . irow; 4
if ( ( unsigned ) drow_start >= mGIFStruct . height )  7
if ( ! mGIFStruct . images_decoded )  12
if ( mGIFStruct . progressive_display && mGIFStruct . interlaced && ( mGIFStruct . ipass < 4 ) )  19
const uint32_t row_dup = 15 >> mGIFStruct . ipass ; 21
const uint32_t row_shift = row_dup >> 1 ; 22
drow_start -= row_shift; 24
drow_end = drow_start + row_dup; 25
if ( ( ( mGIFStruct . height - 1 ) - drow_end ) <= row_shift )  28
if ( ( unsigned ) drow_end >= mGIFStruct . height )  34
if ( drow_end > drow_start )  62
for (int r = drow_start; r <= drow_end; r++) 64
mCurrentRow = drow_end; 72
------------------------------
128 ../data/NVD/CVE_2013_0772_VULN_nsGIFDecoder2__DoLzw.c rowend = rowp + mGIFStruct . width 36
bool
CVE_2013_0772_VULN_nsGIFDecoder2::DoLzw(const uint8_t *q) 2
if ( ! mGIFStruct . rows_remaining )  4
uint32_t bpr = mGIFStruct . width ; 26
if ( ! mGIFStruct . images_decoded )  27
bpr *= sizeof ( uint32_t ); 28
if ( ! OutputRow ( ) )  33
rowp = mImageData + mGIFStruct . irow * bpr; 35
rowend = rowp + mGIFStruct . width; 36
if ( rowp == rowend )  72
if ( rowp == rowend )  122
------------------------------
129 ../data/NVD/CVE_2013_0772_VULN_nsGIFDecoder2__DoLzw.c rowp = mImageData + mGIFStruct . irow * bpr 35
bool
CVE_2013_0772_VULN_nsGIFDecoder2::DoLzw(const uint8_t *q) 2
if ( ! mGIFStruct . rows_remaining )  4
uint32_t bpr = mGIFStruct . width ; 26
if ( ! mGIFStruct . images_decoded )  27
bpr *= sizeof ( uint32_t ); 28
if ( ! OutputRow ( ) )  33
rowp = mImageData + mGIFStruct . irow * bpr; 35
rowend = rowp + mGIFStruct . width; 36
* rowp ++ = suffix [ code ]; 71
if ( rowp == rowend )  72
* rowp ++ = * -- stackp; 121
if ( rowp == rowend )  122
mGIFStruct . rowp = rowp; 140
------------------------------
130 ../data/NVD/CVE_2013_0772_VULN_nsGIFDecoder2__OutputRow.c drow_end = drow_start + row_dup 25
uint32_t CVE_2013_0772_VULN_nsGIFDecoder2::OutputRow() 1
int drow_start , drow_end ; 3
drow_start = drow_end = mGIFStruct . irow; 4
if ( ( unsigned ) drow_start >= mGIFStruct . height )  7
if ( ! mGIFStruct . images_decoded )  12
if ( mGIFStruct . progressive_display && mGIFStruct . interlaced && ( mGIFStruct . ipass < 4 ) )  19
const uint32_t row_dup = 15 >> mGIFStruct . ipass ; 21
const uint32_t row_shift = row_dup >> 1 ; 22
drow_start -= row_shift; 24
drow_end = drow_start + row_dup; 25
if ( ( ( mGIFStruct . height - 1 ) - drow_end ) <= row_shift )  28
if ( ( unsigned ) drow_end >= mGIFStruct . height )  34
if ( drow_end > drow_start )  70
for (int r = drow_start; r <= drow_end; r++) 72
mCurrentRow = drow_end; 80
------------------------------
131 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__DoCharsetConversion.c dstLength = bufferLength - pos2 80
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + RESERVE_FALLBACK_BYTES; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength + 1 ) ; 24
if ( ! dstPtr )  25
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 29
dstLength = bufferLength - pos2; 31
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 33
pos1 += srcLength ? srcLength : 1; 35
pos2 += dstLength; 36
dstPtr [ pos2 ] = '\0'; 37
if ( NS_ERROR_UENC_NOMAPPING != rv )  40
rv = NS_OK; 44
dstLength = bufferLength - pos2; 47
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 48
if ( NS_SUCCEEDED ( rv ) )  49
pos2 += dstLength; 50
dstPtr [ pos2 ] = '\0'; 51
srcLength = inStringLength - pos1; 54
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  57
uint32_t unMappedChar ; 58
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  59
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 61
pos1 ++; 62
unMappedChar = inString [ pos1 - 1 ]; 64
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 67
if ( NS_FAILED ( rv ) )  68
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 71
if ( NS_FAILED ( rv ) )  72
dstPtr [ pos2 ] = '\0'; 74
if ( NS_SUCCEEDED ( rv ) )  78
dstLength = bufferLength - pos2; 80
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 81
if ( NS_SUCCEEDED ( rv ) )  82
pos2 += dstLength; 83
dstPtr [ pos2 ] = '\0'; 84
if ( NS_FAILED ( rv ) )  88
PR_FREEIF ( dstPtr ); 89
return rv ; 90
* outString = dstPtr; 93
return rv ; 100
------------------------------
132 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__DoCharsetConversion.c rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ) 67
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + RESERVE_FALLBACK_BYTES; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength + 1 ) ; 24
if ( ! dstPtr )  25
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 29
dstLength = bufferLength - pos2; 31
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 33
pos1 += srcLength ? srcLength : 1; 35
pos2 += dstLength; 36
dstPtr [ pos2 ] = '\0'; 37
if ( NS_ERROR_UENC_NOMAPPING != rv )  40
rv = NS_OK; 44
dstLength = bufferLength - pos2; 47
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 48
if ( NS_SUCCEEDED ( rv ) )  49
pos2 += dstLength; 50
dstPtr [ pos2 ] = '\0'; 51
srcLength = inStringLength - pos1; 54
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  57
uint32_t unMappedChar ; 58
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  59
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 61
pos1 ++; 62
unMappedChar = inString [ pos1 - 1 ]; 64
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 67
if ( NS_FAILED ( rv ) )  68
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 71
if ( NS_FAILED ( rv ) )  72
if ( NS_SUCCEEDED ( rv ) )  78
if ( NS_FAILED ( rv ) )  88
return rv ; 90
return rv ; 100
------------------------------
133 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__DoCharsetConversion.c srcLength = inStringLength - pos1 54
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + RESERVE_FALLBACK_BYTES; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength + 1 ) ; 24
if ( ! dstPtr )  25
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 29
dstLength = bufferLength - pos2; 31
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 33
pos1 += srcLength ? srcLength : 1; 35
pos2 += dstLength; 36
dstPtr [ pos2 ] = '\0'; 37
if ( NS_ERROR_UENC_NOMAPPING != rv )  40
saveResult = rv; 43
rv = NS_OK; 44
dstLength = bufferLength - pos2; 47
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 48
if ( NS_SUCCEEDED ( rv ) )  49
pos2 += dstLength; 50
dstPtr [ pos2 ] = '\0'; 51
srcLength = inStringLength - pos1; 54
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  57
uint32_t unMappedChar ; 58
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  59
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 61
pos1 ++; 62
unMappedChar = inString [ pos1 - 1 ]; 64
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 67
if ( NS_FAILED ( rv ) )  68
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 71
if ( NS_FAILED ( rv ) )  72
if ( NS_SUCCEEDED ( rv ) )  78
if ( NS_FAILED ( rv ) )  88
return rv ; 90
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  96
return rv ; 100
------------------------------
134 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__DoCharsetConversion.c dstLength = bufferLength - pos2 47
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + RESERVE_FALLBACK_BYTES; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength + 1 ) ; 24
if ( ! dstPtr )  25
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 29
dstLength = bufferLength - pos2; 31
NS_ASSERTION ( dstLength >= 0 , "out of bounds write" ); 32
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 33
pos1 += srcLength ? srcLength : 1; 35
pos2 += dstLength; 36
dstPtr [ pos2 ] = '\0'; 37
if ( NS_ERROR_UENC_NOMAPPING != rv )  40
saveResult = rv; 43
rv = NS_OK; 44
dstLength = bufferLength - pos2; 47
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 48
if ( NS_SUCCEEDED ( rv ) )  49
pos2 += dstLength; 50
dstPtr [ pos2 ] = '\0'; 51
srcLength = inStringLength - pos1; 54
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  57
uint32_t unMappedChar ; 58
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  59
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 61
pos1 ++; 62
unMappedChar = inString [ pos1 - 1 ]; 64
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 67
if ( NS_FAILED ( rv ) )  68
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 71
if ( NS_FAILED ( rv ) )  72
dstPtr [ pos2 ] = '\0'; 74
if ( NS_SUCCEEDED ( rv ) )  78
dstLength = bufferLength - pos2; 80
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 81
if ( NS_SUCCEEDED ( rv ) )  82
pos2 += dstLength; 83
dstPtr [ pos2 ] = '\0'; 84
if ( NS_FAILED ( rv ) )  88
PR_FREEIF ( dstPtr ); 89
return rv ; 90
* outString = dstPtr; 93
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  96
return rv ; 100
------------------------------
135 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__DoCharsetConversion.c dstLength = bufferLength - pos2 31
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + RESERVE_FALLBACK_BYTES; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength + 1 ) ; 24
if ( ! dstPtr )  25
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 29
dstLength = bufferLength - pos2; 31
NS_ASSERTION ( dstLength >= 0 , "out of bounds write" ); 32
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 33
pos1 += srcLength ? srcLength : 1; 35
pos2 += dstLength; 36
dstPtr [ pos2 ] = '\0'; 37
if ( NS_ERROR_UENC_NOMAPPING != rv )  40
saveResult = rv; 43
rv = NS_OK; 44
dstLength = bufferLength - pos2; 47
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 48
if ( NS_SUCCEEDED ( rv ) )  49
pos2 += dstLength; 50
dstPtr [ pos2 ] = '\0'; 51
srcLength = inStringLength - pos1; 54
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  57
uint32_t unMappedChar ; 58
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  59
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 61
pos1 ++; 62
unMappedChar = inString [ pos1 - 1 ]; 64
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 67
if ( NS_FAILED ( rv ) )  68
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 71
if ( NS_FAILED ( rv ) )  72
dstPtr [ pos2 ] = '\0'; 74
if ( NS_SUCCEEDED ( rv ) )  78
dstLength = bufferLength - pos2; 80
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 81
if ( NS_SUCCEEDED ( rv ) )  82
pos2 += dstLength; 83
dstPtr [ pos2 ] = '\0'; 84
if ( NS_FAILED ( rv ) )  88
PR_FREEIF ( dstPtr ); 89
return rv ; 90
* outString = dstPtr; 93
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  96
return rv ; 100
------------------------------
136 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__DoCharsetConversion.c bufferLength = dstLength + RESERVE_FALLBACK_BYTES 20
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t dstLength ; 12
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + RESERVE_FALLBACK_BYTES; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength + 1 ) ; 24
if ( ! dstPtr )  25
dstLength = bufferLength - pos2; 31
NS_ASSERTION ( dstLength >= 0 , "out of bounds write" ); 32
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 33
pos2 += dstLength; 36
dstPtr [ pos2 ] = '\0'; 37
if ( NS_ERROR_UENC_NOMAPPING != rv )  40
saveResult = rv; 43
dstLength = bufferLength - pos2; 47
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 48
if ( NS_SUCCEEDED ( rv ) )  49
pos2 += dstLength; 50
dstPtr [ pos2 ] = '\0'; 51
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 67
if ( NS_FAILED ( rv ) )  68
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 71
if ( NS_FAILED ( rv ) )  72
dstPtr [ pos2 ] = '\0'; 74
if ( NS_SUCCEEDED ( rv ) )  78
dstLength = bufferLength - pos2; 80
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 81
if ( NS_SUCCEEDED ( rv ) )  82
pos2 += dstLength; 83
dstPtr [ pos2 ] = '\0'; 84
if ( NS_FAILED ( rv ) )  88
PR_FREEIF ( dstPtr ); 89
return rv ; 90
* outString = dstPtr; 93
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  96
return rv ; 100
------------------------------
137 ../data/NVD/CVE_2013_0782_VULN_nsSaveAsCharset__DoCharsetConversion.c dstLength = bufferLength - pos2 73
NS_IMETHODIMP
CVE_2013_0782_VULN_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + 512; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength ) ; 21
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 23
dstLength = bufferLength - pos2; 25
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 26
pos1 += srcLength ? srcLength : 1; 28
pos2 += dstLength; 29
if ( NS_ERROR_UENC_NOMAPPING != rv )  33
rv = NS_OK; 37
dstLength = bufferLength - pos2; 40
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 41
if ( NS_SUCCEEDED ( rv ) )  42
pos2 += dstLength; 43
dstPtr [ pos2 ] = '\0'; 44
srcLength = inStringLength - pos1; 47
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  50
uint32_t unMappedChar ; 51
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  52
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 54
pos1 ++; 55
unMappedChar = inString [ pos1 - 1 ]; 57
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 60
if ( NS_FAILED ( rv ) )  61
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 64
if ( NS_FAILED ( rv ) )  65
dstPtr [ pos2 ] = '\0'; 67
if ( NS_SUCCEEDED ( rv ) )  71
dstLength = bufferLength - pos2; 73
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 74
if ( NS_SUCCEEDED ( rv ) )  75
pos2 += dstLength; 76
dstPtr [ pos2 ] = '\0'; 77
if ( NS_FAILED ( rv ) )  81
PR_FREEIF ( dstPtr ); 82
return rv ; 83
* outString = dstPtr; 86
return rv ; 93
------------------------------
138 ../data/NVD/CVE_2013_0782_VULN_nsSaveAsCharset__DoCharsetConversion.c rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ) 60
NS_IMETHODIMP
CVE_2013_0782_VULN_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + 512; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength ) ; 21
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 23
dstLength = bufferLength - pos2; 25
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 26
pos1 += srcLength ? srcLength : 1; 28
pos2 += dstLength; 29
if ( NS_ERROR_UENC_NOMAPPING != rv )  33
rv = NS_OK; 37
dstLength = bufferLength - pos2; 40
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 41
if ( NS_SUCCEEDED ( rv ) )  42
pos2 += dstLength; 43
dstPtr [ pos2 ] = '\0'; 44
srcLength = inStringLength - pos1; 47
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  50
uint32_t unMappedChar ; 51
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  52
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 54
pos1 ++; 55
unMappedChar = inString [ pos1 - 1 ]; 57
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 60
if ( NS_FAILED ( rv ) )  61
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 64
if ( NS_FAILED ( rv ) )  65
if ( NS_SUCCEEDED ( rv ) )  71
if ( NS_SUCCEEDED ( rv ) )  75
if ( NS_FAILED ( rv ) )  81
return rv ; 83
return rv ; 93
------------------------------
139 ../data/NVD/CVE_2013_0782_VULN_nsSaveAsCharset__DoCharsetConversion.c srcLength = inStringLength - pos1 47
NS_IMETHODIMP
CVE_2013_0782_VULN_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + 512; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength ) ; 21
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 23
dstLength = bufferLength - pos2; 25
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 26
pos1 += srcLength ? srcLength : 1; 28
pos2 += dstLength; 29
if ( NS_ERROR_UENC_NOMAPPING != rv )  33
saveResult = rv; 36
rv = NS_OK; 37
dstLength = bufferLength - pos2; 40
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 41
if ( NS_SUCCEEDED ( rv ) )  42
pos2 += dstLength; 43
dstPtr [ pos2 ] = '\0'; 44
srcLength = inStringLength - pos1; 47
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  50
uint32_t unMappedChar ; 51
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  52
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 54
pos1 ++; 55
unMappedChar = inString [ pos1 - 1 ]; 57
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 60
if ( NS_FAILED ( rv ) )  61
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 64
if ( NS_FAILED ( rv ) )  65
if ( NS_SUCCEEDED ( rv ) )  71
if ( NS_SUCCEEDED ( rv ) )  75
if ( NS_FAILED ( rv ) )  81
return rv ; 83
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  89
return rv ; 93
------------------------------
140 ../data/NVD/CVE_2013_0782_VULN_nsSaveAsCharset__DoCharsetConversion.c dstLength = bufferLength - pos2 40
NS_IMETHODIMP
CVE_2013_0782_VULN_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + 512; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength ) ; 21
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 23
dstLength = bufferLength - pos2; 25
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 26
pos1 += srcLength ? srcLength : 1; 28
pos2 += dstLength; 29
dstPtr [ pos2 ] = '\0'; 30
if ( NS_ERROR_UENC_NOMAPPING != rv )  33
saveResult = rv; 36
rv = NS_OK; 37
dstLength = bufferLength - pos2; 40
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 41
if ( NS_SUCCEEDED ( rv ) )  42
pos2 += dstLength; 43
dstPtr [ pos2 ] = '\0'; 44
srcLength = inStringLength - pos1; 47
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  50
uint32_t unMappedChar ; 51
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  52
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 54
pos1 ++; 55
unMappedChar = inString [ pos1 - 1 ]; 57
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 60
if ( NS_FAILED ( rv ) )  61
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 64
if ( NS_FAILED ( rv ) )  65
dstPtr [ pos2 ] = '\0'; 67
if ( NS_SUCCEEDED ( rv ) )  71
dstLength = bufferLength - pos2; 73
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 74
if ( NS_SUCCEEDED ( rv ) )  75
pos2 += dstLength; 76
dstPtr [ pos2 ] = '\0'; 77
if ( NS_FAILED ( rv ) )  81
PR_FREEIF ( dstPtr ); 82
return rv ; 83
* outString = dstPtr; 86
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  89
return rv ; 93
------------------------------
141 ../data/NVD/CVE_2013_0782_VULN_nsSaveAsCharset__DoCharsetConversion.c dstLength = bufferLength - pos2 25
NS_IMETHODIMP
CVE_2013_0782_VULN_nsSaveAsCharset::DoCharsetConversion(const PRUnichar *inString, char **outString) 2
nsresult rv ; 8
int32_t inStringLength = NS_strlen ( inString ) ; 9
int32_t bufferLength ; 10
int32_t srcLength = inStringLength ; 11
int32_t dstLength ; 12
int32_t pos1 , pos2 ; 13
rv = mEncoder -> GetMaxLength ( inString , inStringLength , & dstLength ); 17
if ( NS_FAILED ( rv ) )  18
bufferLength = dstLength + 512; 20
char * dstPtr = ( char * ) PR_Malloc ( bufferLength ) ; 21
for (pos1 = 0, pos2 = 0; pos1 < inStringLength;) 23
dstLength = bufferLength - pos2; 25
rv = mEncoder -> Convert ( & inString [ pos1 ] , & srcLength , & dstPtr [ pos2 ] , & dstLength ); 26
pos1 += srcLength ? srcLength : 1; 28
pos2 += dstLength; 29
dstPtr [ pos2 ] = '\0'; 30
if ( NS_ERROR_UENC_NOMAPPING != rv )  33
saveResult = rv; 36
rv = NS_OK; 37
dstLength = bufferLength - pos2; 40
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 41
if ( NS_SUCCEEDED ( rv ) )  42
pos2 += dstLength; 43
dstPtr [ pos2 ] = '\0'; 44
srcLength = inStringLength - pos1; 47
if ( ! ATTR_NO_FALLBACK ( mAttribute ) )  50
uint32_t unMappedChar ; 51
if ( NS_IS_HIGH_SURROGATE ( inString [ pos1 - 1 ] ) && inStringLength > pos1 && NS_IS_LOW_SURROGATE ( inString [ pos1 ] ) )  52
unMappedChar = SURROGATE_TO_UCS4 ( inString [ pos1 - 1 ] , inString [ pos1 ] ); 54
pos1 ++; 55
unMappedChar = inString [ pos1 - 1 ]; 57
rv = mEncoder -> GetMaxLength ( inString + pos1 , inStringLength - pos1 , & dstLength ); 60
if ( NS_FAILED ( rv ) )  61
rv = HandleFallBack ( unMappedChar , & dstPtr , & bufferLength , & pos2 , dstLength ); 64
if ( NS_FAILED ( rv ) )  65
dstPtr [ pos2 ] = '\0'; 67
if ( NS_SUCCEEDED ( rv ) )  71
dstLength = bufferLength - pos2; 73
rv = mEncoder -> Finish ( & dstPtr [ pos2 ] , & dstLength ); 74
if ( NS_SUCCEEDED ( rv ) )  75
pos2 += dstLength; 76
dstPtr [ pos2 ] = '\0'; 77
if ( NS_FAILED ( rv ) )  81
PR_FREEIF ( dstPtr ); 82
return rv ; 83
* outString = dstPtr; 86
if ( NS_ERROR_UENC_NOMAPPING == saveResult )  89
return rv ; 93
------------------------------
142 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ) 679
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
int previous_sample , current_sample , next_sample ; 444
int coeff1 , coeff2 ; 445
int shift ; 446
unsigned int channel ; 447
int count = 0 ; 449
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R1 )  461
current_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 462
previous_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 463
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
for (count1 = 0; count1 < nb_samples / 28; count1++) 469
int byte = bytestream2_get_byte ( & gb ) ; 470
if ( byte == 0xEE )  471
current_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 472
previous_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 473
coeff1 = ea_adpcm_table [ byte >> 4 ]; 480
coeff2 = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 481
shift = 20 - ( byte & 0x0F ); 482
for (count2=0; count2<28; count2++) 484
if ( count2 & 1 )  485
next_sample = sign_extend ( byte , 4 ) << shift; 486
byte = bytestream2_get_byte ( & gb ); 488
next_sample = sign_extend ( byte >> 4 , 4 ) << shift; 489
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
if ( ! count )  503
count = count1; 504
if ( count != count1 )  505
count = FFMAX ( count , count1 ); 507
if ( avctx -> codec -> id != AV_CODEC_ID_ADPCM_EA_R1 )  510
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
c -> frame . nb_samples = count * 28; 516
for (channel=0; channel<avctx->channels; channel++) 521
int coeff [ 2 ] [ 4 ] , shift [ 4 ] 522
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
int val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ) ; 525
for (i=0; i<2; i++) 526
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 530
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
for (m=2; m<32; m+=2) 535
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 552
c -> status [ 0 ] . step_index = bytestream2_get_le16u ( & gb ); 553
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 556
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 557
if ( c -> status [ 0 ] . step_index > 88u )  560
for (n = nb_samples >> (1 - st); n > 0; n--) 566
int hi , lo , v = bytestream2_get_byteu ( & gb ) ; 567
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
hi = v & 0x0F; 570
lo = v >> 4; 571
lo = v & 0x0F; 573
hi = v >> 4; 574
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
int v = bytestream2_get_byteu ( & gb ) ; 583
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
if ( ! c -> status [ 0 ] . step_index )  591
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
c -> status [ 0 ] . step_index = 1; 596
nb_samples --; 597
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
int byte = bytestream2_get_byteu ( & gb ) ; 601
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
for (n = nb_samples / 3; n > 0; n--) 608
int byte = bytestream2_get_byteu ( & gb ) ; 609
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
int byte = bytestream2_get_byteu ( & gb ) ; 619
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
for (n = nb_samples >> (1 - st); n > 0; n--) 636
int v = bytestream2_get_byteu ( & gb ) ; 637
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
int table [ 2 ] [ 16 ]
int prev [ 2 ] [ 2 ] 645
int ch ; 646
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
samples = ( short * ) c -> frame . data [ 0 ] + ch; 658
for (i = 0; i < nb_samples / 14; i++) 661
int byte = bytestream2_get_byteu ( & gb ) ; 662
int index = ( byte >> 4 ) & 7 ; 663
unsigned int exp = byte & 0x0F ; 664
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
int32_t sampledat ; 670
if ( n & 1 )  672
sampledat = sign_extend ( byte , 4 ); 673
byte = bytestream2_get_byteu ( & gb ); 675
sampledat = sign_extend ( byte >> 4 , 4 ); 676
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
143 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ) 543
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
int previous_sample , current_sample , next_sample ; 444
int coeff1 , coeff2 ; 445
int shift ; 446
unsigned int channel ; 447
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R1 )  461
current_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 462
previous_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 463
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
for (count1 = 0; count1 < nb_samples / 28; count1++) 469
int byte = bytestream2_get_byte ( & gb ) ; 470
if ( byte == 0xEE )  471
current_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 472
previous_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 473
coeff1 = ea_adpcm_table [ byte >> 4 ]; 480
coeff2 = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 481
shift = 20 - ( byte & 0x0F ); 482
for (count2=0; count2<28; count2++) 484
if ( count2 & 1 )  485
next_sample = sign_extend ( byte , 4 ) << shift; 486
byte = bytestream2_get_byte ( & gb ); 488
next_sample = sign_extend ( byte >> 4 , 4 ) << shift; 489
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
if ( avctx -> codec -> id != AV_CODEC_ID_ADPCM_EA_R1 )  510
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
for (channel=0; channel<avctx->channels; channel++) 521
int coeff [ 2 ] [ 4 ] , shift [ 4 ] 522
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
int val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ) ; 525
for (i=0; i<2; i++) 526
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 530
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
for (m=2; m<32; m+=2) 535
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
int byte = bytestream2_get_byteu ( & gb ) ; 538
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
------------------------------
144 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c s = & samples [ m * avctx -> channels + channel ] 536
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
int previous_sample , current_sample , next_sample ; 444
int coeff1 , coeff2 ; 445
int shift ; 446
unsigned int channel ; 447
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R1 )  461
current_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 462
previous_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 463
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
for (count1 = 0; count1 < nb_samples / 28; count1++) 469
int byte = bytestream2_get_byte ( & gb ) ; 470
if ( byte == 0xEE )  471
current_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 472
previous_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 473
coeff1 = ea_adpcm_table [ byte >> 4 ]; 480
coeff2 = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 481
shift = 20 - ( byte & 0x0F ); 482
for (count2=0; count2<28; count2++) 484
if ( count2 & 1 )  485
next_sample = sign_extend ( byte , 4 ) << shift; 486
byte = bytestream2_get_byte ( & gb ); 488
next_sample = sign_extend ( byte >> 4 , 4 ) << shift; 489
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
if ( avctx -> codec -> id != AV_CODEC_ID_ADPCM_EA_R1 )  510
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
for (channel=0; channel<avctx->channels; channel++) 521
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
int val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ) ; 525
s [ 0 ] = val & ~0x0F; 528
val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 530
s [ avctx -> channels ] = val & ~0x0F; 532
for (m=2; m<32; m+=2) 535
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
for (n = nb_samples >> (1 - st); n > 0; n--) 566
for (n = nb_samples >> (1 - st); n > 0; n--) 582
for (n = nb_samples >> (1 - st); n > 0; n--) 600
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
145 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c samplesC = samples + channel 459
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
unsigned int channel ; 447
uint16_t * samplesC ; 448
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
------------------------------
146 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8 424
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
if ( avctx -> channels != 2 )  362
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
byte = bytestream2_get_byteu ( & gb ); 377
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
bytestream2_seek ( & gb , offsets [ channel ] , SEEK_SET ); 458
samplesC = samples + channel; 459
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
c -> frame . nb_samples = count * 28; 516
for (channel=0; channel<avctx->channels; channel++) 521
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 552
c -> status [ 0 ] . step_index = bytestream2_get_le16u ( & gb ); 553
if ( c -> status [ 0 ] . step_index > 88u )  560
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
if ( ! c -> status [ 0 ] . step_index )  591
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
samples = ( short * ) c -> frame . data [ 0 ] + ch; 658
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
* ( AVFrame * ) data = c -> frame; 699
------------------------------
147 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8 389
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
switch ( avctx -> codec -> id )  40
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
148 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8 386
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
switch ( avctx -> codec -> id )  40
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
149 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor 254
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
150 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor 253
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
151 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2 252
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
int diff_channel ; 202
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
diff_channel = c -> status [ 1 ] . predictor; 216
while ( samples < samples_end )  229
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 243
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 252
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
------------------------------
152 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor 245
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
153 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor 244
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
154 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2 243
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
int diff_channel ; 202
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
diff_channel = c -> status [ 1 ] . predictor; 216
while ( samples < samples_end )  229
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 243
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 252
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
------------------------------
155 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ) 679
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
int previous_sample , current_sample , next_sample ; 444
int coeff1 , coeff2 ; 445
int shift ; 446
unsigned int channel ; 447
int count = 0 ; 449
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R1 )  461
current_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 462
previous_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 463
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
for (count1 = 0; count1 < nb_samples / 28; count1++) 469
int byte = bytestream2_get_byte ( & gb ) ; 470
if ( byte == 0xEE )  471
current_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 472
previous_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 473
coeff1 = ea_adpcm_table [ byte >> 4 ]; 480
coeff2 = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 481
shift = 20 - ( byte & 0x0F ); 482
for (count2=0; count2<28; count2++) 484
if ( count2 & 1 )  485
next_sample = sign_extend ( byte , 4 ) << shift; 486
byte = bytestream2_get_byte ( & gb ); 488
next_sample = sign_extend ( byte >> 4 , 4 ) << shift; 489
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
if ( ! count )  503
count = count1; 504
if ( count != count1 )  505
count = FFMAX ( count , count1 ); 507
if ( avctx -> codec -> id != AV_CODEC_ID_ADPCM_EA_R1 )  510
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
c -> frame . nb_samples = count * 28; 516
for (channel=0; channel<avctx->channels; channel++) 521
int coeff [ 2 ] [ 4 ] , shift [ 4 ] 522
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
int val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ) ; 525
for (i=0; i<2; i++) 526
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 530
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
for (m=2; m<32; m+=2) 535
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 552
c -> status [ 0 ] . step_index = bytestream2_get_le16u ( & gb ); 553
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 556
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 557
if ( c -> status [ 0 ] . step_index > 88u )  560
for (n = nb_samples >> (1 - st); n > 0; n--) 566
int hi , lo , v = bytestream2_get_byteu ( & gb ) ; 567
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
hi = v & 0x0F; 570
lo = v >> 4; 571
lo = v & 0x0F; 573
hi = v >> 4; 574
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
int v = bytestream2_get_byteu ( & gb ) ; 583
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
if ( ! c -> status [ 0 ] . step_index )  591
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
c -> status [ 0 ] . step_index = 1; 596
nb_samples --; 597
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
int byte = bytestream2_get_byteu ( & gb ) ; 601
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
for (n = nb_samples / 3; n > 0; n--) 608
int byte = bytestream2_get_byteu ( & gb ) ; 609
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
int byte = bytestream2_get_byteu ( & gb ) ; 619
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
for (n = nb_samples >> (1 - st); n > 0; n--) 636
int v = bytestream2_get_byteu ( & gb ) ; 637
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
int table [ 2 ] [ 16 ]
int prev [ 2 ] [ 2 ] 645
int ch ; 646
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
samples = ( short * ) c -> frame . data [ 0 ] + ch; 658
for (i = 0; i < nb_samples / 14; i++) 661
int byte = bytestream2_get_byteu ( & gb ) ; 662
int index = ( byte >> 4 ) & 7 ; 663
unsigned int exp = byte & 0x0F ; 664
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
int32_t sampledat ; 670
if ( n & 1 )  672
sampledat = sign_extend ( byte , 4 ); 673
byte = bytestream2_get_byteu ( & gb ); 675
sampledat = sign_extend ( byte >> 4 , 4 ); 676
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
156 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ) 543
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
int previous_sample , current_sample , next_sample ; 444
int coeff1 , coeff2 ; 445
int shift ; 446
unsigned int channel ; 447
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R1 )  461
current_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 462
previous_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 463
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
for (count1 = 0; count1 < nb_samples / 28; count1++) 469
int byte = bytestream2_get_byte ( & gb ) ; 470
if ( byte == 0xEE )  471
current_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 472
previous_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 473
coeff1 = ea_adpcm_table [ byte >> 4 ]; 480
coeff2 = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 481
shift = 20 - ( byte & 0x0F ); 482
for (count2=0; count2<28; count2++) 484
if ( count2 & 1 )  485
next_sample = sign_extend ( byte , 4 ) << shift; 486
byte = bytestream2_get_byte ( & gb ); 488
next_sample = sign_extend ( byte >> 4 , 4 ) << shift; 489
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
if ( avctx -> codec -> id != AV_CODEC_ID_ADPCM_EA_R1 )  510
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
for (channel=0; channel<avctx->channels; channel++) 521
int coeff [ 2 ] [ 4 ] , shift [ 4 ] 522
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
int val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ) ; 525
for (i=0; i<2; i++) 526
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 530
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
for (m=2; m<32; m+=2) 535
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
int byte = bytestream2_get_byteu ( & gb ) ; 538
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
------------------------------
157 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c s = & samples [ m * avctx -> channels + channel ] 536
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
int previous_sample , current_sample , next_sample ; 444
int coeff1 , coeff2 ; 445
int shift ; 446
unsigned int channel ; 447
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R1 )  461
current_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 462
previous_sample = sign_extend ( bytestream2_get_le16 ( & gb ) , 16 ); 463
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
for (count1 = 0; count1 < nb_samples / 28; count1++) 469
int byte = bytestream2_get_byte ( & gb ) ; 470
if ( byte == 0xEE )  471
current_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 472
previous_sample = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 473
coeff1 = ea_adpcm_table [ byte >> 4 ]; 480
coeff2 = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 481
shift = 20 - ( byte & 0x0F ); 482
for (count2=0; count2<28; count2++) 484
if ( count2 & 1 )  485
next_sample = sign_extend ( byte , 4 ) << shift; 486
byte = bytestream2_get_byte ( & gb ); 488
next_sample = sign_extend ( byte >> 4 , 4 ) << shift; 489
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
if ( avctx -> codec -> id != AV_CODEC_ID_ADPCM_EA_R1 )  510
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
for (channel=0; channel<avctx->channels; channel++) 521
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
int val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ) ; 525
s [ 0 ] = val & ~0x0F; 528
val = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 530
s [ avctx -> channels ] = val & ~0x0F; 532
for (m=2; m<32; m+=2) 535
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
for (n = nb_samples >> (1 - st); n > 0; n--) 566
for (n = nb_samples >> (1 - st); n > 0; n--) 582
for (n = nb_samples >> (1 - st); n > 0; n--) 600
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
158 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c samplesC = samples + channel 459
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
const uint8_t * buf = avpkt -> data ; 4
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
while ( bytestream2_get_bytes_left ( & gb ) >= 128 )  318
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
for (n = nb_samples >> (1 - st); n > 0; n--) 338
int byte = bytestream2_get_byteu ( & gb ) ; 339
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
int byte = bytestream2_get_byteu ( & gb ) ; 346
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
const int big_endian = avctx -> codec -> id == AV_CODEC_ID_ADPCM_EA_R3 ; 443
unsigned int channel ; 447
uint16_t * samplesC ; 448
int offsets [ 6 ] ; 450
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
------------------------------
159 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8 424
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (n = nb_samples / 2; n > 0; n--) 306
for (channel = 0; channel < avctx->channels; channel++) 307
int v = bytestream2_get_byteu ( & gb ) ; 308
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
for (i=0; i<=st; i++) 327
c -> status [ i ] . step_index = bytestream2_get_le32u ( & gb ); 328
if ( c -> status [ i ] . step_index > 88u )  329
for (i=0; i<=st; i++) 335
c -> status [ i ] . predictor = bytestream2_get_le32u ( & gb ); 336
if ( avctx -> channels != 2 )  362
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
byte = bytestream2_get_byteu ( & gb ); 377
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
int coeff [ 2 ] [ 2 ] , shift [ 2 ] 408
for(channel = 0; channel < avctx->channels; channel++) 410
int byte = bytestream2_get_byteu ( & gb ) ; 411
for (i=0; i<2; i++) 412
coeff [ channel ] [ i ] = ea_adpcm_table [ ( byte >> 4 ) + 4 * i ]; 413
shift [ channel ] = 20 - ( byte & 0x0F ); 414
for (count1 = 0; count1 < nb_samples / 2; count1++) 416
int byte [ 2 ] ; 417
byte [ 0 ] = bytestream2_get_byteu ( & gb ); 419
if ( st )  420
byte [ 1 ] = bytestream2_get_byteu ( & gb ); 420
for(i = 4; i >= 0; i-=4) 421
for(channel = 0; channel < avctx->channels; channel++) 422
int sample = sign_extend ( byte [ channel ] >> i , 4 ) << shift [ channel ] ; 423
sample = ( sample + c -> status [ channel ] . sample1 * coeff [ channel ] [ 0 ] + c -> status [ channel ] . sample2 * coeff [ channel ] [ 1 ] + 0x80 ) >> 8; 424
c -> status [ channel ] . sample2 = c -> status [ channel ] . sample1; 427
c -> status [ channel ] . sample1 = av_clip_int16 ( sample ); 428
* samples ++ = c -> status [ channel ] . sample1; 429
for (channel=0; channel<avctx->channels; channel++) 452
offsets [ channel ] = ( big_endian ? bytestream2_get_be32 ( & gb ) : bytestream2_get_le32 ( & gb ) ) + ( avctx -> channels + 1 ) * 4; 453
for (channel=0; channel<avctx->channels; channel++) 457
bytestream2_seek ( & gb , offsets [ channel ] , SEEK_SET ); 458
samplesC = samples + channel; 459
current_sample = c -> status [ channel ] . predictor; 465
previous_sample = c -> status [ channel ] . prev_sample; 466
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
next_sample += ( current_sample * coeff1 ) + ( previous_sample * coeff2 ); 492
next_sample = av_clip_int16 ( next_sample >> 8 ); 494
previous_sample = current_sample; 496
current_sample = next_sample; 497
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
c -> status [ channel ] . predictor = current_sample; 511
c -> status [ channel ] . prev_sample = previous_sample; 512
c -> frame . nb_samples = count * 28; 516
for (channel=0; channel<avctx->channels; channel++) 521
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 552
c -> status [ 0 ] . step_index = bytestream2_get_le16u ( & gb ); 553
if ( c -> status [ 0 ] . step_index > 88u )  560
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
if ( ! c -> status [ 0 ] . step_index )  591
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
samples = ( short * ) c -> frame . data [ 0 ] + ch; 658
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
* ( AVFrame * ) data = c -> frame; 699
------------------------------
160 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8 389
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
switch ( avctx -> codec -> id )  40
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 367
previous_right_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 368
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1r = ea_adpcm_table [ byte & 0x0F ]; 374
coeff2r = ea_adpcm_table [ ( byte & 0x0F ) + 4 ]; 375
byte = bytestream2_get_byteu ( & gb ); 377
shift_right = 20 - ( byte & 0x0F ); 379
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_right_sample = sign_extend ( byte , 4 ) << shift_right; 384
next_right_sample = ( next_right_sample + ( current_right_sample * coeff1r ) + ( previous_right_sample * coeff2r ) + 0x80 ) >> 8; 389
previous_right_sample = current_right_sample; 395
current_right_sample = av_clip_int16 ( next_right_sample ); 396
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
161 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8 386
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
int count1 , count2 ; 11
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
switch ( avctx -> codec -> id )  40
int previous_left_sample , previous_right_sample ; 353
int current_left_sample , current_right_sample ; 354
int next_left_sample , next_right_sample ; 355
int coeff1l , coeff2l , coeff1r , coeff2r ; 356
int shift_left , shift_right ; 357
if ( avctx -> channels != 2 )  362
current_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 365
previous_left_sample = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 366
for (count1 = 0; count1 < nb_samples / 28; count1++) 370
int byte = bytestream2_get_byteu ( & gb ) ; 371
coeff1l = ea_adpcm_table [ byte >> 4 ]; 372
coeff2l = ea_adpcm_table [ ( byte >> 4 ) + 4 ]; 373
byte = bytestream2_get_byteu ( & gb ); 377
shift_left = 20 - ( byte >> 4 ); 378
for (count2 = 0; count2 < 28; count2++) 381
byte = bytestream2_get_byteu ( & gb ); 382
next_left_sample = sign_extend ( byte >> 4 , 4 ) << shift_left; 383
next_left_sample = ( next_left_sample + ( current_left_sample * coeff1l ) + ( previous_left_sample * coeff2l ) + 0x80 ) >> 8; 386
previous_left_sample = current_left_sample; 393
current_left_sample = av_clip_int16 ( next_left_sample ); 394
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
162 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor 254
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
163 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor 253
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
164 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2 252
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
int diff_channel ; 202
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
diff_channel = c -> status [ 1 ] . predictor; 216
while ( samples < samples_end )  229
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 243
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 252
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
------------------------------
165 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor 245
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
166 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c * samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor 244
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 309
samples [ st ] = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 310
samples += avctx -> channels; 312
if ( ( ret = xa_decode ( avctx , samples , buf + bytestream2_tell ( & gb ) , & c -> status [ 0 ] , & c -> status [ 1 ] , avctx -> channels ) ) < 0 )  319
return ret ; 321
samples += 28 * 8; 323
for (i=0; i<=st; i++) 327
for (i=0; i<=st; i++) 335
for (n = nb_samples >> (1 - st); n > 0; n--) 338
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 3 ); 340
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 3 ); 341
for (n = nb_samples >> (1 - st); n > 0; n--) 345
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 6 ); 347
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 6 ); 348
* samples ++ = current_left_sample; 397
* samples ++ = current_right_sample; 398
if ( st )  420
* samples ++ = c -> status [ channel ] . sample1; 429
samplesC = samples + channel; 459
* samplesC = sign_extend ( bytestream2_get_be16 ( & gb ) , 16 ); 476
samplesC += avctx -> channels; 477
* samplesC = current_sample; 498
samplesC += avctx -> channels; 499
short * s2 , * s = & samples [ channel ] ; 523
for (n=0; n<4; n++, s+=32*avctx->channels) 524
coeff [ i ] [ n ] = ea_adpcm_table [ ( val & 0x0F ) + 4 * i ]; 527
s [ 0 ] = val & ~0x0F; 528
shift [ n ] = 20 - ( val & 0x0F ); 531
s [ avctx -> channels ] = val & ~0x0F; 532
s = & samples [ m * avctx -> channels + channel ]; 536
for (n=0; n<4; n++, s+=32*avctx->channels) 537
for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) 539
int level = sign_extend ( byte >> ( 4 - i ) , 4 ) << shift [ n ] ; 540
int pred = s2 [ - 1 * avctx -> channels ] * coeff [ 0 ] [ n ] + s2 [ - 2 * avctx -> channels ] * coeff [ 1 ] [ n ] ; 541
s2 [ 0 ] = av_clip_int16 ( ( level + pred + 0x80 ) >> 8 ); 543
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  551
av_log ( avctx , AV_LOG_ERROR , "ERROR: step_index = %i\n" , c -> status [ 0 ] . step_index ); 561
for (n = nb_samples >> (1 - st); n > 0; n--) 566
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_IMA_AMV )  569
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , lo , 3 ); 577
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , hi , 3 ); 578
for (n = nb_samples >> (1 - st); n > 0; n--) 582
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ 0 ] , v >> 4 ); 584
* samples ++ = adpcm_ct_expand_nibble ( & c -> status [ st ] , v & 0x0F ); 585
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 593
if ( st )  594
* samples ++ = 128 * ( bytestream2_get_byteu ( & gb ) - 0x80 ); 595
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_4 )  599
for (n = nb_samples >> (1 - st); n > 0; n--) 600
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 4 , 4 , 0 ); 602
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x0F , 4 , 0 ); 604
if ( avctx -> codec -> id == AV_CODEC_ID_ADPCM_SBPRO_3 )  607
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 5 , 3 , 0 ); 610
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x07 , 3 , 0 ); 612
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte & 0x03 , 2 , 0 ); 614
for (n = nb_samples >> (2 - st); n > 0; n--) 618
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , byte >> 6 , 2 , 2 ); 620
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , ( byte >> 4 ) & 0x03 , 2 , 2 ); 622
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ 0 ] , ( byte >> 2 ) & 0x03 , 2 , 2 ); 624
* samples ++ = adpcm_sbpro_expand_nibble ( & c -> status [ st ] , byte & 0x03 , 2 , 2 ); 626
adpcm_swf_decode ( avctx , buf , buf_size , samples ); 632
for (n = nb_samples >> (1 - st); n > 0; n--) 636
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ 0 ] , v & 0x0F ); 638
* samples ++ = adpcm_yamaha_expand_nibble ( & c -> status [ st ] , v >> 4 ); 639
for (i = 0; i < 2; i++) 648
for (n = 0; n < 16; n++) 649
table [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 650
for (i = 0; i < 2; i++) 653
for (n = 0; n < 2; n++) 654
prev [ i ] [ n ] = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 655
for (ch = 0; ch <= st; ch++) 657
for (i = 0; i < nb_samples / 14; i++) 661
int factor1 = table [ ch ] [ index * 2 ] ; 665
int factor2 = table [ ch ] [ index * 2 + 1 ] ; 666
for (n = 0; n < 14; n++) 669
if ( n & 1 )  672
sampledat = ( ( prev [ ch ] [ 0 ] * factor1 + prev [ ch ] [ 1 ] * factor2 ) >> 11 ) + ( sampledat << exp ); 679
* samples = av_clip_int16 ( sampledat ); 681
prev [ ch ] [ 1 ] = prev [ ch ] [ 0 ]; 682
prev [ ch ] [ 0 ] = * samples ++; 683
samples += st; 687
------------------------------
167 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2 243
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
int diff_channel ; 202
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
diff_channel = c -> status [ 1 ] . predictor; 216
while ( samples < samples_end )  229
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 243
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
diff_channel = ( diff_channel + c -> status [ 1 ] . predictor ) / 2; 252
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
------------------------------
168 ../data/NVD/CVE_2013_0850_PATCHED_decode_slice_header.c id_list [ i ] = h -> short_ref_count + k 750
static int CVE_2013_0850_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_dropable ; 10
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
last_pic_structure = s0 -> picture_structure; 316
last_pic_dropable = s -> dropable; 317
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> first_field )  369
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
if ( last_pic_dropable != s -> dropable )  410
s -> picture_structure = last_pic_structure; 414
s -> dropable = last_pic_dropable; 415
s0 -> current_picture_ptr -> owner2 = s0; 425
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( s0 -> first_field )  466
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
s0 -> current_picture_ptr = NULL; 475
s0 -> first_field = FIELD_PICTURE; 476
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
s0 -> first_field = 1; 484
s0 -> current_picture_ptr = NULL; 485
s0 -> first_field = 0; 488
s0 -> first_field = FIELD_PICTURE; 493
if ( ! FIELD_PICTURE || s0 -> first_field )  496
if ( ff_h264_frame_start ( h ) < 0 )  497
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
unsigned max [ 2 ] ; 557
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
h -> ref_count [ 1 ] = 1; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> list_count = 1; 582
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
h -> use_weight = 0; 612
for (i = 0; i < 2; i++) 613
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
h -> deblocking_filter = 0; 695
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
h -> deblocking_filter = 2; 701
h0 -> max_contexts = 1; 703
if ( ! h0 -> single_decode_warning )  704
h0 -> single_decode_warning = 1; 707
if ( h != h0 )  709
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h0 -> last_slice_type = slice_type; 723
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
for (j = 0; j < 2; j++) 735
int id_list [ 16 ] ; 736
for (i = 0; i < 16; i++) 738
id_list [ i ] = 60; 739
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
int k ; 741
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
------------------------------
169 ../data/NVD/CVE_2013_0850_PATCHED_decode_slice_header.c tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ) 646
static int CVE_2013_0850_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_dropable ; 10
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
last_pic_structure = s0 -> picture_structure; 316
last_pic_dropable = s -> dropable; 317
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> first_field )  369
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
if ( last_pic_dropable != s -> dropable )  410
s -> picture_structure = last_pic_structure; 414
s -> dropable = last_pic_dropable; 415
s0 -> current_picture_ptr -> owner2 = s0; 425
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( s0 -> first_field )  466
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
s0 -> current_picture_ptr = NULL; 475
s0 -> first_field = FIELD_PICTURE; 476
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
s0 -> first_field = 1; 484
s0 -> current_picture_ptr = NULL; 485
s0 -> first_field = 0; 488
s0 -> first_field = FIELD_PICTURE; 493
if ( ! FIELD_PICTURE || s0 -> first_field )  496
if ( ff_h264_frame_start ( h ) < 0 )  497
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
unsigned max [ 2 ] ; 557
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
h -> ref_count [ 1 ] = 1; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> list_count = 1; 582
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
h -> use_weight = 0; 612
for (i = 0; i < 2; i++) 613
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
170 ../data/NVD/CVE_2013_0850_PATCHED_decode_slice_header.c s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE 517
static int CVE_2013_0850_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_dropable ; 10
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
last_pic_structure = s0 -> picture_structure; 316
last_pic_dropable = s -> dropable; 317
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> first_field )  369
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
if ( last_pic_dropable != s -> dropable )  410
s -> picture_structure = last_pic_structure; 414
s -> dropable = last_pic_dropable; 415
s0 -> current_picture_ptr -> owner2 = s0; 425
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( s0 -> first_field )  466
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
s0 -> current_picture_ptr = NULL; 475
s0 -> first_field = FIELD_PICTURE; 476
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
s0 -> first_field = 1; 484
s0 -> current_picture_ptr = NULL; 485
s0 -> first_field = 0; 488
s0 -> first_field = FIELD_PICTURE; 493
if ( ! FIELD_PICTURE || s0 -> first_field )  496
if ( ff_h264_frame_start ( h ) < 0 )  497
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
assert ( s -> mb_y < s -> mb_height ); 520
if ( s -> picture_structure == PICT_FRAME )  522
get_ue_golomb ( & s -> gb ); 531
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
init_poc ( h ); 547
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
h -> ref_count [ 1 ] = 1; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 574
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
ff_h264_fill_default_ref_list ( h ); 587
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 597
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 601
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  626
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  632
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 639
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
171 ../data/NVD/CVE_2013_0850_PATCHED_decode_slice_header.c unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1 356
static int CVE_2013_0850_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
unsigned int slice_type , tmp , i , j ; 8
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
av_log ( h -> s . avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 433
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 0 ); 440
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 1 ); 441
ff_generate_sliding_window_mmcos ( h ); 442
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , s -> avctx -> pix_fmt , s -> mb_width * 16 , s -> mb_height * 16 ); 454
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
if ( ff_h264_frame_start ( h ) < 0 )  497
ff_release_unused_pictures ( s , 0 ); 502
if ( h != h0 )  505
clone_slice ( h , h0 ); 506
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
assert ( s -> mb_num == s -> mb_width * s -> mb_height ); 510
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
av_log ( h -> s . avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 513
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
assert ( s -> mb_y < s -> mb_height ); 520
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> nal_unit_type == NAL_IDR_SLICE )  530
get_ue_golomb ( & s -> gb ); 531
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
init_poc ( h ); 547
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
h -> ref_count [ 1 ] = 1; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 574
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
ff_h264_fill_default_ref_list ( h ); 587
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 597
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 601
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  626
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  632
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 639
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
172 ../data/NVD/CVE_2013_0850_PATCHED_decode_slice_header.c s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ) 327
static int CVE_2013_0850_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
unsigned int slice_type , tmp , i , j ; 8
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
if ( h -> sps . frame_mbs_only_flag )  319
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
av_log ( h -> s . avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , s -> picture_structure ); 338
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
av_log ( s -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , s -> picture_structure ); 404
if ( last_pic_dropable != s -> dropable )  410
av_log ( s -> avctx , AV_LOG_ERROR , "Cannot combine reference and non-reference fields in the same frame\n" ); 411
av_log_ask_for_sample ( s -> avctx , NULL ); 413
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
av_log ( h -> s . avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 433
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 0 ); 440
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 1 ); 441
ff_generate_sliding_window_mmcos ( h ); 442
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , s -> avctx -> pix_fmt , s -> mb_width * 16 , s -> mb_height * 16 ); 454
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
if ( ff_h264_frame_start ( h ) < 0 )  497
ff_release_unused_pictures ( s , 0 ); 502
if ( h != h0 )  505
clone_slice ( h , h0 ); 506
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
assert ( s -> mb_num == s -> mb_width * s -> mb_height ); 510
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
av_log ( h -> s . avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 513
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
assert ( s -> mb_y < s -> mb_height ); 520
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> nal_unit_type == NAL_IDR_SLICE )  530
get_ue_golomb ( & s -> gb ); 531
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
init_poc ( h ); 547
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
h -> ref_count [ 1 ] = 1; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 574
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
ff_h264_fill_default_ref_list ( h ); 587
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 597
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 601
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  626
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  632
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 639
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
173 ../data/NVD/CVE_2013_0850_VULN_decode_slice_header.c id_list [ i ] = h -> short_ref_count + k 750
static int CVE_2013_0850_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_dropable ; 10
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
last_pic_structure = s0 -> picture_structure; 316
last_pic_dropable = s -> dropable; 317
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> first_field )  369
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
if ( last_pic_dropable != s -> dropable )  410
s -> picture_structure = last_pic_structure; 414
s -> dropable = last_pic_dropable; 415
s0 -> current_picture_ptr -> owner2 = s0; 425
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( s0 -> first_field )  466
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
s0 -> current_picture_ptr = NULL; 475
s0 -> first_field = FIELD_PICTURE; 476
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
s0 -> first_field = 1; 484
s0 -> current_picture_ptr = NULL; 485
s0 -> first_field = 0; 488
s0 -> first_field = FIELD_PICTURE; 493
if ( ! FIELD_PICTURE || s0 -> first_field )  496
if ( ff_h264_frame_start ( h ) < 0 )  497
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
unsigned max [ 2 ] ; 557
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
max [ 1 ] = 31; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> list_count = 1; 582
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
h -> use_weight = 0; 612
for (i = 0; i < 2; i++) 613
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
h -> deblocking_filter = 0; 695
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
h -> deblocking_filter = 2; 701
h0 -> max_contexts = 1; 703
if ( ! h0 -> single_decode_warning )  704
h0 -> single_decode_warning = 1; 707
if ( h != h0 )  709
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h0 -> last_slice_type = slice_type; 723
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
for (j = 0; j < 2; j++) 735
int id_list [ 16 ] ; 736
for (i = 0; i < 16; i++) 738
id_list [ i ] = 60; 739
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
int k ; 741
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
id_list [ i ] = k; 745
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
for (i = 0; i < 16; i++) 758
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
------------------------------
174 ../data/NVD/CVE_2013_0850_VULN_decode_slice_header.c tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ) 646
static int CVE_2013_0850_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_dropable ; 10
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
last_pic_structure = s0 -> picture_structure; 316
last_pic_dropable = s -> dropable; 317
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> first_field )  369
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
if ( last_pic_dropable != s -> dropable )  410
s -> picture_structure = last_pic_structure; 414
s -> dropable = last_pic_dropable; 415
s0 -> current_picture_ptr -> owner2 = s0; 425
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( s0 -> first_field )  466
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
s0 -> current_picture_ptr = NULL; 475
s0 -> first_field = FIELD_PICTURE; 476
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
s0 -> first_field = 1; 484
s0 -> current_picture_ptr = NULL; 485
s0 -> first_field = 0; 488
s0 -> first_field = FIELD_PICTURE; 493
if ( ! FIELD_PICTURE || s0 -> first_field )  496
if ( ff_h264_frame_start ( h ) < 0 )  497
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
unsigned max [ 2 ] ; 557
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
max [ 1 ] = 31; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> list_count = 1; 582
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
h -> use_weight = 0; 612
for (i = 0; i < 2; i++) 613
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
h -> deblocking_filter = 0; 695
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
h -> deblocking_filter = 2; 701
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
for (i = 0; i < 16; i++) 758
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
175 ../data/NVD/CVE_2013_0850_VULN_decode_slice_header.c s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE 517
static int CVE_2013_0850_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_dropable ; 10
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
last_pic_structure = s0 -> picture_structure; 316
last_pic_dropable = s -> dropable; 317
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> first_field )  369
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
if ( last_pic_dropable != s -> dropable )  410
s -> picture_structure = last_pic_structure; 414
s -> dropable = last_pic_dropable; 415
s0 -> current_picture_ptr -> owner2 = s0; 425
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( s0 -> first_field )  466
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
s0 -> current_picture_ptr = NULL; 475
s0 -> first_field = FIELD_PICTURE; 476
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
s0 -> first_field = 1; 484
s0 -> current_picture_ptr = NULL; 485
s0 -> first_field = 0; 488
s0 -> first_field = FIELD_PICTURE; 493
if ( ! FIELD_PICTURE || s0 -> first_field )  496
if ( ff_h264_frame_start ( h ) < 0 )  497
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
assert ( s -> mb_y < s -> mb_height ); 520
if ( s -> picture_structure == PICT_FRAME )  522
get_ue_golomb ( & s -> gb ); 531
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
init_poc ( h ); 547
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
max [ 1 ] = 31; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 574
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
ff_h264_fill_default_ref_list ( h ); 587
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 597
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 601
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
pred_weight_table ( h ); 607
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
implicit_weight_table ( h , - 1 ); 610
h -> use_weight = 0; 612
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
ff_h264_fill_mbaff_ref_list ( h ); 624
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  626
implicit_weight_table ( h , 0 ); 627
implicit_weight_table ( h , 1 ); 628
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  632
ff_h264_direct_dist_scale_factor ( h ); 633
ff_h264_direct_ref_list_init ( h ); 634
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 639
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
h -> deblocking_filter = 0; 695
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
h -> deblocking_filter = 2; 701
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
for (i = 0; i < 16; i++) 758
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
176 ../data/NVD/CVE_2013_0850_VULN_decode_slice_header.c unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1 356
static int CVE_2013_0850_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
unsigned int slice_type , tmp , i , j ; 8
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
s -> dropable = h -> nal_ref_idc == 0; 318
if ( h -> sps . frame_mbs_only_flag )  319
s -> picture_structure = PICT_FRAME; 320
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
s -> picture_structure = PICT_FRAME; 329
h -> mb_aff_frame = h -> sps . mb_aff; 330
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( h0 -> current_slice != 0 )  335
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
av_log ( h -> s . avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 433
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 0 ); 440
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 1 ); 441
ff_generate_sliding_window_mmcos ( h ); 442
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , s -> avctx -> pix_fmt , s -> mb_width * 16 , s -> mb_height * 16 ); 454
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
if ( ff_h264_frame_start ( h ) < 0 )  497
ff_release_unused_pictures ( s , 0 ); 502
if ( h != h0 )  505
clone_slice ( h , h0 ); 506
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
assert ( s -> mb_num == s -> mb_width * s -> mb_height ); 510
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
av_log ( h -> s . avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 513
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
assert ( s -> mb_y < s -> mb_height ); 520
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> nal_unit_type == NAL_IDR_SLICE )  530
get_ue_golomb ( & s -> gb ); 531
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
init_poc ( h ); 547
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
max [ 1 ] = 31; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 574
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
ff_h264_fill_default_ref_list ( h ); 587
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 597
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 601
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
pred_weight_table ( h ); 607
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
implicit_weight_table ( h , - 1 ); 610
h -> use_weight = 0; 612
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
ff_h264_fill_mbaff_ref_list ( h ); 624
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  626
implicit_weight_table ( h , 0 ); 627
implicit_weight_table ( h , 1 ); 628
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  632
ff_h264_direct_dist_scale_factor ( h ); 633
ff_h264_direct_ref_list_init ( h ); 634
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 639
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
h -> deblocking_filter = 0; 695
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
h -> deblocking_filter = 2; 701
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
for (i = 0; i < 16; i++) 758
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
177 ../data/NVD/CVE_2013_0850_VULN_decode_slice_header.c s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ) 327
static int CVE_2013_0850_VULN_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
unsigned int slice_type , tmp , i , j ; 8
int must_reinit ; 11
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  14
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 19
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 20
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 23
if ( first_mb_in_slice == 0 )  25
h0 -> current_slice = 0; 30
if ( ! s0 -> first_field )  31
s -> current_picture_ptr = NULL; 37
slice_type = get_ue_golomb_31 ( & s -> gb ); 41
if ( slice_type > 9 )  42
if ( slice_type > 4 )  48
slice_type -= 5; 49
h -> slice_type_fixed = 0; 52
slice_type = golomb_to_pict_type [ slice_type ]; 54
h -> slice_type = slice_type; 59
h -> slice_type_nos = slice_type & 3; 60
s -> pict_type = h -> slice_type; 63
pps_id = get_ue_golomb ( & s -> gb ); 65
if ( pps_id >= MAX_PPS_COUNT )  66
if ( ! h0 -> pps_buffers [ pps_id ] )  70
h -> pps = * h0 -> pps_buffers [ pps_id ]; 76
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  78
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 84
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 86
s -> avctx -> level = h -> sps . level_idc; 87
s -> avctx -> refs = h -> sps . ref_frame_count; 88
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 90
if ( must_reinit && ( h != h0 || ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) ) )  97
s -> mb_width = h -> sps . mb_width; 103
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 104
h -> b_stride = s -> mb_width * 4; 106
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 108
s -> width = 16 * s -> mb_width; 110
s -> height = 16 * s -> mb_height; 111
if ( must_reinit )  113
h -> list_count = 0; 117
h -> current_slice = 0; 118
if ( ! s -> context_initialized )  120
if ( h != h0 )  121
if ( FFALIGN ( s -> avctx -> width , 16 ) == s -> width && FFALIGN ( s -> avctx -> height , 16 * ( 2 - h -> sps . frame_mbs_only_flag ) ) == s -> height && ! h -> sps . crop_right && ! h -> sps . crop_bottom && ( s -> avctx -> width != s -> width || s -> avctx -> height && s -> height ) )  126
s -> avctx -> width -= ( 2 >> CHROMA444 ) * FFMIN ( h -> sps . crop_right , ( 8 << CHROMA444 ) - 1 ); 136
s -> avctx -> height -= ( 1 << s -> chroma_y_shift ) * FFMIN ( h -> sps . crop_bottom , ( 16 >> s -> chroma_y_shift ) - 1 ) * ( 2 - h -> sps . frame_mbs_only_flag ); 137
s -> avctx -> sample_aspect_ratio = h -> sps . sar; 139
if ( s -> avctx -> codec -> capabilities & CODEC_CAP_HWACCEL_VDPAU && ( h -> sps . bit_depth_luma != 8 || h -> sps . chroma_format_idc > 1 ) )  142
if ( s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  151
if ( h -> sps . bit_depth_luma >= 8 && h -> sps . bit_depth_luma <= 14 && h -> sps . bit_depth_luma != 11 && h -> sps . bit_depth_luma != 13 && ( h -> sps . bit_depth_luma != 9 || ! CHROMA422 ) )  153
s -> avctx -> bits_per_raw_sample = h -> sps . bit_depth_luma; 155
h -> cur_chroma_format_idc = h -> sps . chroma_format_idc; 156
h -> pixel_shift = h -> sps . bit_depth_luma > 8; 157
s -> dsp . dct_bits = h -> sps . bit_depth_luma > 8 ? 32 : 16; 161
if ( h -> sps . video_signal_type_present_flag )  170
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 171
if ( h -> sps . colour_description_present_flag )  173
s -> avctx -> color_primaries = h -> sps . color_primaries; 174
s -> avctx -> color_trc = h -> sps . color_trc; 175
s -> avctx -> colorspace = h -> sps . colorspace; 176
switch ( h -> sps . bit_depth_luma )  188
if ( CHROMA444 )  190
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  191
s -> avctx -> pix_fmt = PIX_FMT_GBRP9; 192
s -> avctx -> pix_fmt = PIX_FMT_YUV444P9; 194
if ( CHROMA422 )  195
s -> avctx -> pix_fmt = PIX_FMT_YUV422P9; 196
s -> avctx -> pix_fmt = PIX_FMT_YUV420P9; 198
if ( CHROMA444 )  201
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  202
s -> avctx -> pix_fmt = PIX_FMT_GBRP10; 203
s -> avctx -> pix_fmt = PIX_FMT_YUV444P10; 205
if ( CHROMA422 )  206
s -> avctx -> pix_fmt = PIX_FMT_YUV422P10; 207
s -> avctx -> pix_fmt = PIX_FMT_YUV420P10; 209
if ( CHROMA444 )  212
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  213
s -> avctx -> pix_fmt = PIX_FMT_GBRP12; 214
s -> avctx -> pix_fmt = PIX_FMT_YUV444P12; 216
if ( CHROMA422 )  217
s -> avctx -> pix_fmt = PIX_FMT_YUV422P12; 218
s -> avctx -> pix_fmt = PIX_FMT_YUV420P12; 220
if ( CHROMA444 )  223
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  224
s -> avctx -> pix_fmt = PIX_FMT_GBRP14; 225
s -> avctx -> pix_fmt = PIX_FMT_YUV444P14; 227
if ( CHROMA422 )  228
s -> avctx -> pix_fmt = PIX_FMT_YUV422P14; 229
s -> avctx -> pix_fmt = PIX_FMT_YUV420P14; 231
if ( CHROMA444 )  234
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ444P : PIX_FMT_YUV444P; 235
if ( s -> avctx -> colorspace == AVCOL_SPC_RGB )  237
s -> avctx -> pix_fmt = PIX_FMT_GBR24P; 238
if ( CHROMA422 )  243
s -> avctx -> pix_fmt = s -> avctx -> color_range == AVCOL_RANGE_JPEG ? PIX_FMT_YUVJ422P : PIX_FMT_YUV422P; 244
s -> avctx -> pix_fmt = s -> avctx -> get_format ( s -> avctx , s -> avctx -> codec -> pix_fmts ? s -> avctx -> codec -> pix_fmts : s -> avctx -> color_range == AVCOL_RANGE_JPEG ? hwaccel_pixfmt_list_h264_jpeg_420 : ff_hwaccel_pixfmt_list_420 ); 247
s -> avctx -> hwaccel = ff_find_hwaccel ( s -> avctx -> codec -> id , s -> avctx -> pix_fmt ); 261
if ( ff_MPV_common_init ( s ) < 0 )  264
s -> first_field = 0; 268
h -> prev_interlaced_frame = 1; 269
if ( ff_h264_alloc_tables ( h ) < 0 )  272
if ( ! HAVE_THREADS || ! ( s -> avctx -> active_thread_type & FF_THREAD_SLICE ) )  278
if ( context_init ( h ) < 0 )  279
for (i = 1; i < s->slice_context_count; i++) 284
H264Context * c ; 285
c = h -> thread_context [ i ] = av_malloc ( sizeof ( H264Context ) ); 286
for (i = 0; i < s->slice_context_count; i++) 298
if ( context_init ( h -> thread_context [ i ] ) < 0 )  299
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  307
h -> dequant_coeff_pps = pps_id; 308
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 312
h -> mb_mbaff = 0; 314
h -> mb_aff_frame = 0; 315
if ( h -> sps . frame_mbs_only_flag )  319
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  322
if ( get_bits1 ( & s -> gb ) )  326
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 327
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 333
if ( last_pic_structure != s -> picture_structure || last_pic_dropable != s -> dropable )  336
av_log ( h -> s . avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , s -> picture_structure ); 338
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  348
int unwrap_prev_frame_num = h -> prev_frame_num ; 349
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 350
if ( unwrap_prev_frame_num > h -> frame_num )  352
unwrap_prev_frame_num -= max_frame_num; 353
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  355
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 356
if ( unwrap_prev_frame_num < 0 )  357
unwrap_prev_frame_num += max_frame_num; 358
h -> prev_frame_num = unwrap_prev_frame_num; 360
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  381
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  389
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  400
av_log ( s -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , s -> picture_structure ); 404
if ( last_pic_dropable != s -> dropable )  410
av_log ( s -> avctx , AV_LOG_ERROR , "Cannot combine reference and non-reference fields in the same frame\n" ); 411
av_log_ask_for_sample ( s -> avctx , NULL ); 413
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  430
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 432
av_log ( h -> s . avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 433
if ( ff_h264_frame_start ( h ) < 0 )  435
h -> prev_frame_num ++; 437
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 438
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 439
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 0 ); 440
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 1 ); 441
ff_generate_sliding_window_mmcos ( h ); 442
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  443
if ( h -> short_ref_count )  452
if ( prev )  453
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , s -> avctx -> pix_fmt , s -> mb_width * 16 , s -> mb_height * 16 ); 454
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 457
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 459
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  472
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  478
if ( ff_h264_frame_start ( h ) < 0 )  497
ff_release_unused_pictures ( s , 0 ); 502
if ( h != h0 )  505
clone_slice ( h , h0 ); 506
s -> current_picture_ptr -> frame_num = h -> frame_num; 508
assert ( s -> mb_num == s -> mb_width * s -> mb_height ); 510
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  511
av_log ( h -> s . avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 513
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 516
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 517
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  518
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 519
assert ( s -> mb_y < s -> mb_height ); 520
if ( s -> picture_structure == PICT_FRAME )  522
h -> curr_pic_num = h -> frame_num; 523
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 524
h -> curr_pic_num = 2 * h -> frame_num + 1; 526
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 527
if ( h -> nal_unit_type == NAL_IDR_SLICE )  530
get_ue_golomb ( & s -> gb ); 531
if ( h -> sps . poc_type == 0 )  533
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 534
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  536
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 537
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  540
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 541
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  543
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 544
init_poc ( h ); 547
if ( h -> pps . redundant_pic_cnt_present )  549
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 550
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 553
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 554
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  556
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 558
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  560
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 561
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 562
if ( num_ref_idx_active_override_flag )  564
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 565
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  566
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 567
max [ 1 ] = 31; 570
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  573
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 574
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 575
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  579
h -> list_count = 2; 580
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 584
ff_h264_fill_default_ref_list ( h ); 587
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  589
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 591
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  595
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 596
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 597
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  599
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 600
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 601
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  604
pred_weight_table ( h ); 607
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  608
implicit_weight_table ( h , - 1 ); 610
h -> use_weight = 0; 612
h -> luma_weight_flag [ i ] = 0; 614
h -> chroma_weight_flag [ i ] = 0; 615
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  619
ff_h264_fill_mbaff_ref_list ( h ); 624
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  626
implicit_weight_table ( h , 0 ); 627
implicit_weight_table ( h , 1 ); 628
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  632
ff_h264_direct_dist_scale_factor ( h ); 633
ff_h264_direct_ref_list_init ( h ); 634
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  636
tmp = get_ue_golomb_31 ( & s -> gb ); 637
if ( tmp > 2 )  638
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 639
h -> cabac_init_idc = tmp; 642
h -> last_qscale_diff = 0; 645
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 646
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  647
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 648
s -> qscale = tmp; 651
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 652
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 653
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  655
get_bits1 ( & s -> gb ); 656
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  657
get_se_golomb ( & s -> gb ); 659
h -> deblocking_filter = 1; 661
h -> slice_alpha_c0_offset = 52; 662
h -> slice_beta_offset = 52; 663
if ( h -> pps . deblocking_filter_parameters_present )  664
tmp = get_ue_golomb_31 ( & s -> gb ); 665
if ( tmp > 2 )  666
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 667
h -> deblocking_filter = tmp; 671
if ( h -> deblocking_filter < 2 )  672
h -> deblocking_filter ^= 1; 673
if ( h -> deblocking_filter )  675
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 676
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 677
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  678
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 680
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  688
h -> deblocking_filter = 0; 695
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  697
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  698
h -> deblocking_filter = 2; 701
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 705
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 710
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 716
h -> slice_num = ++ h0 -> current_slice; 724
if ( h -> slice_num )  726
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 727
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  728
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 732
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 737
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  740
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 742
for (k = 0; k < h->short_ref_count; k++) 743
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  744
for (k = 0; k < h->long_ref_count; k++) 748
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  749
id_list [ i ] = h -> short_ref_count + k; 750
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 756
for (i = 0; i < 16; i++) 758
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 759
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 761
for (i = 16; i < 48; i++) 763
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 764
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 769
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 773
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  775
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 776
------------------------------
178 ../data/NVD/CVE_2013_0855_PATCHED_allocate_buffers.c buf_size = alac -> max_samples_per_frame * sizeof ( int32_t ) 8
static int CVE_2013_0855_PATCHED_allocate_buffers(ALACContext *alac) 1
int buf_size ; 4
if ( alac -> max_samples_per_frame > INT_MAX / sizeof ( int32_t ) )  6
buf_size = alac -> max_samples_per_frame * sizeof ( int32_t ); 8
FF_ALLOC_OR_GOTO ( alac -> avctx , alac -> predict_error_buffer [ ch ] , buf_size , buf_alloc_fail ); 11
FF_ALLOC_OR_GOTO ( alac -> avctx , alac -> output_samples_buffer [ ch ] , buf_size , buf_alloc_fail ); 16
FF_ALLOC_OR_GOTO ( alac -> avctx , alac -> extra_bits_buffer [ ch ] , buf_size , buf_alloc_fail ); 20
------------------------------
179 ../data/NVD/CVE_2013_0856_PATCHED_lpc_prediction.c val = d - pred [ j ] 54
static void CVE_2013_0856_PATCHED_lpc_prediction(int32_t *error_buffer, int32_t *buffer_out,
int nb_samples, int bps, int16_t *lpc_coefs,
int lpc_order, int lpc_quant) 3
int i ; 5
int32_t * pred = buffer_out ; 6
* buffer_out = * error_buffer; 9
if ( nb_samples <= 1 )  11
if ( ! lpc_order )  14
if ( lpc_order == 31 )  20
for (i = 1; i <= lpc_order && i < nb_samples; i++) 30
buffer_out [ i ] = sign_extend ( buffer_out [ i - 1 ] + error_buffer [ i ] , bps ); 31
for (; i < nb_samples; i++) 35
int j ; 36
int val = 0 ; 37
int error_val = error_buffer [ i ] ; 38
int error_sign ; 39
int d = * pred ++ ; 40
for (j = 0; j < lpc_order; j++) 43
val += ( pred [ j ] - d ) * lpc_coefs [ j ]; 44
val = ( val + ( 1 << ( lpc_quant - 1 ) ) ) >> lpc_quant; 45
val += d + error_val; 46
buffer_out [ i ] = sign_extend ( val , bps ); 47
error_sign = sign_only ( error_val ); 50
if ( error_sign )  51
for (j = 0; j < lpc_order && error_val * error_sign > 0; j++) 52
int sign ; 53
val = d - pred [ j ]; 54
sign = sign_only ( val ) * error_sign; 55
lpc_coefs [ j ] -= sign; 56
val *= sign; 57
error_val -= ( val >> lpc_quant ) * ( j + 1 ); 58
------------------------------
180 ../data/NVD/CVE_2013_0856_VULN_lpc_prediction.c val = d - pred [ j ] 54
static void CVE_2013_0856_VULN_lpc_prediction(int32_t *error_buffer, int32_t *buffer_out,
int nb_samples, int bps, int16_t *lpc_coefs,
int lpc_order, int lpc_quant) 3
int i ; 5
int32_t * pred = buffer_out ; 6
* buffer_out = * error_buffer; 9
if ( nb_samples <= 1 )  11
if ( ! lpc_order )  14
if ( lpc_order == 31 )  20
for (i = 1; i <= lpc_order; i++) 30
buffer_out [ i ] = sign_extend ( buffer_out [ i - 1 ] + error_buffer [ i ] , bps ); 31
for (; i < nb_samples; i++) 35
int j ; 36
int val = 0 ; 37
int error_val = error_buffer [ i ] ; 38
int error_sign ; 39
int d = * pred ++ ; 40
for (j = 0; j < lpc_order; j++) 43
val += ( pred [ j ] - d ) * lpc_coefs [ j ]; 44
val = ( val + ( 1 << ( lpc_quant - 1 ) ) ) >> lpc_quant; 45
val += d + error_val; 46
buffer_out [ i ] = sign_extend ( val , bps ); 47
error_sign = sign_only ( error_val ); 50
if ( error_sign )  51
for (j = 0; j < lpc_order && error_val * error_sign > 0; j++) 52
int sign ; 53
val = d - pred [ j ]; 54
sign = sign_only ( val ) * error_sign; 55
lpc_coefs [ j ] -= sign; 56
val *= sign; 57
error_val -= ( val >> lpc_quant ) * ( j + 1 ); 58
------------------------------
181 ../data/NVD/CVE_2013_0859_PATCHED_add_doubles_metadata.c dp = av_malloc ( count * sizeof ( double ) ) 14
static int CVE_2013_0859_PATCHED_add_doubles_metadata(int count,
const char *name, const char *sep,
TiffContext *s) 3
double * dp ; 7
if ( count >= INT_MAX / sizeof ( int64_t ) || count <= 0 )  9
if ( bytestream2_get_bytes_left ( & s -> gb ) < count * sizeof ( int64_t ) )  11
dp = av_malloc ( count * sizeof ( double ) ); 14
if ( ! dp )  15
dp [ i ] = tget_double ( & s -> gb , s -> le ); 19
ap = doubles2str ( dp , count , sep ); 20
av_freep ( & dp ); 21
if ( ! ap )  22
av_dict_set ( & s -> picture . metadata , name , ap , AV_DICT_DONT_STRDUP_VAL ); 24
------------------------------
182 ../data/NVD/CVE_2013_0859_VULN_add_doubles_metadata.c dp = av_malloc ( count * sizeof ( double ) ) 14
static int CVE_2013_0859_VULN_add_doubles_metadata(int count,
const char *name, const char *sep,
TiffContext *s) 3
double * dp ; 7
if ( count >= INT_MAX / sizeof ( int64_t ) )  9
if ( bytestream2_get_bytes_left ( & s -> gb ) < count * sizeof ( int64_t ) )  11
dp = av_malloc ( count * sizeof ( double ) ); 14
if ( ! dp )  15
dp [ i ] = tget_double ( & s -> gb , s -> le ); 19
ap = doubles2str ( dp , count , sep ); 20
av_freep ( & dp ); 21
if ( ! ap )  22
av_dict_set ( & s -> picture . metadata , name , ap , AV_DICT_DONT_STRDUP_VAL ); 24
------------------------------
183 ../data/NVD/CVE_2013_0862_VULN_process_frame_obj.c ctx -> avctx -> height = FFMAX ( top + h , ctx -> height ) 13
static int CVE_2013_0862_VULN_process_frame_obj(SANMVideoContext *ctx) 1
uint16_t codec , top , left , w , h ; 3
left = bytestream2_get_le16u ( & ctx -> gb ); 6
top = bytestream2_get_le16u ( & ctx -> gb ); 7
w = bytestream2_get_le16u ( & ctx -> gb ); 8
h = bytestream2_get_le16u ( & ctx -> gb ); 9
if ( ctx -> width < left + w || ctx -> height < top + h )  11
ctx -> avctx -> width = FFMAX ( left + w , ctx -> width ); 12
ctx -> avctx -> height = FFMAX ( top + h , ctx -> height ); 13
init_sizes ( ctx , left + w , top + h ); 14
if ( init_buffers ( ctx ) )  15
av_log ( ctx -> avctx , AV_LOG_ERROR , "error resizing buffers\n" ); 16
------------------------------
184 ../data/NVD/CVE_2013_0862_VULN_process_frame_obj.c ctx -> avctx -> width = FFMAX ( left + w , ctx -> width ) 12
static int CVE_2013_0862_VULN_process_frame_obj(SANMVideoContext *ctx) 1
uint16_t codec , top , left , w , h ; 3
left = bytestream2_get_le16u ( & ctx -> gb ); 6
top = bytestream2_get_le16u ( & ctx -> gb ); 7
w = bytestream2_get_le16u ( & ctx -> gb ); 8
h = bytestream2_get_le16u ( & ctx -> gb ); 9
if ( ctx -> width < left + w || ctx -> height < top + h )  11
ctx -> avctx -> width = FFMAX ( left + w , ctx -> width ); 12
ctx -> avctx -> height = FFMAX ( top + h , ctx -> height ); 13
init_sizes ( ctx , left + w , top + h ); 14
if ( init_buffers ( ctx ) )  15
av_log ( ctx -> avctx , AV_LOG_ERROR , "error resizing buffers\n" ); 16
------------------------------
185 ../data/NVD/CVE_2013_0864_PATCHED_gif_copy_img_rect.c src_pr = src_px + w 14
static void CVE_2013_0864_PATCHED_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + h * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
------------------------------
186 ../data/NVD/CVE_2013_0864_PATCHED_gif_copy_img_rect.c dst_px = ( uint32_t * ) dst_py + l 13
static void CVE_2013_0864_PATCHED_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + h * linesize ; 8
uint32_t * dst_px ; 9
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
dst_px = ( uint32_t * ) dst_py + l; 13
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
187 ../data/NVD/CVE_2013_0864_PATCHED_gif_copy_img_rect.c src_px = src_py + l 12
static void CVE_2013_0864_PATCHED_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + h * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
188 ../data/NVD/CVE_2013_0864_VULN_gif_copy_img_rect.c src_pr = src_px + w 14
static void CVE_2013_0864_VULN_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + t * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
------------------------------
189 ../data/NVD/CVE_2013_0864_VULN_gif_copy_img_rect.c dst_px = ( uint32_t * ) dst_py + l 13
static void CVE_2013_0864_VULN_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + t * linesize ; 8
uint32_t * dst_px ; 9
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
dst_px = ( uint32_t * ) dst_py + l; 13
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
190 ../data/NVD/CVE_2013_0864_VULN_gif_copy_img_rect.c src_px = src_py + l 12
static void CVE_2013_0864_VULN_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + t * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
191 ../data/NVD/CVE_2013_0867_PATCHED_decode_slice_header.c id_list [ i ] = h -> short_ref_count + k 651
static int CVE_2013_0867_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag , ret ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_droppable ; 10
int must_reinit ; 11
int needs_reinit = 0 ; 12
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  15
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 20
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 21
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 24
if ( first_mb_in_slice == 0 )  26
h0 -> current_slice = 0; 31
if ( ! s0 -> first_field )  32
s -> current_picture_ptr = NULL; 38
slice_type = get_ue_golomb_31 ( & s -> gb ); 42
if ( slice_type > 9 )  43
if ( slice_type > 4 )  49
slice_type -= 5; 50
h -> slice_type_fixed = 0; 53
slice_type = golomb_to_pict_type [ slice_type ]; 55
h -> slice_type = slice_type; 60
h -> slice_type_nos = slice_type & 3; 61
s -> pict_type = h -> slice_type; 64
pps_id = get_ue_golomb ( & s -> gb ); 66
if ( pps_id >= MAX_PPS_COUNT )  67
if ( ! h0 -> pps_buffers [ pps_id ] )  71
h -> pps = * h0 -> pps_buffers [ pps_id ]; 77
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  79
SPS * new_sps = h0 -> sps_buffers [ h -> pps . sps_id ] ; 89
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 91
if ( h -> sps . chroma_format_idc != new_sps -> chroma_format_idc || h -> sps . bit_depth_luma != new_sps -> bit_depth_luma )  93
needs_reinit = 1; 95
h -> current_sps_id = h -> pps . sps_id; 97
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 98
if ( s -> mb_width != h -> sps . mb_width || s -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  100
needs_reinit = 1; 105
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  107
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 111
s -> avctx -> level = h -> sps . level_idc; 112
s -> avctx -> refs = h -> sps . ref_frame_count; 113
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 115
if ( h0 -> s . avctx -> pix_fmt != get_pixel_format ( h0 ) )  121
must_reinit = 1; 122
s -> mb_width = h -> sps . mb_width; 124
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 125
h -> b_stride = s -> mb_width * 4; 127
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 129
s -> width = 16 * s -> mb_width; 131
s -> height = 16 * s -> mb_height; 132
if ( h -> sps . video_signal_type_present_flag )  134
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 135
if ( h -> sps . colour_description_present_flag )  137
if ( s -> avctx -> colorspace != h -> sps . colorspace )  138
needs_reinit = 1; 139
s -> avctx -> color_primaries = h -> sps . color_primaries; 140
s -> avctx -> color_trc = h -> sps . color_trc; 141
s -> avctx -> colorspace = h -> sps . colorspace; 142
if ( s -> context_initialized && ( needs_reinit || must_reinit ) )  146
if ( h != h0 )  151
if ( ( ret = get_pixel_format ( h ) ) < 0 )  159
s -> avctx -> pix_fmt = ret; 161
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  166
h -> context_reinitialized = 1; 171
if ( ! s -> context_initialized )  173
if ( h != h0 )  174
if ( ( ret = get_pixel_format ( h ) ) < 0 )  180
s -> avctx -> pix_fmt = ret; 182
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  184
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  191
h -> dequant_coeff_pps = pps_id; 192
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 196
h -> mb_mbaff = 0; 198
h -> mb_aff_frame = 0; 199
last_pic_structure = s0 -> picture_structure; 200
last_pic_droppable = s0 -> droppable; 201
s -> droppable = h -> nal_ref_idc == 0; 202
if ( h -> sps . frame_mbs_only_flag )  203
s -> picture_structure = PICT_FRAME; 204
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  206
if ( get_bits1 ( & s -> gb ) )  210
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 211
s -> picture_structure = PICT_FRAME; 213
h -> mb_aff_frame = h -> sps . mb_aff; 214
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 217
if ( h0 -> current_slice != 0 )  219
if ( last_pic_structure != s -> picture_structure || last_pic_droppable != s -> droppable )  220
if ( ! s0 -> current_picture_ptr )  228
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  237
int unwrap_prev_frame_num = h -> prev_frame_num ; 238
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 239
if ( unwrap_prev_frame_num > h -> frame_num )  241
unwrap_prev_frame_num -= max_frame_num; 242
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  244
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 245
if ( unwrap_prev_frame_num < 0 )  246
unwrap_prev_frame_num += max_frame_num; 247
h -> prev_frame_num = unwrap_prev_frame_num; 249
if ( s0 -> first_field )  258
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  270
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  278
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  289
if ( last_pic_droppable != s -> droppable )  299
s -> picture_structure = last_pic_structure; 303
s -> droppable = last_pic_droppable; 304
s0 -> current_picture_ptr -> owner2 = s0; 314
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! s0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  319
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 321
if ( ff_h264_frame_start ( h ) < 0 )  324
h -> prev_frame_num ++; 326
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 327
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 328
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && s -> avctx -> err_recognition & AV_EF_EXPLODE )  331
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  334
if ( h -> short_ref_count )  343
if ( prev )  344
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 348
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 350
if ( s0 -> first_field )  357
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  363
s0 -> current_picture_ptr = NULL; 366
s0 -> first_field = FIELD_PICTURE; 367
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  369
s0 -> first_field = 1; 375
s0 -> current_picture_ptr = NULL; 376
s0 -> first_field = 0; 379
s0 -> first_field = FIELD_PICTURE; 384
if ( ! FIELD_PICTURE || s0 -> first_field )  387
if ( ff_h264_frame_start ( h ) < 0 )  388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  396
s -> current_picture_ptr -> frame_num = h -> frame_num; 399
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  402
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 407
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 408
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  409
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 410
if ( s -> picture_structure == PICT_FRAME )  413
h -> curr_pic_num = h -> frame_num; 414
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 415
h -> curr_pic_num = 2 * h -> frame_num + 1; 417
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 418
if ( h -> sps . poc_type == 0 )  424
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 425
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  427
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 428
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  431
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 432
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  434
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 435
if ( h -> pps . redundant_pic_cnt_present )  440
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 441
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 444
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 445
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  447
unsigned max [ 2 ] ; 448
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 449
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  451
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 452
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 453
if ( num_ref_idx_active_override_flag )  455
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 456
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 458
h -> ref_count [ 1 ] = 1; 461
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  464
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  470
h -> list_count = 2; 471
h -> list_count = 1; 473
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 475
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  480
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  486
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 487
s -> last_picture_ptr -> owner2 = s; 488
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  491
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 492
s -> next_picture_ptr -> owner2 = s; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb , ! ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & s -> gb ); 538
if ( tmp > 2 )  539
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
s -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 554
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & s -> gb ); 566
if ( tmp > 2 )  567
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
h0 -> max_contexts = 1; 604
if ( ! h0 -> single_decode_warning )  605
h0 -> single_decode_warning = 1; 608
if ( h != h0 )  610
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h0 -> last_slice_type = slice_type; 624
h -> slice_num = ++ h0 -> current_slice; 625
if ( h -> slice_num )  627
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 628
for (j = 0; j < 2; j++) 636
int id_list [ 16 ] ; 637
for (i = 0; i < 16; i++) 639
id_list [ i ] = 60; 640
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  641
int k ; 642
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 643
for (k = 0; k < h->short_ref_count; k++) 644
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  645
id_list [ i ] = k; 646
for (k = 0; k < h->long_ref_count; k++) 649
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  650
id_list [ i ] = h -> short_ref_count + k; 651
for (i = 0; i < 16; i++) 659
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 660
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 662
for (i = 16; i < 48; i++) 664
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 665
------------------------------
192 ../data/NVD/CVE_2013_0867_PATCHED_decode_slice_header.c tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ) 547
static int CVE_2013_0867_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag , ret ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_droppable ; 10
int must_reinit ; 11
int needs_reinit = 0 ; 12
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  15
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 20
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 21
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 24
if ( first_mb_in_slice == 0 )  26
h0 -> current_slice = 0; 31
if ( ! s0 -> first_field )  32
s -> current_picture_ptr = NULL; 38
slice_type = get_ue_golomb_31 ( & s -> gb ); 42
if ( slice_type > 9 )  43
if ( slice_type > 4 )  49
slice_type -= 5; 50
h -> slice_type_fixed = 0; 53
slice_type = golomb_to_pict_type [ slice_type ]; 55
h -> slice_type = slice_type; 60
h -> slice_type_nos = slice_type & 3; 61
s -> pict_type = h -> slice_type; 64
pps_id = get_ue_golomb ( & s -> gb ); 66
if ( pps_id >= MAX_PPS_COUNT )  67
if ( ! h0 -> pps_buffers [ pps_id ] )  71
h -> pps = * h0 -> pps_buffers [ pps_id ]; 77
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  79
SPS * new_sps = h0 -> sps_buffers [ h -> pps . sps_id ] ; 89
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 91
if ( h -> sps . chroma_format_idc != new_sps -> chroma_format_idc || h -> sps . bit_depth_luma != new_sps -> bit_depth_luma )  93
needs_reinit = 1; 95
h -> current_sps_id = h -> pps . sps_id; 97
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 98
if ( s -> mb_width != h -> sps . mb_width || s -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  100
needs_reinit = 1; 105
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  107
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 111
s -> avctx -> level = h -> sps . level_idc; 112
s -> avctx -> refs = h -> sps . ref_frame_count; 113
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 115
if ( h0 -> s . avctx -> pix_fmt != get_pixel_format ( h0 ) )  121
must_reinit = 1; 122
s -> mb_width = h -> sps . mb_width; 124
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 125
h -> b_stride = s -> mb_width * 4; 127
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 129
s -> width = 16 * s -> mb_width; 131
s -> height = 16 * s -> mb_height; 132
if ( h -> sps . video_signal_type_present_flag )  134
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 135
if ( h -> sps . colour_description_present_flag )  137
if ( s -> avctx -> colorspace != h -> sps . colorspace )  138
needs_reinit = 1; 139
s -> avctx -> color_primaries = h -> sps . color_primaries; 140
s -> avctx -> color_trc = h -> sps . color_trc; 141
s -> avctx -> colorspace = h -> sps . colorspace; 142
if ( s -> context_initialized && ( needs_reinit || must_reinit ) )  146
if ( h != h0 )  151
if ( ( ret = get_pixel_format ( h ) ) < 0 )  159
s -> avctx -> pix_fmt = ret; 161
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  166
h -> context_reinitialized = 1; 171
if ( ! s -> context_initialized )  173
if ( h != h0 )  174
if ( ( ret = get_pixel_format ( h ) ) < 0 )  180
s -> avctx -> pix_fmt = ret; 182
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  184
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  191
h -> dequant_coeff_pps = pps_id; 192
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 196
h -> mb_mbaff = 0; 198
h -> mb_aff_frame = 0; 199
last_pic_structure = s0 -> picture_structure; 200
last_pic_droppable = s0 -> droppable; 201
s -> droppable = h -> nal_ref_idc == 0; 202
if ( h -> sps . frame_mbs_only_flag )  203
s -> picture_structure = PICT_FRAME; 204
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  206
if ( get_bits1 ( & s -> gb ) )  210
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 211
s -> picture_structure = PICT_FRAME; 213
h -> mb_aff_frame = h -> sps . mb_aff; 214
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 217
if ( h0 -> current_slice != 0 )  219
if ( last_pic_structure != s -> picture_structure || last_pic_droppable != s -> droppable )  220
if ( ! s0 -> current_picture_ptr )  228
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  237
int unwrap_prev_frame_num = h -> prev_frame_num ; 238
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 239
if ( unwrap_prev_frame_num > h -> frame_num )  241
unwrap_prev_frame_num -= max_frame_num; 242
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  244
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 245
if ( unwrap_prev_frame_num < 0 )  246
unwrap_prev_frame_num += max_frame_num; 247
h -> prev_frame_num = unwrap_prev_frame_num; 249
if ( s0 -> first_field )  258
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  270
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  278
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  289
if ( last_pic_droppable != s -> droppable )  299
s -> picture_structure = last_pic_structure; 303
s -> droppable = last_pic_droppable; 304
s0 -> current_picture_ptr -> owner2 = s0; 314
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! s0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  319
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 321
if ( ff_h264_frame_start ( h ) < 0 )  324
h -> prev_frame_num ++; 326
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 327
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 328
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && s -> avctx -> err_recognition & AV_EF_EXPLODE )  331
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  334
if ( h -> short_ref_count )  343
if ( prev )  344
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 348
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 350
if ( s0 -> first_field )  357
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  363
s0 -> current_picture_ptr = NULL; 366
s0 -> first_field = FIELD_PICTURE; 367
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  369
s0 -> first_field = 1; 375
s0 -> current_picture_ptr = NULL; 376
s0 -> first_field = 0; 379
s0 -> first_field = FIELD_PICTURE; 384
if ( ! FIELD_PICTURE || s0 -> first_field )  387
if ( ff_h264_frame_start ( h ) < 0 )  388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  396
s -> current_picture_ptr -> frame_num = h -> frame_num; 399
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  402
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 407
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 408
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  409
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 410
if ( s -> picture_structure == PICT_FRAME )  413
h -> curr_pic_num = h -> frame_num; 414
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 415
h -> curr_pic_num = 2 * h -> frame_num + 1; 417
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 418
if ( h -> sps . poc_type == 0 )  424
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 425
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  427
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 428
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  431
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 432
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  434
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 435
if ( h -> pps . redundant_pic_cnt_present )  440
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 441
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 444
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 445
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  447
unsigned max [ 2 ] ; 448
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 449
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  451
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 452
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 453
if ( num_ref_idx_active_override_flag )  455
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 456
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 458
h -> ref_count [ 1 ] = 1; 461
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  464
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  470
h -> list_count = 2; 471
h -> list_count = 1; 473
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 475
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  480
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  486
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 487
s -> last_picture_ptr -> owner2 = s; 488
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  491
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 492
s -> next_picture_ptr -> owner2 = s; 493
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
h -> use_weight = 0; 505
for (i = 0; i < 2; i++) 506
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb , ! ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & s -> gb ); 538
if ( tmp > 2 )  539
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
s -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & s -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & s -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & s -> gb ); 566
if ( tmp > 2 )  567
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 625
if ( h -> slice_num )  627
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 628
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  629
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 633
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 638
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  641
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 643
for (k = 0; k < h->short_ref_count; k++) 644
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  645
for (k = 0; k < h->long_ref_count; k++) 649
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  650
id_list [ i ] = h -> short_ref_count + k; 651
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 657
for (i = 0; i < 16; i++) 659
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 660
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 662
for (i = 16; i < 48; i++) 664
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 665
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 670
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 674
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  676
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 677
------------------------------
193 ../data/NVD/CVE_2013_0867_PATCHED_decode_slice_header.c s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE 408
static int CVE_2013_0867_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag , ret ; 7
unsigned int slice_type , tmp , i , j ; 8
int last_pic_structure , last_pic_droppable ; 10
int must_reinit ; 11
int needs_reinit = 0 ; 12
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  15
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 20
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 21
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 24
if ( first_mb_in_slice == 0 )  26
h0 -> current_slice = 0; 31
if ( ! s0 -> first_field )  32
s -> current_picture_ptr = NULL; 38
slice_type = get_ue_golomb_31 ( & s -> gb ); 42
if ( slice_type > 9 )  43
if ( slice_type > 4 )  49
slice_type -= 5; 50
h -> slice_type_fixed = 0; 53
slice_type = golomb_to_pict_type [ slice_type ]; 55
h -> slice_type = slice_type; 60
h -> slice_type_nos = slice_type & 3; 61
s -> pict_type = h -> slice_type; 64
pps_id = get_ue_golomb ( & s -> gb ); 66
if ( pps_id >= MAX_PPS_COUNT )  67
if ( ! h0 -> pps_buffers [ pps_id ] )  71
h -> pps = * h0 -> pps_buffers [ pps_id ]; 77
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  79
SPS * new_sps = h0 -> sps_buffers [ h -> pps . sps_id ] ; 89
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 91
if ( h -> sps . chroma_format_idc != new_sps -> chroma_format_idc || h -> sps . bit_depth_luma != new_sps -> bit_depth_luma )  93
needs_reinit = 1; 95
h -> current_sps_id = h -> pps . sps_id; 97
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 98
if ( s -> mb_width != h -> sps . mb_width || s -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  100
needs_reinit = 1; 105
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  107
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 111
s -> avctx -> level = h -> sps . level_idc; 112
s -> avctx -> refs = h -> sps . ref_frame_count; 113
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 115
if ( h0 -> s . avctx -> pix_fmt != get_pixel_format ( h0 ) )  121
must_reinit = 1; 122
s -> mb_width = h -> sps . mb_width; 124
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 125
h -> b_stride = s -> mb_width * 4; 127
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 129
s -> width = 16 * s -> mb_width; 131
s -> height = 16 * s -> mb_height; 132
if ( h -> sps . video_signal_type_present_flag )  134
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 135
if ( h -> sps . colour_description_present_flag )  137
if ( s -> avctx -> colorspace != h -> sps . colorspace )  138
needs_reinit = 1; 139
s -> avctx -> color_primaries = h -> sps . color_primaries; 140
s -> avctx -> color_trc = h -> sps . color_trc; 141
s -> avctx -> colorspace = h -> sps . colorspace; 142
if ( s -> context_initialized && ( needs_reinit || must_reinit ) )  146
if ( h != h0 )  151
if ( ( ret = get_pixel_format ( h ) ) < 0 )  159
s -> avctx -> pix_fmt = ret; 161
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  166
h -> context_reinitialized = 1; 171
if ( ! s -> context_initialized )  173
if ( h != h0 )  174
if ( ( ret = get_pixel_format ( h ) ) < 0 )  180
s -> avctx -> pix_fmt = ret; 182
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  184
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  191
h -> dequant_coeff_pps = pps_id; 192
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 196
h -> mb_mbaff = 0; 198
h -> mb_aff_frame = 0; 199
last_pic_structure = s0 -> picture_structure; 200
last_pic_droppable = s0 -> droppable; 201
s -> droppable = h -> nal_ref_idc == 0; 202
if ( h -> sps . frame_mbs_only_flag )  203
s -> picture_structure = PICT_FRAME; 204
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  206
if ( get_bits1 ( & s -> gb ) )  210
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 211
s -> picture_structure = PICT_FRAME; 213
h -> mb_aff_frame = h -> sps . mb_aff; 214
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 217
if ( h0 -> current_slice != 0 )  219
if ( last_pic_structure != s -> picture_structure || last_pic_droppable != s -> droppable )  220
if ( ! s0 -> current_picture_ptr )  228
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  237
int unwrap_prev_frame_num = h -> prev_frame_num ; 238
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 239
if ( unwrap_prev_frame_num > h -> frame_num )  241
unwrap_prev_frame_num -= max_frame_num; 242
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  244
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 245
if ( unwrap_prev_frame_num < 0 )  246
unwrap_prev_frame_num += max_frame_num; 247
h -> prev_frame_num = unwrap_prev_frame_num; 249
if ( s0 -> first_field )  258
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  270
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  278
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  289
if ( last_pic_droppable != s -> droppable )  299
s -> picture_structure = last_pic_structure; 303
s -> droppable = last_pic_droppable; 304
s0 -> current_picture_ptr -> owner2 = s0; 314
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! s0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  319
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 321
if ( ff_h264_frame_start ( h ) < 0 )  324
h -> prev_frame_num ++; 326
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 327
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 328
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && s -> avctx -> err_recognition & AV_EF_EXPLODE )  331
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  334
if ( h -> short_ref_count )  343
if ( prev )  344
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 348
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 350
if ( s0 -> first_field )  357
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  363
s0 -> current_picture_ptr = NULL; 366
s0 -> first_field = FIELD_PICTURE; 367
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  369
s0 -> first_field = 1; 375
s0 -> current_picture_ptr = NULL; 376
s0 -> first_field = 0; 379
s0 -> first_field = FIELD_PICTURE; 384
if ( ! FIELD_PICTURE || s0 -> first_field )  387
if ( ff_h264_frame_start ( h ) < 0 )  388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  396
s -> current_picture_ptr -> frame_num = h -> frame_num; 399
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  402
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 407
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 408
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  409
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 410
av_assert1 ( s -> mb_y < s -> mb_height ); 411
if ( s -> picture_structure == PICT_FRAME )  413
get_ue_golomb ( & s -> gb ); 422
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 425
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  427
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 428
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  431
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 432
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  434
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 435
init_poc ( h ); 438
if ( h -> pps . redundant_pic_cnt_present )  440
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 441
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 444
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 445
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  447
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 449
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  451
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 452
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 453
if ( num_ref_idx_active_override_flag )  455
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 456
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 458
h -> ref_count [ 1 ] = 1; 461
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  464
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 465
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 466
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  470
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 475
ff_h264_fill_default_ref_list ( h ); 478
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  480
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  486
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 487
s -> last_picture_ptr -> owner2 = s; 488
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 489
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  491
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 492
s -> next_picture_ptr -> owner2 = s; 493
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 494
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb , ! ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & s -> gb ); 538
if ( tmp > 2 )  539
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
s -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & s -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & s -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & s -> gb ); 566
if ( tmp > 2 )  567
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 625
if ( h -> slice_num )  627
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 628
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  629
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 633
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 638
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  641
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 643
for (k = 0; k < h->short_ref_count; k++) 644
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  645
for (k = 0; k < h->long_ref_count; k++) 649
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  650
id_list [ i ] = h -> short_ref_count + k; 651
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 657
for (i = 0; i < 16; i++) 659
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 660
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 662
for (i = 16; i < 48; i++) 664
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 665
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 670
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 674
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  676
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 677
------------------------------
194 ../data/NVD/CVE_2013_0867_PATCHED_decode_slice_header.c unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1 245
static int CVE_2013_0867_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag , ret ; 7
unsigned int slice_type , tmp , i , j ; 8
int must_reinit ; 11
int needs_reinit = 0 ; 12
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  15
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 20
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 21
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 24
if ( first_mb_in_slice == 0 )  26
h0 -> current_slice = 0; 31
if ( ! s0 -> first_field )  32
s -> current_picture_ptr = NULL; 38
slice_type = get_ue_golomb_31 ( & s -> gb ); 42
if ( slice_type > 9 )  43
if ( slice_type > 4 )  49
slice_type -= 5; 50
h -> slice_type_fixed = 0; 53
slice_type = golomb_to_pict_type [ slice_type ]; 55
h -> slice_type = slice_type; 60
h -> slice_type_nos = slice_type & 3; 61
s -> pict_type = h -> slice_type; 64
pps_id = get_ue_golomb ( & s -> gb ); 66
if ( pps_id >= MAX_PPS_COUNT )  67
if ( ! h0 -> pps_buffers [ pps_id ] )  71
h -> pps = * h0 -> pps_buffers [ pps_id ]; 77
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  79
SPS * new_sps = h0 -> sps_buffers [ h -> pps . sps_id ] ; 89
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 91
if ( h -> sps . chroma_format_idc != new_sps -> chroma_format_idc || h -> sps . bit_depth_luma != new_sps -> bit_depth_luma )  93
needs_reinit = 1; 95
h -> current_sps_id = h -> pps . sps_id; 97
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 98
if ( s -> mb_width != h -> sps . mb_width || s -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  100
needs_reinit = 1; 105
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  107
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 111
s -> avctx -> level = h -> sps . level_idc; 112
s -> avctx -> refs = h -> sps . ref_frame_count; 113
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 115
if ( h0 -> s . avctx -> pix_fmt != get_pixel_format ( h0 ) )  121
must_reinit = 1; 122
s -> mb_width = h -> sps . mb_width; 124
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 125
h -> b_stride = s -> mb_width * 4; 127
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 129
s -> width = 16 * s -> mb_width; 131
s -> height = 16 * s -> mb_height; 132
if ( h -> sps . video_signal_type_present_flag )  134
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 135
if ( h -> sps . colour_description_present_flag )  137
if ( s -> avctx -> colorspace != h -> sps . colorspace )  138
needs_reinit = 1; 139
s -> avctx -> color_primaries = h -> sps . color_primaries; 140
s -> avctx -> color_trc = h -> sps . color_trc; 141
s -> avctx -> colorspace = h -> sps . colorspace; 142
if ( s -> context_initialized && ( needs_reinit || must_reinit ) )  146
if ( h != h0 )  151
if ( ( ret = get_pixel_format ( h ) ) < 0 )  159
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  166
h -> context_reinitialized = 1; 171
if ( ! s -> context_initialized )  173
if ( h != h0 )  174
if ( ( ret = get_pixel_format ( h ) ) < 0 )  180
s -> avctx -> pix_fmt = ret; 182
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  184
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  191
h -> dequant_coeff_pps = pps_id; 192
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 196
h -> mb_mbaff = 0; 198
h -> mb_aff_frame = 0; 199
s -> droppable = h -> nal_ref_idc == 0; 202
if ( h -> sps . frame_mbs_only_flag )  203
s -> picture_structure = PICT_FRAME; 204
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  206
if ( get_bits1 ( & s -> gb ) )  210
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 211
s -> picture_structure = PICT_FRAME; 213
h -> mb_aff_frame = h -> sps . mb_aff; 214
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 217
if ( h0 -> current_slice != 0 )  219
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  237
int unwrap_prev_frame_num = h -> prev_frame_num ; 238
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 239
if ( unwrap_prev_frame_num > h -> frame_num )  241
unwrap_prev_frame_num -= max_frame_num; 242
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  244
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 245
if ( unwrap_prev_frame_num < 0 )  246
unwrap_prev_frame_num += max_frame_num; 247
h -> prev_frame_num = unwrap_prev_frame_num; 249
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  278
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! s0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  319
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 321
av_log ( h -> s . avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 322
if ( ff_h264_frame_start ( h ) < 0 )  324
h -> prev_frame_num ++; 326
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 327
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 328
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 0 ); 329
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 1 ); 330
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && s -> avctx -> err_recognition & AV_EF_EXPLODE )  331
return ret ; 333
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  334
if ( h -> short_ref_count )  343
if ( prev )  344
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , s -> avctx -> pix_fmt , s -> mb_width * 16 , s -> mb_height * 16 ); 345
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 348
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 350
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  369
if ( ff_h264_frame_start ( h ) < 0 )  388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  396
return ret ; 397
s -> current_picture_ptr -> frame_num = h -> frame_num; 399
av_assert1 ( s -> mb_num == s -> mb_width * s -> mb_height ); 401
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  402
av_log ( h -> s . avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 404
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 407
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 408
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  409
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 410
av_assert1 ( s -> mb_y < s -> mb_height ); 411
if ( s -> picture_structure == PICT_FRAME )  413
h -> curr_pic_num = h -> frame_num; 414
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 415
h -> curr_pic_num = 2 * h -> frame_num + 1; 417
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 418
if ( h -> nal_unit_type == NAL_IDR_SLICE )  421
get_ue_golomb ( & s -> gb ); 422
if ( h -> sps . poc_type == 0 )  424
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 425
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  427
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 428
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  431
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 432
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  434
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 435
init_poc ( h ); 438
if ( h -> pps . redundant_pic_cnt_present )  440
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 441
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 444
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 445
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  447
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 449
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  451
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 452
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 453
if ( num_ref_idx_active_override_flag )  455
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 456
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 458
h -> ref_count [ 1 ] = 1; 461
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  464
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 465
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 466
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  470
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 475
ff_h264_fill_default_ref_list ( h ); 478
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  480
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  486
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 487
s -> last_picture_ptr -> owner2 = s; 488
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 489
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  491
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 492
s -> next_picture_ptr -> owner2 = s; 493
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 494
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb , ! ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & s -> gb ); 538
if ( tmp > 2 )  539
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
s -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & s -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & s -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & s -> gb ); 566
if ( tmp > 2 )  567
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 625
if ( h -> slice_num )  627
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 628
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  629
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 633
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 638
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  641
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 643
for (k = 0; k < h->short_ref_count; k++) 644
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  645
for (k = 0; k < h->long_ref_count; k++) 649
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  650
id_list [ i ] = h -> short_ref_count + k; 651
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 657
for (i = 0; i < 16; i++) 659
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 660
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 662
for (i = 16; i < 48; i++) 664
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 665
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 670
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 674
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  676
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 677
------------------------------
195 ../data/NVD/CVE_2013_0867_PATCHED_decode_slice_header.c s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ) 211
static int CVE_2013_0867_PATCHED_decode_slice_header(H264Context *h, H264Context *h0) 1
MpegEncContext * const s = & h -> s
MpegEncContext * const s0 = & h0 -> s 4
unsigned int first_mb_in_slice ; 5
unsigned int pps_id ; 6
int num_ref_idx_active_override_flag , ret ; 7
unsigned int slice_type , tmp , i , j ; 8
int must_reinit ; 11
int needs_reinit = 0 ; 12
if ( ( s -> avctx -> flags2 & CODEC_FLAG2_FAST ) && ! h -> nal_ref_idc && ! h -> pixel_shift )  15
s -> me . qpel_put = s -> dsp . put_h264_qpel_pixels_tab; 20
s -> me . qpel_avg = s -> dsp . avg_h264_qpel_pixels_tab; 21
first_mb_in_slice = get_ue_golomb_long ( & s -> gb ); 24
if ( first_mb_in_slice == 0 )  26
h0 -> current_slice = 0; 31
if ( ! s0 -> first_field )  32
s -> current_picture_ptr = NULL; 38
slice_type = get_ue_golomb_31 ( & s -> gb ); 42
if ( slice_type > 9 )  43
if ( slice_type > 4 )  49
slice_type -= 5; 50
h -> slice_type_fixed = 0; 53
slice_type = golomb_to_pict_type [ slice_type ]; 55
h -> slice_type = slice_type; 60
h -> slice_type_nos = slice_type & 3; 61
s -> pict_type = h -> slice_type; 64
pps_id = get_ue_golomb ( & s -> gb ); 66
if ( pps_id >= MAX_PPS_COUNT )  67
if ( ! h0 -> pps_buffers [ pps_id ] )  71
h -> pps = * h0 -> pps_buffers [ pps_id ]; 77
if ( ! h0 -> sps_buffers [ h -> pps . sps_id ] )  79
SPS * new_sps = h0 -> sps_buffers [ h -> pps . sps_id ] ; 89
h0 -> sps_buffers [ h -> pps . sps_id ] -> new = 0 91
if ( h -> sps . chroma_format_idc != new_sps -> chroma_format_idc || h -> sps . bit_depth_luma != new_sps -> bit_depth_luma )  93
needs_reinit = 1; 95
h -> current_sps_id = h -> pps . sps_id; 97
h -> sps = * h0 -> sps_buffers [ h -> pps . sps_id ]; 98
if ( s -> mb_width != h -> sps . mb_width || s -> mb_height != h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc )  100
needs_reinit = 1; 105
if ( ( ret = h264_set_parameter_from_sps ( h ) ) < 0 )  107
s -> avctx -> profile = ff_h264_get_profile ( & h -> sps ); 111
s -> avctx -> level = h -> sps . level_idc; 112
s -> avctx -> refs = h -> sps . ref_frame_count; 113
must_reinit = ( s -> context_initialized && ( 16 * h -> sps . mb_width != s -> avctx -> coded_width || 16 * h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ) != s -> avctx -> coded_height || s -> avctx -> bits_per_raw_sample != h -> sps . bit_depth_luma || h -> cur_chroma_format_idc != h -> sps . chroma_format_idc || av_cmp_q ( h -> sps . sar , s -> avctx -> sample_aspect_ratio ) ) ); 115
if ( h0 -> s . avctx -> pix_fmt != get_pixel_format ( h0 ) )  121
must_reinit = 1; 122
s -> mb_width = h -> sps . mb_width; 124
s -> mb_height = h -> sps . mb_height * ( 2 - h -> sps . frame_mbs_only_flag ); 125
h -> b_stride = s -> mb_width * 4; 127
s -> chroma_y_shift = h -> sps . chroma_format_idc <= 1; 129
s -> width = 16 * s -> mb_width; 131
s -> height = 16 * s -> mb_height; 132
if ( h -> sps . video_signal_type_present_flag )  134
s -> avctx -> color_range = h -> sps . full_range > 0 ? AVCOL_RANGE_JPEG : AVCOL_RANGE_MPEG; 135
if ( h -> sps . colour_description_present_flag )  137
if ( s -> avctx -> colorspace != h -> sps . colorspace )  138
needs_reinit = 1; 139
s -> avctx -> color_primaries = h -> sps . color_primaries; 140
s -> avctx -> color_trc = h -> sps . color_trc; 141
s -> avctx -> colorspace = h -> sps . colorspace; 142
if ( s -> context_initialized && ( needs_reinit || must_reinit ) )  146
if ( h != h0 )  151
if ( ( ret = get_pixel_format ( h ) ) < 0 )  159
if ( ( ret = h264_slice_header_init ( h , 1 ) ) < 0 )  166
h -> context_reinitialized = 1; 171
if ( ! s -> context_initialized )  173
if ( h != h0 )  174
if ( ( ret = get_pixel_format ( h ) ) < 0 )  180
s -> avctx -> pix_fmt = ret; 182
if ( ( ret = h264_slice_header_init ( h , 0 ) ) < 0 )  184
if ( h == h0 && h -> dequant_coeff_pps != pps_id )  191
h -> dequant_coeff_pps = pps_id; 192
h -> frame_num = get_bits ( & s -> gb , h -> sps . log2_max_frame_num ); 196
h -> mb_mbaff = 0; 198
h -> mb_aff_frame = 0; 199
if ( h -> sps . frame_mbs_only_flag )  203
if ( ! h -> sps . direct_8x8_inference_flag && slice_type == AV_PICTURE_TYPE_B )  206
if ( get_bits1 ( & s -> gb ) )  210
s -> picture_structure = PICT_TOP_FIELD + get_bits1 ( & s -> gb ); 211
h -> mb_field_decoding_flag = s -> picture_structure != PICT_FRAME; 217
if ( last_pic_structure != s -> picture_structure || last_pic_droppable != s -> droppable )  220
av_log ( h -> s . avctx , AV_LOG_ERROR , "Changing field mode (%d -> %d) between slices is not allowed\n" , last_pic_structure , s -> picture_structure ); 222
av_log ( s -> avctx , AV_LOG_ERROR , "unset current_picture_ptr on %d. slice\n" , h0 -> current_slice + 1 ); 229
if ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 )  237
int unwrap_prev_frame_num = h -> prev_frame_num ; 238
int max_frame_num = 1 << h -> sps . log2_max_frame_num ; 239
if ( unwrap_prev_frame_num > h -> frame_num )  241
unwrap_prev_frame_num -= max_frame_num; 242
if ( ( h -> frame_num - unwrap_prev_frame_num ) > h -> sps . ref_frame_count )  244
unwrap_prev_frame_num = ( h -> frame_num - h -> sps . ref_frame_count ) - 1; 245
if ( unwrap_prev_frame_num < 0 )  246
unwrap_prev_frame_num += max_frame_num; 247
h -> prev_frame_num = unwrap_prev_frame_num; 249
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  270
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  278
if ( ! ( ( last_pic_structure == PICT_TOP_FIELD && s -> picture_structure == PICT_BOTTOM_FIELD ) || ( last_pic_structure == PICT_BOTTOM_FIELD && s -> picture_structure == PICT_TOP_FIELD ) ) )  289
av_log ( s -> avctx , AV_LOG_ERROR , "Invalid field mode combination %d/%d\n" , last_pic_structure , s -> picture_structure ); 293
if ( last_pic_droppable != s -> droppable )  299
av_log ( s -> avctx , AV_LOG_ERROR , "Cannot combine reference and non-reference fields in the same frame\n" ); 300
av_log_ask_for_sample ( s -> avctx , NULL ); 302
while ( h -> frame_num != h -> prev_frame_num && h -> prev_frame_num >= 0 && ! s0 -> first_field && h -> frame_num != ( h -> prev_frame_num + 1 ) % ( 1 << h -> sps . log2_max_frame_num ) )  319
Picture * prev = h -> short_ref_count ? h -> short_ref [ 0 ] : NULL ; 321
av_log ( h -> s . avctx , AV_LOG_DEBUG , "Frame num gap %d %d\n" , h -> frame_num , h -> prev_frame_num ); 322
if ( ff_h264_frame_start ( h ) < 0 )  324
h -> prev_frame_num ++; 326
h -> prev_frame_num %= 1 << h -> sps . log2_max_frame_num; 327
s -> current_picture_ptr -> frame_num = h -> prev_frame_num; 328
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 0 ); 329
ff_thread_report_progress ( & s -> current_picture_ptr -> f , INT_MAX , 1 ); 330
if ( ( ret = ff_generate_sliding_window_mmcos ( h , 1 ) ) < 0 && s -> avctx -> err_recognition & AV_EF_EXPLODE )  331
return ret ; 333
if ( ff_h264_execute_ref_pic_marking ( h , h -> mmco , h -> mmco_index ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  334
if ( h -> short_ref_count )  343
if ( prev )  344
av_image_copy ( h -> short_ref [ 0 ] -> f . data , h -> short_ref [ 0 ] -> f . linesize , ( const uint8_t * * ) prev -> f . data , prev -> f . linesize , s -> avctx -> pix_fmt , s -> mb_width * 16 , s -> mb_height * 16 ); 345
h -> short_ref [ 0 ] -> poc = prev -> poc + 2; 348
h -> short_ref [ 0 ] -> frame_num = h -> prev_frame_num; 350
if ( ! FIELD_PICTURE || s -> picture_structure == last_pic_structure )  363
if ( s0 -> current_picture_ptr -> frame_num != h -> frame_num )  369
if ( ff_h264_frame_start ( h ) < 0 )  388
if ( h != h0 && ( ret = clone_slice ( h , h0 ) ) < 0 )  396
return ret ; 397
s -> current_picture_ptr -> frame_num = h -> frame_num; 399
av_assert1 ( s -> mb_num == s -> mb_width * s -> mb_height ); 401
if ( first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s -> mb_num || first_mb_in_slice >= s -> mb_num )  402
av_log ( h -> s . avctx , AV_LOG_ERROR , "first_mb_in_slice overflow\n" ); 404
s -> resync_mb_x = s -> mb_x = first_mb_in_slice % s -> mb_width; 407
s -> resync_mb_y = s -> mb_y = ( first_mb_in_slice / s -> mb_width ) << FIELD_OR_MBAFF_PICTURE; 408
if ( s -> picture_structure == PICT_BOTTOM_FIELD )  409
s -> resync_mb_y = s -> mb_y = s -> mb_y + 1; 410
av_assert1 ( s -> mb_y < s -> mb_height ); 411
if ( s -> picture_structure == PICT_FRAME )  413
h -> curr_pic_num = h -> frame_num; 414
h -> max_pic_num = 1 << h -> sps . log2_max_frame_num; 415
h -> curr_pic_num = 2 * h -> frame_num + 1; 417
h -> max_pic_num = 1 << ( h -> sps . log2_max_frame_num + 1 ); 418
if ( h -> nal_unit_type == NAL_IDR_SLICE )  421
get_ue_golomb ( & s -> gb ); 422
if ( h -> sps . poc_type == 0 )  424
h -> poc_lsb = get_bits ( & s -> gb , h -> sps . log2_max_poc_lsb ); 425
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  427
h -> delta_poc_bottom = get_se_golomb ( & s -> gb ); 428
if ( h -> sps . poc_type == 1 && ! h -> sps . delta_pic_order_always_zero_flag )  431
h -> delta_poc [ 0 ] = get_se_golomb ( & s -> gb ); 432
if ( h -> pps . pic_order_present == 1 && s -> picture_structure == PICT_FRAME )  434
h -> delta_poc [ 1 ] = get_se_golomb ( & s -> gb ); 435
init_poc ( h ); 438
if ( h -> pps . redundant_pic_cnt_present )  440
h -> redundant_pic_count = get_ue_golomb ( & s -> gb ); 441
h -> ref_count [ 0 ] = h -> pps . ref_count [ 0 ]; 444
h -> ref_count [ 1 ] = h -> pps . ref_count [ 1 ]; 445
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  447
max [ 0 ] = max [ 1 ] = s -> picture_structure == PICT_FRAME ? 15 : 31; 449
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  451
h -> direct_spatial_mv_pred = get_bits1 ( & s -> gb ); 452
num_ref_idx_active_override_flag = get_bits1 ( & s -> gb ); 453
if ( num_ref_idx_active_override_flag )  455
h -> ref_count [ 0 ] = get_ue_golomb ( & s -> gb ) + 1; 456
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  457
h -> ref_count [ 1 ] = get_ue_golomb ( & s -> gb ) + 1; 458
h -> ref_count [ 1 ] = 1; 461
if ( h -> ref_count [ 0 ] - 1 > max [ 0 ] || h -> ref_count [ 1 ] - 1 > max [ 1 ] )  464
av_log ( h -> s . avctx , AV_LOG_ERROR , "reference overflow %u > %u or %u > %u\n" , h -> ref_count [ 0 ] - 1 , max [ 0 ] , h -> ref_count [ 1 ] - 1 , max [ 1 ] ); 465
h -> ref_count [ 0 ] = h -> ref_count [ 1 ] = 1; 466
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  470
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = h -> list_count = 0; 475
ff_h264_fill_default_ref_list ( h ); 478
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && ff_h264_decode_ref_pic_list_reordering ( h ) < 0 )  480
h -> ref_count [ 1 ] = h -> ref_count [ 0 ] = 0; 482
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I )  486
s -> last_picture_ptr = & h -> ref_list [ 0 ] [ 0 ]; 487
s -> last_picture_ptr -> owner2 = s; 488
ff_copy_picture ( & s -> last_picture , s -> last_picture_ptr ); 489
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B )  491
s -> next_picture_ptr = & h -> ref_list [ 1 ] [ 0 ]; 492
s -> next_picture_ptr -> owner2 = s; 493
ff_copy_picture ( & s -> next_picture , s -> next_picture_ptr ); 494
if ( ( h -> pps . weighted_pred && h -> slice_type_nos == AV_PICTURE_TYPE_P ) || ( h -> pps . weighted_bipred_idc == 1 && h -> slice_type_nos == AV_PICTURE_TYPE_B ) )  497
pred_weight_table ( h ); 500
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  501
implicit_weight_table ( h , - 1 ); 503
h -> use_weight = 0; 505
h -> luma_weight_flag [ i ] = 0; 507
h -> chroma_weight_flag [ i ] = 0; 508
if ( h -> nal_ref_idc && ff_h264_decode_ref_pic_marking ( h0 , & s -> gb , ! ( s -> avctx -> active_thread_type & FF_THREAD_FRAME ) || h0 -> current_slice == 0 ) < 0 && ( s -> avctx -> err_recognition & AV_EF_EXPLODE ) )  517
ff_h264_fill_mbaff_ref_list ( h ); 525
if ( h -> pps . weighted_bipred_idc == 2 && h -> slice_type_nos == AV_PICTURE_TYPE_B )  527
implicit_weight_table ( h , 0 ); 528
implicit_weight_table ( h , 1 ); 529
if ( h -> slice_type_nos == AV_PICTURE_TYPE_B && ! h -> direct_spatial_mv_pred )  533
ff_h264_direct_dist_scale_factor ( h ); 534
ff_h264_direct_ref_list_init ( h ); 535
if ( h -> slice_type_nos != AV_PICTURE_TYPE_I && h -> pps . cabac )  537
tmp = get_ue_golomb_31 ( & s -> gb ); 538
if ( tmp > 2 )  539
av_log ( s -> avctx , AV_LOG_ERROR , "cabac_init_idc overflow\n" ); 540
h -> cabac_init_idc = tmp; 543
h -> last_qscale_diff = 0; 546
tmp = h -> pps . init_qp + get_se_golomb ( & s -> gb ); 547
if ( tmp > 51 + 6 * ( h -> sps . bit_depth_luma - 8 ) )  548
av_log ( s -> avctx , AV_LOG_ERROR , "QP %u out of range\n" , tmp ); 549
s -> qscale = tmp; 552
h -> chroma_qp [ 0 ] = get_chroma_qp ( h , 0 , s -> qscale ); 553
h -> chroma_qp [ 1 ] = get_chroma_qp ( h , 1 , s -> qscale ); 554
if ( h -> slice_type == AV_PICTURE_TYPE_SP )  556
get_bits1 ( & s -> gb ); 557
if ( h -> slice_type == AV_PICTURE_TYPE_SP || h -> slice_type == AV_PICTURE_TYPE_SI )  558
get_se_golomb ( & s -> gb ); 560
h -> deblocking_filter = 1; 562
h -> slice_alpha_c0_offset = 52; 563
h -> slice_beta_offset = 52; 564
if ( h -> pps . deblocking_filter_parameters_present )  565
tmp = get_ue_golomb_31 ( & s -> gb ); 566
if ( tmp > 2 )  567
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking_filter_idc %u out of range\n" , tmp ); 568
h -> deblocking_filter = tmp; 572
if ( h -> deblocking_filter < 2 )  573
h -> deblocking_filter ^= 1; 574
if ( h -> deblocking_filter )  576
h -> slice_alpha_c0_offset += get_se_golomb ( & s -> gb ) << 1; 577
h -> slice_beta_offset += get_se_golomb ( & s -> gb ) << 1; 578
if ( h -> slice_alpha_c0_offset > 104U || h -> slice_beta_offset > 104U )  579
av_log ( s -> avctx , AV_LOG_ERROR , "deblocking filter parameters %d %d out of range\n" , h -> slice_alpha_c0_offset , h -> slice_beta_offset ); 581
if ( s -> avctx -> skip_loop_filter >= AVDISCARD_ALL || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONKEY && h -> slice_type_nos != AV_PICTURE_TYPE_I ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_BIDIR && h -> slice_type_nos == AV_PICTURE_TYPE_B ) || ( s -> avctx -> skip_loop_filter >= AVDISCARD_NONREF && h -> nal_ref_idc == 0 ) )  589
h -> deblocking_filter = 0; 596
if ( h -> deblocking_filter == 1 && h0 -> max_contexts > 1 )  598
if ( s -> avctx -> flags2 & CODEC_FLAG2_FAST )  599
h -> deblocking_filter = 2; 602
av_log ( s -> avctx , AV_LOG_INFO , "Cannot parallelize deblocking type 1, decoding such frames in sequential order\n" ); 606
av_log ( h -> s . avctx , AV_LOG_ERROR , "Deblocking switched inside frame.\n" ); 611
h -> qp_thresh = 15 + 52 - FFMIN ( h -> slice_alpha_c0_offset , h -> slice_beta_offset ) - FFMAX3 ( 0 , h -> pps . chroma_qp_index_offset [ 0 ] , h -> pps . chroma_qp_index_offset [ 1 ] ) + 6 * ( h -> sps . bit_depth_luma - 8 ); 617
h -> slice_num = ++ h0 -> current_slice; 625
if ( h -> slice_num )  627
h0 -> slice_row [ ( h -> slice_num - 1 ) & ( MAX_SLICES - 1 ) ] = s -> resync_mb_y; 628
if ( h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] + 3 >= s -> resync_mb_y && h0 -> slice_row [ h -> slice_num & ( MAX_SLICES - 1 ) ] <= s -> resync_mb_y && h -> slice_num >= MAX_SLICES )  629
av_log ( s -> avctx , AV_LOG_WARNING , "Possibly too many slices (%d >= %d), increase MAX_SLICES and recompile if there are artifacts\n" , h -> slice_num , MAX_SLICES ); 633
int * ref2frm = h -> ref2frm [ h -> slice_num & ( MAX_SLICES - 1 ) ] [ j ] ; 638
if ( h -> ref_list [ j ] [ i ] . f . data [ 0 ] )  641
uint8_t * base = h -> ref_list [ j ] [ i ] . f . base [ 0 ] ; 643
for (k = 0; k < h->short_ref_count; k++) 644
if ( h -> short_ref [ k ] -> f . base [ 0 ] == base )  645
for (k = 0; k < h->long_ref_count; k++) 649
if ( h -> long_ref [ k ] && h -> long_ref [ k ] -> f . base [ 0 ] == base )  650
id_list [ i ] = h -> short_ref_count + k; 651
ref2frm [ 0 ] = ref2frm [ 1 ] = - 1; 657
for (i = 0; i < 16; i++) 659
ref2frm [ i + 2 ] = 4 * id_list [ i ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 660
ref2frm [ 18 + 0 ] = ref2frm [ 18 + 1 ] = - 1; 662
for (i = 16; i < 48; i++) 664
ref2frm [ i + 4 ] = 4 * id_list [ ( i - 16 ) >> 1 ] + ( h -> ref_list [ j ] [ i ] . f . reference & 3 ); 665
h -> emu_edge_width = ( s -> flags & CODEC_FLAG_EMU_EDGE || ( ! h -> sps . frame_mbs_only_flag && s -> avctx -> active_thread_type ) ) ? 0 : 16; 670
h -> emu_edge_height = ( FRAME_MBAFF || FIELD_PICTURE ) ? 0 : h -> emu_edge_width; 674
if ( s -> avctx -> debug & FF_DEBUG_PICT_INFO )  676
av_log ( h -> s . avctx , AV_LOG_DEBUG , "slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\n" , h -> slice_num , ( s -> picture_structure == PICT_FRAME ? "F" : s -> picture_structure == PICT_TOP_FIELD ? "T" : "B" ) , first_mb_in_slice , av_get_picture_type_char ( h -> slice_type ) , h -> slice_type_fixed ? " fix" : "" , h -> nal_unit_type == NAL_IDR_SLICE ? " IDR" : "" , pps_id , h -> frame_num , s -> current_picture_ptr -> field_poc [ 0 ] , s -> current_picture_ptr -> field_poc [ 1 ] , h -> ref_count [ 0 ] , h -> ref_count [ 1 ] , s -> qscale , h -> deblocking_filter , h -> slice_alpha_c0_offset / 2 - 26 , h -> slice_beta_offset / 2 - 26 , h -> use_weight , h -> use_weight == 1 && h -> use_weight_chroma ? "c" : "" , h -> slice_type == AV_PICTURE_TYPE_B ? ( h -> direct_spatial_mv_pred ? "SPAT" : "TEMP" ) : "" ); 677
------------------------------
196 ../data/NVD/CVE_2012_4190_PATCHED_ft_module_get_service.c FT_Module * limit = cur + library -> num_modules ; 21
CVE_2012_4190_PATCHED_ft_module_get_service( FT_Module    module,
const char*  service_id ) 2
FT_Pointer result = NULL ; 4
if ( module )  6
if ( module -> clazz -> get_interface )  12
result = module -> clazz -> get_interface ( module , service_id ); 13
if ( result == NULL )  15
FT_Library library = module -> library ; 19
FT_Module * cur = library -> modules ; 20
FT_Module * limit = cur + library -> num_modules ; 21
for ( ; cur < limit; cur++ ) 23
------------------------------
197 ../data/NVD/CVE_2012_4190_VULN_ft_module_get_service.c FT_Module * limit = cur + library -> num_modules ; 21
CVE_2012_4190_VULN_ft_module_get_service( FT_Module    module,
const char*  service_id ) 2
FT_Pointer result = NULL ; 4
if ( module )  6
if ( module -> clazz -> get_interface )  12
result = module -> clazz -> get_interface ( module , service_id ); 13
if ( result == NULL )  15
FT_Library library = module -> library ; 19
FT_Module * cur = library -> modules ; 20
FT_Module * limit = cur + library -> num_modules ; 21
for ( ; cur < limit; cur++ ) 23
------------------------------
198 ../data/NVD/CVE_2012_5669_PATCHED__bdf_parse_glyphs.c unsigned short sw = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) ; 414
static FT_Error
CVE_2012_5669_PATCHED__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  261
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 262
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 264
if ( p -> flags & _BDF_BITMAP )  267
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  328
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  344
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  372
if ( ! ( p -> flags & _BDF_ENCODING ) )  374
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 377
if ( error )  378
glyph -> bbx . width = _bdf_atos ( p -> list . field [ 1 ] , 0 , 10 ); 381
glyph -> bbx . height = _bdf_atos ( p -> list . field [ 2 ] , 0 , 10 ); 382
glyph -> bbx . x_offset = _bdf_atos ( p -> list . field [ 3 ] , 0 , 10 ); 383
glyph -> bbx . y_offset = _bdf_atos ( p -> list . field [ 4 ] , 0 , 10 ); 384
glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ); 387
glyph -> bbx . descent = ( short ) ( - glyph -> bbx . y_offset ); 388
p -> maxas = ( short ) FT_MAX ( glyph -> bbx . ascent , p -> maxas ); 392
p -> maxds = ( short ) FT_MAX ( glyph -> bbx . descent , p -> maxds ); 393
p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ); 395
p -> maxrb = ( short ) FT_MAX ( p -> rbearing , p -> maxrb ); 397
p -> minlb = ( short ) FT_MIN ( glyph -> bbx . x_offset , p -> minlb ); 398
p -> maxlb = ( short ) FT_MAX ( glyph -> bbx . x_offset , p -> maxlb ); 399
if ( ! ( p -> flags & _BDF_DWIDTH ) )  401
glyph -> dwidth = glyph -> bbx . width; 406
if ( p -> opts -> correct_metrics != 0 )  411
unsigned short sw = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) ; 414
if ( sw != glyph -> swidth )  420
glyph -> swidth = sw; 422
_bdf_set_glyph_modified ( font -> nmod , glyph -> encoding ); 428
------------------------------
199 ../data/NVD/CVE_2012_5669_VULN__bdf_parse_glyphs.c unsigned short sw = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) ; 413
static FT_Error
CVE_2012_5669_VULN__bdf_parse_glyphs( char*          line,
unsigned long  linelen,
unsigned long  lineno,
void*          call_data,
void*          client_data ) 6
_bdf_parse_t * p ; 13
bdf_glyph_t * glyph ; 14
bdf_font_t * font ; 15
p = ( _bdf_parse_t * ) client_data; 24
font = p -> font; 26
if ( ft_memcmp ( line , "COMMENT" , 7 ) == 0 )  30
if ( ! ( p -> flags & _BDF_GLYPHS ) )  45
if ( ft_memcmp ( line , "ENDFONT" , 7 ) == 0 )  81
if ( ft_memcmp ( line , "ENDCHAR" , 7 ) == 0 )  95
if ( ( p -> flags & _BDF_GLYPH ) && p -> glyph_enc == - 1 && p -> opts -> keep_unencoded == 0 )  105
if ( ft_memcmp ( line , "STARTCHAR" , 9 ) == 0 )  111
if ( ft_memcmp ( line , "ENCODING" , 8 ) == 0 )  145
if ( p -> glyph_enc == - 1 )  260
glyph = font -> unencoded + ( font -> unencoded_used - 1 ); 261
glyph = font -> glyphs + ( font -> glyphs_used - 1 ); 263
if ( p -> flags & _BDF_BITMAP )  266
if ( ft_memcmp ( line , "SWIDTH" , 6 ) == 0 )  327
if ( ft_memcmp ( line , "DWIDTH" , 6 ) == 0 )  343
if ( ft_memcmp ( line , "BBX" , 3 ) == 0 )  371
if ( ! ( p -> flags & _BDF_ENCODING ) )  373
error = _bdf_list_split ( & p -> list , ( char * ) " +" , line , linelen ); 376
if ( error )  377
glyph -> bbx . width = _bdf_atos ( p -> list . field [ 1 ] , 0 , 10 ); 380
glyph -> bbx . height = _bdf_atos ( p -> list . field [ 2 ] , 0 , 10 ); 381
glyph -> bbx . x_offset = _bdf_atos ( p -> list . field [ 3 ] , 0 , 10 ); 382
glyph -> bbx . y_offset = _bdf_atos ( p -> list . field [ 4 ] , 0 , 10 ); 383
glyph -> bbx . ascent = ( short ) ( glyph -> bbx . height + glyph -> bbx . y_offset ); 386
glyph -> bbx . descent = ( short ) ( - glyph -> bbx . y_offset ); 387
p -> maxas = ( short ) FT_MAX ( glyph -> bbx . ascent , p -> maxas ); 391
p -> maxds = ( short ) FT_MAX ( glyph -> bbx . descent , p -> maxds ); 392
p -> rbearing = ( short ) ( glyph -> bbx . width + glyph -> bbx . x_offset ); 394
p -> maxrb = ( short ) FT_MAX ( p -> rbearing , p -> maxrb ); 396
p -> minlb = ( short ) FT_MIN ( glyph -> bbx . x_offset , p -> minlb ); 397
p -> maxlb = ( short ) FT_MAX ( glyph -> bbx . x_offset , p -> maxlb ); 398
if ( ! ( p -> flags & _BDF_DWIDTH ) )  400
glyph -> dwidth = glyph -> bbx . width; 405
if ( p -> opts -> correct_metrics != 0 )  410
unsigned short sw = ( unsigned short ) FT_MulDiv ( glyph -> dwidth , 72000L , ( FT_Long ) ( font -> point_size * font -> resolution_x ) ) ; 413
if ( sw != glyph -> swidth )  419
glyph -> swidth = sw; 421
_bdf_set_glyph_modified ( font -> nmod , glyph -> encoding ); 427
------------------------------
200 ../data/NVD/CVE_2012_6060_PATCHED_dissect_iscsi_pdu.c guint end_offset = offset + tvb_length_remaining ( tvb , offset ) ; 9
static void
CVE_2012_6060_PATCHED_dissect_iscsi_pdu(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset, guint8 opcode, const char *opcode_str, guint32 data_segment_len, iscsi_session_t *iscsi_session, conversation_t *conversation) 2
guint end_offset = offset + tvb_length_remaining ( tvb , offset ) ; 9
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_ping_data ); 204
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_ping_data ); 218
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_immediate_data ); 297
immediate_data_length = offset - immediate_data_offset; 298
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , digestsActive ); 436
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , digestsActive ); 503
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , TRUE ); 528
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , TRUE ); 554
if ( ( end_offset - offset ) > 0 )  755
proto_tree_add_item ( ti , hf_iscsi_async_event_data , tvb , offset , end_offset - offset , ENC_NA ); 756
offset = end_offset; 759
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_vendor_specific_data ); 797
proto_item_set_len ( ti , offset - original_offset ); 855
if ( immediate_data_length )  899
if ( tvb_len > ( int ) immediate_data_length )  902
tvb_len = immediate_data_length; 903
if ( tvb_rlen > ( int ) immediate_data_length )  905
tvb_rlen = immediate_data_length; 906
data_tvb = tvb_new_subset ( tvb , immediate_data_offset , tvb_len , tvb_rlen ); 907
dissect_scsi_payload ( data_tvb , pinfo , tree , TRUE , & cdata -> itlq , itl , 0 ); 908
if ( ( end_offset - offset ) >= 2 )  918
int senseLen = tvb_get_ntohs ( tvb , offset ) ; 919
proto_tree_add_item ( ti , hf_iscsi_SenseLength , tvb , offset , 2 , ENC_BIG_ENDIAN ); 921
offset += 2; 922
if ( senseLen > 0 )  923
tvb_len = tvb_length_remaining ( tvb , offset ); 927
if ( tvb_len > senseLen )  928
tvb_len = senseLen; 929
tvb_rlen = tvb_reported_length_remaining ( tvb , offset ); 930
if ( tvb_rlen > senseLen )  931
tvb_rlen = senseLen; 932
data_tvb = tvb_new_subset ( tvb , offset , tvb_len , tvb_rlen ); 933
dissect_scsi_snsinfo ( data_tvb , pinfo , tree , 0 , tvb_len , & cdata -> itlq , itl ); 934
tvb_len = tvb_length_remaining ( tvb , offset ); 950
if ( tvb_len > ( int ) data_segment_len )  951
tvb_rlen = tvb_reported_length_remaining ( tvb , offset ); 953
if ( tvb_rlen > ( int ) data_segment_len )  954
data_tvb = tvb_new_subset ( tvb , offset , tvb_len , tvb_rlen ); 956
dissect_scsi_payload ( data_tvb , pinfo , tree , ( opcode == ISCSI_OPCODE_SCSI_DATA_OUT ) , & cdata -> itlq , itl , data_offset ); 957
------------------------------
201 ../data/NVD/CVE_2012_6060_VULN_dissect_iscsi_pdu.c guint end_offset = offset + tvb_length_remaining ( tvb , offset ) ; 9
static void
CVE_2012_6060_VULN_dissect_iscsi_pdu(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset, guint8 opcode, const char *opcode_str, guint32 data_segment_len, iscsi_session_t *iscsi_session, conversation_t *conversation) 2
guint end_offset = offset + tvb_length_remaining ( tvb , offset ) ; 9
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_ping_data ); 204
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_ping_data ); 218
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_immediate_data ); 297
immediate_data_length = offset - immediate_data_offset; 298
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , digestsActive ); 436
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , digestsActive ); 503
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , TRUE ); 528
offset = handleDataSegmentAsTextKeys ( pinfo , ti , tvb , offset , data_segment_len , end_offset , TRUE ); 554
if ( ( end_offset - offset ) > 0 )  755
proto_tree_add_item ( ti , hf_iscsi_async_event_data , tvb , offset , end_offset - offset , ENC_NA ); 756
offset = end_offset; 759
offset = handleDataSegment ( ti , tvb , offset , data_segment_len , end_offset , hf_iscsi_vendor_specific_data ); 797
proto_item_set_len ( ti , offset - original_offset ); 855
if ( immediate_data_length )  899
if ( tvb_len > ( int ) immediate_data_length )  902
tvb_len = immediate_data_length; 903
if ( tvb_rlen > ( int ) immediate_data_length )  905
tvb_rlen = immediate_data_length; 906
data_tvb = tvb_new_subset ( tvb , immediate_data_offset , tvb_len , tvb_rlen ); 907
dissect_scsi_payload ( data_tvb , pinfo , tree , TRUE , & cdata -> itlq , itl , 0 ); 908
if ( ( end_offset - offset ) >= 2 )  918
int senseLen = tvb_get_ntohs ( tvb , offset ) ; 919
proto_tree_add_item ( ti , hf_iscsi_SenseLength , tvb , offset , 2 , ENC_BIG_ENDIAN ); 921
offset += 2; 922
if ( senseLen > 0 )  923
tvb_len = tvb_length_remaining ( tvb , offset ); 927
if ( tvb_len > senseLen )  928
tvb_len = senseLen; 929
tvb_rlen = tvb_reported_length_remaining ( tvb , offset ); 930
if ( tvb_rlen > senseLen )  931
tvb_rlen = senseLen; 932
data_tvb = tvb_new_subset ( tvb , offset , tvb_len , tvb_rlen ); 933
dissect_scsi_snsinfo ( data_tvb , pinfo , tree , 0 , tvb_len , & cdata -> itlq , itl ); 934
tvb_len = tvb_length_remaining ( tvb , offset ); 950
if ( tvb_len > ( int ) data_segment_len )  951
tvb_rlen = tvb_reported_length_remaining ( tvb , offset ); 953
if ( tvb_rlen > ( int ) data_segment_len )  954
data_tvb = tvb_new_subset ( tvb , offset , tvb_len , tvb_rlen ); 956
dissect_scsi_payload ( data_tvb , pinfo , tree , ( opcode == ISCSI_OPCODE_SCSI_DATA_OUT ) , & cdata -> itlq , itl , data_offset ); 957
------------------------------
202 ../data/NVD/CVE_2013_0750_VULN_ReplaceRegExpCallback.c size_t growth = leftlen + replen ; 15
static bool
CVE_2013_0750_VULN_ReplaceRegExpCallback(JSContext *cx, RegExpStatics *res, size_t count, void *p) 2
ReplaceData & rdata = * static_cast < ReplaceData * > p 4
rdata . calledBack = true; 6
size_t leftoff = rdata . leftIndex ; 7
size_t leftlen = res -> matchStart ( ) - leftoff ; 8
rdata . leftIndex = res -> matchLimit ( ); 9
size_t replen = 0 ; 11
if ( ! FindReplaceLength ( cx , res , rdata , & replen ) )  12
size_t growth = leftlen + replen ; 15
if ( ! rdata . sb . reserve ( rdata . sb . length ( ) + growth ) )  16
------------------------------
203 ../data/NVD/CVE_2013_0756_PATCHED_obj_toSource.c const jschar * end = vchars + vlength ; 122
static JSBool
CVE_2013_0756_PATCHED_obj_toSource(JSContext *cx, unsigned argc, Value *vp) 2
CallArgs args = CallArgsFromVp ( argc , vp ) ; 4
RootedObject obj ( cx , ToObject ( cx , args . thisv ( ) ) ) ; 7
if ( ! obj )  8
bool outermost = ( cx -> cycleDetectorSet . count ( ) == 0 ) ; 12
AutoCycleDetector detector ( cx , obj ) ; 14
if ( ! detector . init ( ) )  15
if ( detector . foundCycle ( ) )  17
StringBuffer buf ( cx ) ; 25
if ( outermost && ! buf . append ( '(' ) )  26
if ( ! buf . append ( '{' ) )  28
Value val [ 2 ] ; 31
JSString * gsop [ 2 ] ; 35
AutoIdVector idv ( cx ) ; 38
if ( ! GetPropertyNames ( cx , obj , JSITER_OWNONLY , & idv ) )  39
bool comma = false ; 42
for (size_t i = 0; i < idv.length(); ++i) 43
RootedId id ( cx , idv [ i ] ) ; 44
RootedObject obj2 ( cx ) ; 45
RootedShape shape ( cx ) ; 46
if ( ! JSObject :: lookupGeneric ( cx , obj , id , & obj2 , & shape ) )  47
int valcnt = 0 ; 51
if ( shape )  52
bool doGet = true ; 53
if ( obj2 -> isNative ( ) )  54
unsigned attrs = shape -> attributes ( ) ; 55
if ( attrs & JSPROP_GETTER )  56
doGet = false; 57
val [ valcnt ] = shape -> getterValue ( ); 58
gsop [ valcnt ] = cx -> runtime -> atomState . getAtom; 59
valcnt ++; 60
if ( attrs & JSPROP_SETTER )  62
doGet = false; 63
val [ valcnt ] = shape -> setterValue ( ); 64
gsop [ valcnt ] = cx -> runtime -> atomState . setAtom; 65
valcnt ++; 66
if ( doGet )  69
valcnt = 1; 70
gsop [ 0 ] = NULL; 71
MutableHandleValue vp = MutableHandleValue :: fromMarkedLocation ( & val [ 0 ] ) ; 72
if ( ! JSObject :: getGeneric ( cx , obj , obj , id , vp ) )  73
RawString s = ToString ( cx , IdToValue ( id ) ) ; 79
if ( ! s )  80
Rooted < JSLinearString * > idstr ( cx , s -> ensureLinear ( cx ) ) ; 82
if ( ! idstr )  83
if ( JSID_IS_ATOM ( id ) ? ! IsIdentifier ( idstr ) : ( ! JSID_IS_INT ( id ) || JSID_TO_INT ( id ) < 0 ) )  90
s = js_QuoteString ( cx , idstr , jschar ( '\'' ) ); 94
if ( ! s || ! ( idstr = s -> ensureLinear ( cx ) ) )  95
for (int j = 0; j < valcnt; j++) 99
if ( gsop [ j ] && val [ j ] . isUndefined ( ) )  104
RootedString valstr ( cx , js_ValueToSource ( cx , val [ j ] ) ) ; 108
if ( ! valstr )  109
const jschar * vchars = valstr -> getChars ( cx ) ; 111
if ( ! vchars )  112
size_t vlength = valstr -> length ( ) ; 114
if ( gsop [ j ] && IsFunctionObject ( val [ j ] ) )  120
const jschar * start = vchars ; 121
const jschar * end = vchars + vlength ; 122
uint8_t parenChomp = 0 ; 124
if ( vchars [ 0 ] == '(' )  125
vchars ++; 126
parenChomp = 1; 127
if ( vchars )  131
vchars = js_strchr_limit ( vchars , ' ' , end ); 132
if ( vchars )  138
vchars = js_strchr_limit ( vchars , '(' , end ); 139
if ( vchars )  141
if ( * vchars == ' ' )  142
vchars ++; 143
vlength = end - vchars - parenChomp; 144
gsop [ j ] = NULL; 146
vchars = start; 147
if ( comma && ! buf . append ( ", " ) )  151
comma = true; 153
if ( gsop [ j ] )  155
if ( ! buf . append ( gsop [ j ] ) || ! buf . append ( ' ' ) )  156
if ( ! buf . append ( idstr ) )  159
if ( ! buf . append ( gsop [ j ] ? ' ' : ':' ) )  161
if ( ! buf . append ( vchars , vlength ) )  164
------------------------------
204 ../data/NVD/CVE_2013_0756_VULN_obj_toSource.c const jschar * end = vchars + vlength ; 160
static JSBool
CVE_2013_0756_VULN_obj_toSource(JSContext *cx, unsigned argc, Value *vp) 2
CallArgs args = CallArgsFromVp ( argc , vp ) ; 4
bool comma = false ; 6
const jschar * vchars ; 7
size_t vlength ; 8
Value * val ; 9
JSString * gsop [ 2 ] ; 10
Value localroot [ 4 ] ; 15
bool outermost = ( cx -> sharpObjectMap . depth == 0 ) ; 20
RootedObject obj ( cx , ToObject ( cx , args . thisv ( ) ) ) ; 22
if ( ! obj )  23
JSIdArray * ida ; 26
if ( ! js_EnterSharpObject ( cx , obj , & ida , & alreadySeen , & isSharp ) )  29
if ( ! ida )  32
StringBuffer buf ( cx ) ; 64
if ( outermost && ! buf . append ( '(' ) )  65
if ( ! buf . append ( '{' ) )  67
val = localroot + 2; 75
RootedId id ( cx ) ; 77
for (int i = 0; i < ida->length; i++) 78
id = ida -> vector [ i ]; 80
Rooted < JSLinearString * > idstr ( cx ) ; 81
RootedObject obj2 ( cx ) ; 83
RootedShape prop ( cx ) ; 84
if ( ! JSObject :: lookupGeneric ( cx , obj , id , & obj2 , & prop ) )  85
JSString * s = ToString ( cx , IdToValue ( id ) ) ; 92
if ( ! s || ! ( idstr = s -> ensureLinear ( cx ) ) )  93
int valcnt = 0 ; 96
if ( prop )  97
bool doGet = true ; 98
if ( obj2 -> isNative ( ) )  99
Shape * shape = ( Shape * ) prop ; 100
unsigned attrs = shape -> attributes ( ) ; 101
if ( attrs & JSPROP_GETTER )  102
doGet = false; 103
val [ valcnt ] = shape -> getterValue ( ); 104
gsop [ valcnt ] = cx -> runtime -> atomState . getAtom; 105
valcnt ++; 106
if ( attrs & JSPROP_SETTER )  108
doGet = false; 109
val [ valcnt ] = shape -> setterValue ( ); 110
gsop [ valcnt ] = cx -> runtime -> atomState . setAtom; 111
valcnt ++; 112
if ( doGet )  115
valcnt = 1; 116
gsop [ 0 ] = NULL; 117
MutableHandleValue vp = MutableHandleValue :: fromMarkedLocation ( & val [ 0 ] ) ; 118
if ( ! JSObject :: getGeneric ( cx , obj , obj , id , vp ) )  119
if ( JSID_IS_ATOM ( id ) ? ! IsIdentifier ( idstr ) : ( ! JSID_IS_INT ( id ) || JSID_TO_INT ( id ) < 0 ) )  128
s = js_QuoteString ( cx , idstr , jschar ( '\'' ) ); 131
if ( ! s || ! ( idstr = s -> ensureLinear ( cx ) ) )  132
for (int j = 0; j < valcnt; j++) 136
if ( gsop [ j ] && val [ j ] . isUndefined ( ) )  141
JSString * valstr = js_ValueToSource ( cx , val [ j ] ) ; 145
if ( ! valstr )  146
vchars = valstr -> getChars ( cx ); 149
if ( ! vchars )  150
vlength = valstr -> length ( ); 152
if ( gsop [ j ] && IsFunctionObject ( val [ j ] ) )  158
const jschar * start = vchars ; 159
const jschar * end = vchars + vlength ; 160
uint8_t parenChomp = 0 ; 162
if ( vchars [ 0 ] == '(' )  163
vchars ++; 164
parenChomp = 1; 165
if ( vchars )  169
vchars = js_strchr_limit ( vchars , ' ' , end ); 170
if ( vchars )  176
vchars = js_strchr_limit ( vchars , '(' , end ); 177
if ( vchars )  179
if ( * vchars == ' ' )  180
vchars ++; 181
vlength = end - vchars - parenChomp; 182
gsop [ j ] = NULL; 184
vchars = start; 185
if ( comma && ! buf . append ( ", " ) )  189
comma = true; 191
if ( gsop [ j ] )  193
if ( ! buf . append ( gsop [ j ] ) || ! buf . append ( ' ' ) )  194
if ( ! buf . append ( idstr ) )  197
if ( ! buf . append ( gsop [ j ] ? ' ' : ':' ) )  199
if ( ! buf . append ( vchars , vlength ) )  202
------------------------------
205 ../data/NVD/CVE_2013_0761_PATCHED_CopyTrackData.c TrackTicks inputStartTicks = inputEndTicks - ticks ; 58
void CVE_2013_0761_PATCHED_CopyTrackData(StreamBuffer::Track* aInputTrack,
uint32_t aMapIndex, GraphTime aFrom, GraphTime aTo,
bool* aOutputTrackFinished) 3
TrackMapEntry * map = & mTrackMap [ aMapIndex ] ; 5
StreamBuffer :: Track * outputTrack = mBuffer . FindTrack ( map -> mOutputTrackID ) ; 6
TrackRate rate = outputTrack -> GetRate ( ) ; 9
MediaStream * source = map -> mInputPort -> GetSource ( ) ; 11
GraphTime next ; 13
for (GraphTime t = aFrom; t < aTo; t = next) 15
MediaInputPort :: InputInterval interval = map -> mInputPort -> GetNextInputInterval ( t ) ; 16
interval . mEnd = NS_MIN ( interval . mEnd , aTo ); 17
if ( interval . mStart >= interval . mEnd )  18
next = interval . mEnd; 20
StreamTime outputEnd = GraphTimeToStreamTime ( interval . mEnd ) ; 23
TrackTicks startTicks = outputTrack -> GetEnd ( ) ; 24
TrackTicks endTicks = TimeToTicksRoundUp ( rate , outputEnd ) ; 30
TrackTicks ticks = endTicks - startTicks ; 31
StreamTime inputEnd = source -> GraphTimeToStreamTime ( interval . mEnd ) ; 33
if ( interval . mInputIsBlocked )  44
TrackTicks inputEndTicks = TimeToTicksRoundUp ( rate , inputEnd ) ; 57
TrackTicks inputStartTicks = inputEndTicks - ticks ; 58
segment -> AppendSlice ( * aInputTrack -> GetSegment ( ) , NS_MIN ( inputTrackEndPoint , inputStartTicks ) , NS_MIN ( inputTrackEndPoint , inputEndTicks ) ); 59
LOG ( PR_LOG_DEBUG , ( "TrackUnionStream %p appending %lld ticks of input data to track %d" , this , ( long long ) ( NS_MIN ( inputTrackEndPoint , inputEndTicks ) - NS_MIN ( inputTrackEndPoint , inputStartTicks ) ) , outputTrack -> GetID ( ) ) ); 62
------------------------------
206 ../data/NVD/CVE_2013_0761_PATCHED_CopyTrackData.c TrackTicks ticks = endTicks - startTicks ; 31
void CVE_2013_0761_PATCHED_CopyTrackData(StreamBuffer::Track* aInputTrack,
uint32_t aMapIndex, GraphTime aFrom, GraphTime aTo,
bool* aOutputTrackFinished) 3
TrackMapEntry * map = & mTrackMap [ aMapIndex ] ; 5
StreamBuffer :: Track * outputTrack = mBuffer . FindTrack ( map -> mOutputTrackID ) ; 6
TrackRate rate = outputTrack -> GetRate ( ) ; 9
GraphTime next ; 13
for (GraphTime t = aFrom; t < aTo; t = next) 15
MediaInputPort :: InputInterval interval = map -> mInputPort -> GetNextInputInterval ( t ) ; 16
interval . mEnd = NS_MIN ( interval . mEnd , aTo ); 17
if ( interval . mStart >= interval . mEnd )  18
next = interval . mEnd; 20
StreamTime outputEnd = GraphTimeToStreamTime ( interval . mEnd ) ; 23
TrackTicks startTicks = outputTrack -> GetEnd ( ) ; 24
TrackTicks endTicks = TimeToTicksRoundUp ( rate , outputEnd ) ; 30
TrackTicks ticks = endTicks - startTicks ; 31
segment -> AppendNullData ( ticks ); 46
LOG ( PR_LOG_DEBUG , ( "TrackUnionStream %p appending %lld ticks of null data to track %d" , this , ( long long ) ticks , outputTrack -> GetID ( ) ) ); 47
TrackTicks inputStartTicks = inputEndTicks - ticks ; 58
segment -> AppendSlice ( * aInputTrack -> GetSegment ( ) , NS_MIN ( inputTrackEndPoint , inputStartTicks ) , NS_MIN ( inputTrackEndPoint , inputEndTicks ) ); 59
LOG ( PR_LOG_DEBUG , ( "TrackUnionStream %p appending %lld ticks of input data to track %d" , this , ( long long ) ( NS_MIN ( inputTrackEndPoint , inputEndTicks ) - NS_MIN ( inputTrackEndPoint , inputStartTicks ) ) , outputTrack -> GetID ( ) ) ); 62
------------------------------
207 ../data/NVD/CVE_2013_0761_VULN_CopyTrackData.c TrackTicks inputStartTicks = inputEndTicks - ticks ; 58
void CVE_2013_0761_VULN_CopyTrackData(uint32_t aMapIndex, GraphTime aFrom, GraphTime aTo,
bool* aOutputTrackFinished) 2
TrackMapEntry * map = & mTrackMap [ aMapIndex ] ; 4
StreamBuffer :: Track * outputTrack = map -> mOutputTrack ; 6
TrackRate rate = outputTrack -> GetRate ( ) ; 7
MediaStream * source = map -> mInputPort -> GetSource ( ) ; 9
GraphTime next ; 13
for (GraphTime t = aFrom; t < aTo; t = next) 15
MediaInputPort :: InputInterval interval = map -> mInputPort -> GetNextInputInterval ( t ) ; 16
interval . mEnd = NS_MIN ( interval . mEnd , aTo ); 17
if ( interval . mStart >= interval . mEnd )  18
next = interval . mEnd; 20
StreamTime outputEnd = GraphTimeToStreamTime ( interval . mEnd ) ; 23
TrackTicks startTicks = outputTrack -> GetEnd ( ) ; 24
TrackTicks endTicks = TimeToTicksRoundUp ( rate , outputEnd ) ; 30
TrackTicks ticks = endTicks - startTicks ; 31
StreamTime inputEnd = source -> GraphTimeToStreamTime ( interval . mEnd ) ; 33
if ( interval . mInputIsBlocked )  44
TrackTicks inputEndTicks = TimeToTicksRoundUp ( rate , inputEnd ) ; 57
TrackTicks inputStartTicks = inputEndTicks - ticks ; 58
segment -> AppendSlice ( * inputTrack -> GetSegment ( ) , NS_MIN ( inputTrackEndPoint , inputStartTicks ) , NS_MIN ( inputTrackEndPoint , inputEndTicks ) ); 59
LOG ( PR_LOG_DEBUG , ( "TrackUnionStream %p appending %lld ticks of input data to track %d" , this , ( long long ) ( NS_MIN ( inputTrackEndPoint , inputEndTicks ) - NS_MIN ( inputTrackEndPoint , inputStartTicks ) ) , outputTrack -> GetID ( ) ) ); 62
------------------------------
208 ../data/NVD/CVE_2013_0761_VULN_CopyTrackData.c TrackTicks ticks = endTicks - startTicks ; 31
void CVE_2013_0761_VULN_CopyTrackData(uint32_t aMapIndex, GraphTime aFrom, GraphTime aTo,
bool* aOutputTrackFinished) 2
TrackMapEntry * map = & mTrackMap [ aMapIndex ] ; 4
StreamBuffer :: Track * outputTrack = map -> mOutputTrack ; 6
TrackRate rate = outputTrack -> GetRate ( ) ; 7
GraphTime next ; 13
for (GraphTime t = aFrom; t < aTo; t = next) 15
MediaInputPort :: InputInterval interval = map -> mInputPort -> GetNextInputInterval ( t ) ; 16
interval . mEnd = NS_MIN ( interval . mEnd , aTo ); 17
if ( interval . mStart >= interval . mEnd )  18
next = interval . mEnd; 20
StreamTime outputEnd = GraphTimeToStreamTime ( interval . mEnd ) ; 23
TrackTicks startTicks = outputTrack -> GetEnd ( ) ; 24
TrackTicks endTicks = TimeToTicksRoundUp ( rate , outputEnd ) ; 30
TrackTicks ticks = endTicks - startTicks ; 31
segment -> AppendNullData ( ticks ); 46
LOG ( PR_LOG_DEBUG , ( "TrackUnionStream %p appending %lld ticks of null data to track %d" , this , ( long long ) ticks , outputTrack -> GetID ( ) ) ); 47
TrackTicks inputStartTicks = inputEndTicks - ticks ; 58
segment -> AppendSlice ( * inputTrack -> GetSegment ( ) , NS_MIN ( inputTrackEndPoint , inputStartTicks ) , NS_MIN ( inputTrackEndPoint , inputEndTicks ) ); 59
LOG ( PR_LOG_DEBUG , ( "TrackUnionStream %p appending %lld ticks of input data to track %d" , this , ( long long ) ( NS_MIN ( inputTrackEndPoint , inputEndTicks ) - NS_MIN ( inputTrackEndPoint , inputStartTicks ) ) , outputTrack -> GetID ( ) ) ); 62
------------------------------
209 ../data/NVD/CVE_2013_0771_PATCHED_nsTextFrame__ReflowText.c int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
void
CVE_2013_0771_PATCHED_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
if ( whitespaceCount )  112
offset += whitespaceCount; 113
length -= whitespaceCount; 114
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  126
if ( aLineLayout . GetInFirstLetter ( ) )  130
if ( mTextRun )  142
int32_t firstLetterLength = length ; 143
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  144
if ( newLineOffset >= 0 )  147
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 149
firstLetterLength = 0; 163
length = firstLetterLength; 166
if ( ! mTextRun )  207
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 226
int32_t limitLength = length ; 239
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 240
if ( forceBreak >= offset + length )  242
forceBreak = - 1; 245
if ( forceBreak >= 0 )  247
limitLength = forceBreak - offset; 248
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 297
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 299
if ( charsFit >= limitLength )  311
charsFit = limitLength; 312
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 369
aStatus = contentLength == maxContentLength ? NS_FRAME_COMPLETE : NS_FRAME_NOT_COMPLETE; 465
if ( contentLength > 0 && mContentOffset + contentLength - 1 == newLineOffset )  471
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 473
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 476
aStatus |= NS_INLINE_BREAK_FIRST_LETTER_COMPLETE; 480
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  484
if ( ! cachedNewlineOffset )  488
cachedNewlineOffset = new NewlineProperty 489
SetLength ( contentLength , & aLineLayout , ALLOW_FRAME_CREATION_AND_DESTRUCTION ); 520
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 526
------------------------------
210 ../data/NVD/CVE_2013_0771_VULN_nsTextFrame__ReflowText.c int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
void
CVE_2013_0771_VULN_nsTextFrame::ReflowText(nsLineLayout& aLineLayout, nscoord aAvailableWidth,
nsRenderingContext* aRenderingContext,
bool aShouldBlink,
nsHTMLReflowMetrics& aMetrics,
nsReflowStatus& aStatus) 6
int32_t maxContentLength = GetInFlowContentLength ( ) ; 33
if ( ! maxContentLength )  36
const nsStyleText * textStyle = GetStyleText ( ) ; 59
bool atStartOfLine = aLineLayout . LineAtStart ( ) ; 61
const nsTextFragment * frag = mContent -> GetText ( ) ; 69
int32_t length = maxContentLength ; 74
int32_t offset = GetContentOffset ( ) ; 75
int32_t newLineOffset = - 1 ; 78
int32_t contentNewLineOffset = - 1 ; 79
NewlineProperty * cachedNewlineOffset = nullptr ; 81
if ( textStyle -> NewlineIsSignificant ( ) )  82
cachedNewlineOffset =
static_cast < NewlineProperty * > mContent -> GetProperty ( nsGkAtoms :: newline ) 84
if ( cachedNewlineOffset && cachedNewlineOffset -> mStartOffset <= offset && ( cachedNewlineOffset -> mNewlineOffset == - 1 || cachedNewlineOffset -> mNewlineOffset >= offset ) )  85
contentNewLineOffset = cachedNewlineOffset -> mNewlineOffset; 88
contentNewLineOffset = FindChar ( frag , offset , mContent -> TextLength ( ) - offset , '\n' ); 90
if ( contentNewLineOffset < offset + length )  93
newLineOffset = contentNewLineOffset; 99
if ( newLineOffset >= 0 )  101
length = newLineOffset + 1 - offset; 102
if ( ( atStartOfLine && ! textStyle -> WhiteSpaceIsSignificant ( ) ) || ( GetStateBits ( ) & TEXT_FORCE_TRIM_WHITESPACE ) )  105
int32_t skipLength = newLineOffset >= 0 ? length - 1 : length ; 109
int32_t whitespaceCount = GetTrimmableWhitespaceCount ( frag , offset , skipLength , 1 ) ; 110
offset += whitespaceCount; 112
length -= whitespaceCount; 113
if ( aLineLayout . GetInFirstLetter ( ) || aLineLayout . GetInFirstLine ( ) )  119
if ( aLineLayout . GetInFirstLetter ( ) )  123
if ( mTextRun )  135
int32_t firstLetterLength = length ; 136
if ( aLineLayout . GetFirstLetterStyleOK ( ) )  137
if ( newLineOffset >= 0 )  140
firstLetterLength = NS_MIN ( firstLetterLength , length - 1 ); 142
firstLetterLength = 0; 156
length = firstLetterLength; 159
if ( ! mTextRun )  200
PropertyProvider provider ( mTextRun , textStyle , frag , this , iter , length , lineContainer , xOffsetForTabs , nsTextFrame :: eInflated ) ; 219
int32_t limitLength = length ; 232
int32_t forceBreak = aLineLayout . GetForcedBreakPosition ( mContent ) ; 233
if ( forceBreak >= offset + length )  235
forceBreak = - 1; 238
if ( forceBreak >= 0 )  240
limitLength = forceBreak - offset; 241
gfxSkipCharsIterator end ( provider . GetEndHint ( ) ) ; 290
int32_t charsFit = end . GetOriginalOffset ( ) - offset ; 292
if ( charsFit >= limitLength )  304
charsFit = limitLength; 305
int32_t contentLength = offset + charsFit - GetContentOffset ( ) ; 362
aStatus = contentLength == maxContentLength ? NS_FRAME_COMPLETE : NS_FRAME_NOT_COMPLETE; 458
if ( contentLength > 0 && mContentOffset + contentLength - 1 == newLineOffset )  464
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 466
aStatus = NS_INLINE_LINE_BREAK_AFTER ( aStatus ); 469
aStatus |= NS_INLINE_BREAK_FIRST_LETTER_COMPLETE; 473
if ( contentLength < maxContentLength && textStyle -> NewlineIsSignificant ( ) && ( contentNewLineOffset < 0 || mContentOffset + contentLength <= contentNewLineOffset ) )  477
if ( ! cachedNewlineOffset )  481
cachedNewlineOffset = new NewlineProperty 482
SetLength ( contentLength , & aLineLayout , ALLOW_FRAME_CREATION_AND_DESTRUCTION ); 513
printf ( ": desiredSize=%d,%d(b=%d) status=%x\n" , aMetrics . width , aMetrics . height , aMetrics . ascent , aStatus ); 519
------------------------------
211 ../data/NVD/CVE_2013_0772_PATCHED_nsGIFDecoder2__DoLzw.c uint8_t * rowend = mImageData + ( bpr * mGIFStruct . irow ) + mGIFStruct . width ; 29
bool
CVE_2013_0772_PATCHED_nsGIFDecoder2::DoLzw(const uint8_t *q) 2
if ( ! mGIFStruct . rows_remaining )  4
uint32_t bpr = mGIFStruct . width ; 26
if ( ! mGIFStruct . images_decoded )  27
bpr *= sizeof ( uint32_t ); 28
uint8_t * rowend = mImageData + ( bpr * mGIFStruct . irow ) + mGIFStruct . width ; 29
------------------------------
212 ../data/NVD/CVE_2013_0772_PATCHED_nsGIFDecoder2__OutputRow.c uint8_t * from = rowp + mGIFStruct . width ; 43
uint32_t CVE_2013_0772_PATCHED_nsGIFDecoder2::OutputRow() 1
int drow_start , drow_end ; 3
drow_start = drow_end = mGIFStruct . irow; 4
if ( ( unsigned ) drow_start >= mGIFStruct . height )  7
if ( ! mGIFStruct . images_decoded )  12
const uint32_t bpr = sizeof ( uint32_t ) * mGIFStruct . width ; 39
uint8_t * rowp = mImageData + ( mGIFStruct . irow * bpr ) ; 40
uint8_t * from = rowp + mGIFStruct . width ; 43
* -- to = cmap [ * -- from ]; 47
------------------------------
213 ../data/NVD/CVE_2013_0772_PATCHED_nsGIFDecoder2__OutputRow.c uint8_t * rowp = mImageData + ( mGIFStruct . irow * bpr ) ; 40
uint32_t CVE_2013_0772_PATCHED_nsGIFDecoder2::OutputRow() 1
int drow_start , drow_end ; 3
drow_start = drow_end = mGIFStruct . irow; 4
if ( ( unsigned ) drow_start >= mGIFStruct . height )  7
if ( ! mGIFStruct . images_decoded )  12
const uint32_t bpr = sizeof ( uint32_t ) * mGIFStruct . width ; 39
uint8_t * rowp = mImageData + ( mGIFStruct . irow * bpr ) ; 40
uint8_t * from = rowp + mGIFStruct . width ; 43
uint32_t * to = ( ( uint32_t * ) rowp ) + mGIFStruct . width ; 44
* -- to = cmap [ * -- from ]; 47
const uint32_t * rgb = ( uint32_t * ) rowp ; 52
if ( * rgb ++ == 0 )  54
memcpy ( mImageData + ( r * bpr ) , rowp , bpr ); 66
------------------------------
214 ../data/NVD/CVE_2013_0772_VULN_nsGIFDecoder2__DoLzw.c uint8_t * rowend = mImageData + ( bpr * mGIFStruct . irow ) + mGIFStruct . width ; 29
bool
CVE_2013_0772_VULN_nsGIFDecoder2::DoLzw(const uint8_t *q) 2
if ( ! mGIFStruct . rows_remaining )  4
uint32_t bpr = mGIFStruct . width ; 26
if ( ! mGIFStruct . images_decoded )  27
bpr *= sizeof ( uint32_t ); 28
uint8_t * rowend = mImageData + ( bpr * mGIFStruct . irow ) + mGIFStruct . width ; 29
------------------------------
215 ../data/NVD/CVE_2013_0772_VULN_nsGIFDecoder2__OutputRow.c uint8_t * from = rowp + mGIFStruct . width ; 43
uint32_t CVE_2013_0772_VULN_nsGIFDecoder2::OutputRow() 1
int drow_start , drow_end ; 3
drow_start = drow_end = mGIFStruct . irow; 4
if ( ( unsigned ) drow_start >= mGIFStruct . height )  7
if ( ! mGIFStruct . images_decoded )  12
const uint32_t bpr = sizeof ( uint32_t ) * mGIFStruct . width ; 39
uint8_t * rowp = mImageData + ( mGIFStruct . irow * bpr ) ; 40
uint8_t * from = rowp + mGIFStruct . width ; 43
* -- to = cmap [ * -- from ]; 48
* -- to = cmap [ ( * -- from ) & mask ]; 54
------------------------------
216 ../data/NVD/CVE_2013_0772_VULN_nsGIFDecoder2__OutputRow.c uint8_t * rowp = mImageData + ( mGIFStruct . irow * bpr ) ; 40
uint32_t CVE_2013_0772_VULN_nsGIFDecoder2::OutputRow() 1
int drow_start , drow_end ; 3
drow_start = drow_end = mGIFStruct . irow; 4
if ( ( unsigned ) drow_start >= mGIFStruct . height )  7
if ( ! mGIFStruct . images_decoded )  12
const uint32_t bpr = sizeof ( uint32_t ) * mGIFStruct . width ; 39
uint8_t * rowp = mImageData + ( mGIFStruct . irow * bpr ) ; 40
uint8_t * from = rowp + mGIFStruct . width ; 43
uint32_t * to = ( ( uint32_t * ) rowp ) + mGIFStruct . width ; 44
* -- to = cmap [ * -- from ]; 48
* -- to = cmap [ ( * -- from ) & mask ]; 54
const uint32_t * rgb = ( uint32_t * ) rowp ; 60
if ( * rgb ++ == 0 )  62
memcpy ( mImageData + ( r * bpr ) , rowp , bpr ); 74
------------------------------
217 ../data/NVD/CVE_2013_0777_PATCHED_nsCSSRendering__PaintBoxShadowOuter.c gfxFloat spreadDistance = shadowItem -> mSpread / twipsPerPixel ; 157
void
CVE_2013_0777_PATCHED_nsCSSRendering::PaintBoxShadowOuter(nsPresContext* aPresContext,
nsRenderingContext& aRenderingContext,
nsIFrame* aForFrame,
const nsRect& aFrameArea,
const nsRect& aDirtyRect) 6
const nsStyleBorder * styleBorder = aForFrame -> GetStyleBorder ( ) ; 8
nsCSSShadowArray * shadows = styleBorder -> mBoxShadow ; 9
if ( ! shadows )  10
nscoord twipsPerPixel = aPresContext -> DevPixelsToAppUnits ( 1 ) ; 12
bool hasBorderRadius ; 14
bool nativeTheme ; 15
const nsStyleDisplay * styleDisplay = aForFrame -> GetStyleDisplay ( ) ; 19
nsITheme :: Transparency transparency ; 20
if ( aForFrame -> IsThemed ( styleDisplay , & transparency ) )  21
hasBorderRadius = false; 23
nativeTheme = transparency != nsITheme :: eOpaque; 26
nativeTheme = false; 28
nscoord twipsRadii [ 8 ] ; 29
hasBorderRadius = aForFrame -> GetBorderRadii ( twipsRadii ); 31
nsRect frameRect = nativeTheme ? aForFrame -> GetVisualOverflowRectRelativeToSelf ( ) + aFrameArea . TopLeft ( ) : aFrameArea ; 37
bool useSkipGfxRect = true ; 45
if ( nativeTheme )  46
useSkipGfxRect = ! aForFrame -> IsLeaf ( ); 52
nsRect paddingRect = aForFrame -> GetPaddingRect ( ) - aForFrame -> GetPosition ( ) + aFrameArea . TopLeft ( ) ; 53
skipGfxRect = nsLayoutUtils :: RectToGfxRect ( paddingRect , twipsPerPixel ); 55
for (uint32_t i = shadows->Length(); i > 0; --i) 62
nsCSSShadowItem * shadowItem = shadows -> ShadowAt ( i - 1 ) ; 63
if ( shadowItem -> mInset )  64
nsRect shadowRect = frameRect ; 67
nscoord pixelSpreadRadius ; 69
if ( nativeTheme )  70
pixelSpreadRadius = shadowItem -> mSpread; 71
pixelSpreadRadius = 0; 74
nscoord blurRadius = shadowItem -> mRadius ; 80
gfxContext * renderContext = aRenderingContext . ThebesContext ( ) ; 91
nsContextBoxBlur blurringArea ; 92
gfxContext * shadowContext = blurringArea . Init ( shadowRect , pixelSpreadRadius , blurRadius , twipsPerPixel , renderContext , aDirtyRect , useSkipGfxRect ? & skipGfxRect : nullptr , nativeTheme ? nsContextBoxBlur :: FORCE_MASK : 0 ) ; 98
if ( ! shadowContext )  103
if ( nativeTheme )  125
if ( hasBorderRadius )  155
gfxFloat spreadDistance = shadowItem -> mSpread / twipsPerPixel ; 157
borderSizes [ NS_SIDE_LEFT ] = spreadDistance; 161
borderSizes [ NS_SIDE_TOP ] = spreadDistance; 162
borderSizes [ NS_SIDE_RIGHT ] = spreadDistance; 163
borderSizes [ NS_SIDE_BOTTOM ] = spreadDistance; 164
nsCSSBorderRenderer :: ComputeOuterRadii ( borderRadii , borderSizes , & clipRectRadii ); 166
------------------------------
218 ../data/NVD/CVE_2013_0777_VULN_nsCSSRendering__PaintBoxShadowOuter.c gfxFloat spreadDistance = shadowItem -> mSpread / twipsPerPixel ; 154
void
CVE_2013_0777_VULN_nsCSSRendering::PaintBoxShadowOuter(nsPresContext* aPresContext,
nsRenderingContext& aRenderingContext,
nsIFrame* aForFrame,
const nsRect& aFrameArea,
const nsRect& aDirtyRect) 6
const nsStyleBorder * styleBorder = aForFrame -> GetStyleBorder ( ) ; 8
nsCSSShadowArray * shadows = styleBorder -> mBoxShadow ; 9
if ( ! shadows )  10
nscoord twipsPerPixel = aPresContext -> DevPixelsToAppUnits ( 1 ) ; 12
bool hasBorderRadius ; 14
bool nativeTheme ; 15
const nsStyleDisplay * styleDisplay = aForFrame -> GetStyleDisplay ( ) ; 19
nsITheme :: Transparency transparency ; 20
if ( aForFrame -> IsThemed ( styleDisplay , & transparency ) )  21
hasBorderRadius = false; 23
nativeTheme = transparency != nsITheme :: eOpaque; 26
nativeTheme = false; 28
nscoord twipsRadii [ 8 ] ; 29
hasBorderRadius = aForFrame -> GetBorderRadii ( twipsRadii ); 31
nsRect frameRect = nativeTheme ? aForFrame -> GetVisualOverflowRectRelativeToSelf ( ) + aFrameArea . TopLeft ( ) : aFrameArea ; 37
bool useSkipGfxRect = true ; 45
if ( nativeTheme )  46
useSkipGfxRect = ! aForFrame -> IsLeaf ( ); 52
nsRect paddingRect = aForFrame -> GetPaddingRect ( ) - aForFrame -> GetPosition ( ) + aFrameArea . TopLeft ( ) ; 53
skipGfxRect = nsLayoutUtils :: RectToGfxRect ( paddingRect , twipsPerPixel ); 55
for (uint32_t i = shadows->Length(); i > 0; --i) 62
nsCSSShadowItem * shadowItem = shadows -> ShadowAt ( i - 1 ) ; 63
if ( shadowItem -> mInset )  64
nsRect shadowRect = frameRect ; 67
nscoord pixelSpreadRadius ; 69
if ( nativeTheme )  70
pixelSpreadRadius = shadowItem -> mSpread; 71
pixelSpreadRadius = 0; 74
nscoord blurRadius = shadowItem -> mRadius ; 80
gfxContext * renderContext = aRenderingContext . ThebesContext ( ) ; 91
nsRefPtr < gfxContext > shadowContext ; 92
nsContextBoxBlur blurringArea ; 93
shadowContext = blurringArea . Init ( shadowRect , pixelSpreadRadius , blurRadius , twipsPerPixel , renderContext , aDirtyRect , useSkipGfxRect ? & skipGfxRect : nullptr , nativeTheme ? nsContextBoxBlur :: FORCE_MASK : 0 ); 99
if ( ! shadowContext )  104
if ( nativeTheme )  122
if ( hasBorderRadius )  152
gfxFloat spreadDistance = shadowItem -> mSpread / twipsPerPixel ; 154
borderSizes [ NS_SIDE_LEFT ] = spreadDistance; 158
borderSizes [ NS_SIDE_TOP ] = spreadDistance; 159
borderSizes [ NS_SIDE_RIGHT ] = spreadDistance; 160
borderSizes [ NS_SIDE_BOTTOM ] = spreadDistance; 161
nsCSSBorderRenderer :: ComputeOuterRadii ( borderRadii , borderSizes , & clipRectRadii ); 163
------------------------------
219 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__HandleFallBack.c char * temp = ( char * ) PR_Realloc ( * outString , * bufferLength + addLength + 1 ) ; 18
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::HandleFallBack(uint32_t character, char **outString, int32_t *bufferLength,
int32_t *currentPos, int32_t estimatedLength) 3
char fallbackStr [ 256 ] ; 9
nsresult rv = DoConversionFallBack ( character , fallbackStr , 256 ) ; 10
if ( NS_SUCCEEDED ( rv ) )  11
int32_t tempLen = ( int32_t ) PL_strlen ( fallbackStr ) ; 12
if ( ( tempLen + estimatedLength ) >= ( * bufferLength - * currentPos ) )  15
int32_t addLength = tempLen + RESERVE_FALLBACK_BYTES ; 16
char * temp = ( char * ) PR_Realloc ( * outString , * bufferLength + addLength + 1 ) ; 18
if ( temp )  19
* outString = temp; 22
* outString = nullptr; 24
memcpy ( ( * outString + * currentPos ) , fallbackStr , tempLen ); 29
------------------------------
220 ../data/NVD/CVE_2013_0782_PATCHED_nsSaveAsCharset__HandleFallBack.c int32_t addLength = tempLen + RESERVE_FALLBACK_BYTES ; 16
NS_IMETHODIMP
CVE_2013_0782_PATCHED_nsSaveAsCharset::HandleFallBack(uint32_t character, char **outString, int32_t *bufferLength,
int32_t *currentPos, int32_t estimatedLength) 3
char fallbackStr [ 256 ] ; 9
nsresult rv = DoConversionFallBack ( character , fallbackStr , 256 ) ; 10
if ( NS_SUCCEEDED ( rv ) )  11
int32_t tempLen = ( int32_t ) PL_strlen ( fallbackStr ) ; 12
if ( ( tempLen + estimatedLength ) >= ( * bufferLength - * currentPos ) )  15
int32_t addLength = tempLen + RESERVE_FALLBACK_BYTES ; 16
char * temp = ( char * ) PR_Realloc ( * outString , * bufferLength + addLength + 1 ) ; 18
if ( temp )  19
* bufferLength += addLength; 21
* outString = temp; 22
* outString = nullptr; 24
* bufferLength = 0; 25
memcpy ( ( * outString + * currentPos ) , fallbackStr , tempLen ); 29
------------------------------
221 ../data/NVD/CVE_2013_0782_VULN_nsSaveAsCharset__HandleFallBack.c char * temp = ( char * ) PR_Realloc ( * outString , * bufferLength + tempLen ) ; 16
NS_IMETHODIMP
CVE_2013_0782_VULN_nsSaveAsCharset::HandleFallBack(uint32_t character, char **outString, int32_t *bufferLength,
int32_t *currentPos, int32_t estimatedLength) 3
char fallbackStr [ 256 ] ; 9
nsresult rv = DoConversionFallBack ( character , fallbackStr , 256 ) ; 10
if ( NS_SUCCEEDED ( rv ) )  11
int32_t tempLen = ( int32_t ) PL_strlen ( fallbackStr ) ; 12
if ( ( tempLen + estimatedLength ) >= ( * bufferLength - * currentPos ) )  15
char * temp = ( char * ) PR_Realloc ( * outString , * bufferLength + tempLen ) ; 16
if ( temp )  17
* outString = temp; 20
* outString = nullptr; 22
memcpy ( ( * outString + * currentPos ) , fallbackStr , tempLen ); 27
------------------------------
222 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c int16_t * smp = samples + channel ; 295
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (channel = 0; channel < avctx->channels; channel++) 294
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
------------------------------
223 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = (nb_samples - 1) >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
while ( samples < samples_end )  229
------------------------------
224 ../data/NVD/CVE_2013_0844_PATCHED_adpcm_decode_frame.c int diff = predictor - cs -> predictor ; 56
static int CVE_2013_0844_PATCHED_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
------------------------------
225 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c int16_t * smp = samples + channel ; 295
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
GetByteContext gb ; 13
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
c -> status [ 0 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 206
c -> status [ 1 ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 207
c -> status [ 0 ] . step_index = bytestream2_get_byteu ( & gb ); 208
c -> status [ 1 ] . step_index = bytestream2_get_byteu ( & gb ); 209
if ( c -> status [ 0 ] . step_index > 88u || c -> status [ 1 ] . step_index > 88u )  210
while ( samples < samples_end )  229
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 244
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 245
* samples ++ = c -> status [ 0 ] . predictor + c -> status [ 1 ] . predictor; 253
* samples ++ = c -> status [ 0 ] . predictor - c -> status [ 1 ] . predictor; 254
for (channel = 0; channel < avctx->channels; channel++) 259
cs = & c -> status [ channel ]; 260
cs -> predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 261
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 262
if ( cs -> step_index > 88u )  263
for (n = nb_samples >> (1 - st); n > 0; n--) 270
int v1 , v2 ; 271
int v = bytestream2_get_byteu ( & gb ) ; 272
if ( st )  274
v1 = v >> 4; 275
v2 = v & 0x0F; 276
v2 = v >> 4; 278
v1 = v & 0x0F; 279
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v1 , 3 ); 281
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v2 , 3 ); 282
while ( bytestream2_get_bytes_left ( & gb ) > 0 )  286
int v = bytestream2_get_byteu ( & gb ) ; 287
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 288
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 289
if ( c -> vqa_version == 3 )  293
for (channel = 0; channel < avctx->channels; channel++) 294
int16_t * smp = samples + channel ; 295
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v >> 4 , 3 ); 299
smp += avctx -> channels; 300
* smp = adpcm_ima_expand_nibble ( & c -> status [ channel ] , v & 0x0F , 3 ); 301
smp += avctx -> channels; 302
------------------------------
226 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
short * samples ; 9
int st ; 10
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
samples = ( short * ) c -> frame . data [ 0 ]; 28
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
st = avctx -> channels == 2 ? 1 : 0; 38
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
samples = ( short * ) c -> frame . data [ 0 ] + channel; 73
for (m = 0; m < 32; m++) 75
int byte = bytestream2_get_byteu ( & gb ) ; 76
* samples = adpcm_ima_qt_expand_nibble ( cs , byte & 0x0F , 3 ); 77
samples += avctx -> channels; 78
* samples = adpcm_ima_qt_expand_nibble ( cs , byte >> 4 , 3 ); 79
samples += avctx -> channels; 80
for(i=0; i<avctx->channels; i++) 85
cs = & ( c -> status [ i ] ); 86
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 87
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 89
if ( cs -> step_index > 88u )  90
for (n = (nb_samples - 1) / 8; n > 0; n--) 97
for (i = 0; i < avctx->channels; i++) 98
cs = & c -> status [ i ]; 99
for (m = 0; m < 4; m++) 100
int v = bytestream2_get_byteu ( & gb ) ; 101
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 3 ); 102
samples += avctx -> channels; 103
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 3 ); 104
samples += avctx -> channels; 105
samples -= 8 * avctx -> channels - 1; 107
samples += 7 * avctx -> channels; 109
for (i = 0; i < avctx->channels; i++) 113
c -> status [ i ] . predictor = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 114
for (i = 0; i < avctx->channels; i++) 116
c -> status [ i ] . step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 117
if ( c -> status [ i ] . step_index > 88u )  118
for (i = 0; i < avctx->channels; i++) 125
samples = ( short * ) c -> frame . data [ 0 ] + i; 126
cs = & c -> status [ i ]; 127
for (n = nb_samples >> 1; n > 0; n--) 128
int v = bytestream2_get_byteu ( & gb ) ; 129
* samples = adpcm_ima_expand_nibble ( cs , v & 0x0F , 4 ); 130
samples += avctx -> channels; 131
* samples = adpcm_ima_expand_nibble ( cs , v >> 4 , 4 ); 132
samples += avctx -> channels; 133
int block_predictor ; 139
block_predictor = bytestream2_get_byteu ( & gb ); 141
if ( block_predictor > 6 )  142
c -> status [ 0 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 147
c -> status [ 0 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 148
if ( st )  149
block_predictor = bytestream2_get_byteu ( & gb ); 150
if ( block_predictor > 6 )  151
c -> status [ 1 ] . coeff1 = ff_adpcm_AdaptCoeff1 [ block_predictor ]; 156
c -> status [ 1 ] . coeff2 = ff_adpcm_AdaptCoeff2 [ block_predictor ]; 157
c -> status [ 0 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 159
if ( st )  160
c -> status [ 1 ] . idelta = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 161
c -> status [ 0 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 164
if ( st )  165
c -> status [ 1 ] . sample1 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 165
c -> status [ 0 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 166
if ( st )  167
c -> status [ 1 ] . sample2 = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 167
* samples ++ = c -> status [ 0 ] . sample2; 169
if ( st )  170
* samples ++ = c -> status [ 1 ] . sample2; 170
* samples ++ = c -> status [ 0 ] . sample1; 171
if ( st )  172
* samples ++ = c -> status [ 1 ] . sample1; 172
for(n = (nb_samples - 2) >> (1 - st); n > 0; n--) 173
int byte = bytestream2_get_byteu ( & gb ) ; 174
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ 0 ] , byte >> 4 ); 175
* samples ++ = adpcm_ms_expand_nibble ( & c -> status [ st ] , byte & 0x0F ); 176
for (channel = 0; channel < avctx->channels; channel++) 181
cs = & c -> status [ channel ]; 182
cs -> predictor = * samples ++ = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 183
cs -> step_index = sign_extend ( bytestream2_get_le16u ( & gb ) , 16 ); 184
if ( cs -> step_index > 88u )  185
for (n = nb_samples >> (1 - st); n > 0; n--) 191
int v = bytestream2_get_byteu ( & gb ) ; 192
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ 0 ] , v >> 4 , 3 ); 193
* samples ++ = adpcm_ima_expand_nibble ( & c -> status [ st ] , v & 0x0F , 3 ); 194
const int16_t * samples_end = samples + avctx -> channels * nb_samples ; 203
while ( samples < samples_end )  229
------------------------------
227 ../data/NVD/CVE_2013_0844_VULN_adpcm_decode_frame.c int diff = predictor - cs -> predictor ; 56
static int CVE_2013_0844_VULN_adpcm_decode_frame(AVCodecContext *avctx, void *data,
int *got_frame_ptr, AVPacket *avpkt) 2
int buf_size = avpkt -> size ; 5
ADPCMDecodeContext * c = avctx -> priv_data ; 6
ADPCMChannelStatus * cs ; 7
int n , m , channel , i ; 8
int nb_samples , coded_samples , ret ; 12
nb_samples = get_nb_samples ( avctx , & gb , buf_size , & coded_samples ); 16
if ( nb_samples <= 0 )  17
c -> frame . nb_samples = nb_samples; 23
if ( ( ret = avctx -> get_buffer ( avctx , & c -> frame ) ) < 0 )  24
if ( coded_samples )  32
c -> frame . nb_samples = nb_samples = coded_samples; 35
switch ( avctx -> codec -> id )  40
for (channel = 0; channel < avctx->channels; channel++) 44
int predictor ; 45
int step_index ; 46
cs = & ( c -> status [ channel ] ); 47
predictor = sign_extend ( bytestream2_get_be16u ( & gb ) , 16 ); 51
step_index = predictor & 0x7F; 52
predictor &= ~0x7F; 53
if ( cs -> step_index == step_index )  55
int diff = predictor - cs -> predictor ; 56
if ( diff < 0 )  57
diff = - diff; 58
if ( diff > 0x7f )  59
cs -> step_index = step_index; 63
cs -> predictor = predictor; 64
if ( cs -> step_index > 88u )  67
------------------------------
228 ../data/NVD/CVE_2013_0851_PATCHED_decode_frame.c const uint8_t * buf_end = buf + buf_size ; 7
static int CVE_2013_0851_PATCHED_decode_frame(AVCodecContext *avctx,
void *data, int *data_size,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> data ; 5
int buf_size = avpkt -> size ; 6
const uint8_t * buf_end = buf + buf_size ; 7
if ( ( width * height ) / 2048 * 7 > buf_end - buf )  32
av_fast_malloc ( & s -> bitstream_buf , & s -> bitstream_buf_size , ( buf_end - buf ) + FF_INPUT_BUFFER_PADDING_SIZE ); 51
s -> dsp . bswap16_buf ( s -> bitstream_buf , ( const uint16_t * ) buf , ( buf_end - buf ) / 2 ); 54
memset ( ( uint8_t * ) s -> bitstream_buf + ( buf_end - buf ) , 0 , FF_INPUT_BUFFER_PADDING_SIZE ); 55
init_get_bits ( & s -> gb , s -> bitstream_buf , 8 * ( buf_end - buf ) ); 56
------------------------------
229 ../data/NVD/CVE_2013_0851_VULN_decode_frame.c const uint8_t * buf_end = buf + buf_size ; 7
static int CVE_2013_0851_VULN_decode_frame(AVCodecContext *avctx,
void *data, int *data_size,
AVPacket *avpkt) 3
const uint8_t * buf = avpkt -> data ; 5
int buf_size = avpkt -> size ; 6
const uint8_t * buf_end = buf + buf_size ; 7
if ( ( width * height ) / 2048 * 7 > buf_end - buf )  32
av_fast_malloc ( & s -> bitstream_buf , & s -> bitstream_buf_size , ( buf_end - buf ) + FF_INPUT_BUFFER_PADDING_SIZE ); 51
s -> dsp . bswap16_buf ( s -> bitstream_buf , ( const uint16_t * ) buf , ( buf_end - buf ) / 2 ); 54
memset ( ( uint8_t * ) s -> bitstream_buf + ( buf_end - buf ) , 0 , FF_INPUT_BUFFER_PADDING_SIZE ); 55
init_get_bits ( & s -> gb , s -> bitstream_buf , 8 * ( buf_end - buf ) ); 56
------------------------------
230 ../data/NVD/CVE_2013_0855_VULN_allocate_buffers.c int buf_size = alac -> max_samples_per_frame * sizeof ( int32_t ) ; 4
static int CVE_2013_0855_VULN_allocate_buffers(ALACContext *alac) 1
int buf_size = alac -> max_samples_per_frame * sizeof ( int32_t ) ; 4
FF_ALLOC_OR_GOTO ( alac -> avctx , alac -> predict_error_buffer [ ch ] , buf_size , buf_alloc_fail ); 7
FF_ALLOC_OR_GOTO ( alac -> avctx , alac -> output_samples_buffer [ ch ] , buf_size , buf_alloc_fail ); 12
FF_ALLOC_OR_GOTO ( alac -> avctx , alac -> extra_bits_buffer [ ch ] , buf_size , buf_alloc_fail ); 16
------------------------------
231 ../data/NVD/CVE_2013_0864_PATCHED_gif_copy_img_rect.c const uint32_t * src_pb = src_py + h * linesize ; 8
static void CVE_2013_0864_PATCHED_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + h * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
------------------------------
232 ../data/NVD/CVE_2013_0864_PATCHED_gif_copy_img_rect.c const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
static void CVE_2013_0864_PATCHED_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + h * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
dst_px = ( uint32_t * ) dst_py + l; 13
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
233 ../data/NVD/CVE_2013_0864_PATCHED_gif_copy_img_rect.c const int y_start = t * linesize ; 4
static void CVE_2013_0864_PATCHED_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + h * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
dst_px = ( uint32_t * ) dst_py + l; 13
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
234 ../data/NVD/CVE_2013_0864_VULN_gif_copy_img_rect.c const uint32_t * src_pb = src_py + t * linesize ; 8
static void CVE_2013_0864_VULN_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + t * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
------------------------------
235 ../data/NVD/CVE_2013_0864_VULN_gif_copy_img_rect.c const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
static void CVE_2013_0864_VULN_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + t * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
dst_px = ( uint32_t * ) dst_py + l; 13
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
236 ../data/NVD/CVE_2013_0864_VULN_gif_copy_img_rect.c const int y_start = t * linesize ; 4
static void CVE_2013_0864_VULN_gif_copy_img_rect(const uint32_t *src, uint32_t *dst,
int linesize, int l, int t, int w, int h) 2
const int y_start = t * linesize ; 4
const uint32_t * src_px , * src_pr , * src_py = src + y_start , * dst_py = dst + y_start ; 5
const uint32_t * src_pb = src_py + t * linesize ; 8
for (; src_py < src_pb; src_py += linesize, dst_py += linesize) 11
src_px = src_py + l; 12
dst_px = ( uint32_t * ) dst_py + l; 13
src_pr = src_px + w; 14
for (; src_px < src_pr; src_px++, dst_px++) 16
* dst_px = * src_px; 17
------------------------------
